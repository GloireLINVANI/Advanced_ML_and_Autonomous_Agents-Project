{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjC5UydPYSvm"
   },
   "source": [
    "# Comparing Tree Search and Reinforcement Learning Approaches for King and Courtesan Game\n",
    "## Gloire LINVANI\n",
    "### CSC-52081-EP Advanced Machine Learning and Autonomous Agents Project\n",
    "\n",
    "### The following contains adapted material from the labs 6 and 7 developed by Jérémie Decock.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jeremiedecock/polytechnique-csc-52081-ep-2025-students/refs/heads/main/assets/logo.jpg\" style=\"float: left; width: 15%\" />\n",
    "\n",
    "[CSC-52081-EP-2025](https://moodle.polytechnique.fr/course/view.php?id=19336)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0SUKVaBYuNt"
   },
   "source": [
    "# Colab Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAi4s3cPhZ4J"
   },
   "source": [
    "#### For practical reasons, we run the notebook in the Google Drive folder where it is located. We need to provide a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16114,
     "status": "ok",
     "timestamp": 1742263907729,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "uGI1hFYag0vn",
    "outputId": "61823615-e82b-4967-c147-489e40318b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/Colab Notebooks/M1 Data AI/Advanced Machine Learning and Autonomous Agents/Project\n",
      "/content/drive/MyDrive/Colab Notebooks/M1 Data AI/Advanced Machine Learning and Autonomous Agents/Project\n",
      " checkpoints\t\t\t\t        __pycache__\n",
      " commons-cli-1.4.jar\t\t\t        qodana.yaml\n",
      "'Copy of Reinforcement_Learning_Agents.ipynb'   README.md\n",
      " figs\t\t\t\t\t        Reinforcement_Learning_Agents.ipynb\n",
      " IDAlphaBetaClient.py\t\t\t        reinforcement_learning_agents.py\n",
      " json-20250107.jar\t\t\t        Reinforcement_Learning_Project_Report.pdf\n",
      " kac_server.log\t\t\t\t       'Reinforcement Learning Project Report.zip'\n",
      " kac_server.log.1\t\t\t        requirements.txt\n",
      " kac_server.log.lck\t\t\t        RL_KAC.jar\n",
      " KingAndCourtesanEnv.py\t\t\t        server1.log\n",
      " King_and_Courtesan_Game_Java\t\t        server2.log\n",
      " models\t\t\t\t\t        test_functions.py\n",
      " nohup.out\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Replace path_to_notebook with your actual path\n",
    "path_to_notebook = \"/content/drive/MyDrive/Colab Notebooks/M1 Data AI/Advanced Machine Learning and Autonomous Agents/Project\"\n",
    "\n",
    "%cd {path_to_notebook}\n",
    "\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13873,
     "status": "ok",
     "timestamp": 1742263921603,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "4AixSpsoc0r3",
    "outputId": "b1e159b3-e8a1-4c1e-954c-4c62a51fa45a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 5,484 B/129 kB 4%] [Waiting \u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,378 kB]\n",
      "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [69.9 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,236 kB]\n",
      "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,753 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,692 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,535 kB]\n",
      "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,000 kB]\n",
      "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,674 kB]\n",
      "Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.6 kB]\n",
      "Get:20 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.8 kB]\n",
      "Fetched 21.9 MB in 2s (12.5 MB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  default-jdk-headless default-jre default-jre-headless fonts-dejavu-core\n",
      "  fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
      "  libice-dev libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1\n",
      "  openjdk-11-jdk openjdk-11-jre x11-utils\n",
      "Suggested packages:\n",
      "  libice-doc libsm-doc libxt-doc openjdk-11-demo openjdk-11-source visualvm\n",
      "  mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  default-jdk default-jdk-headless default-jre default-jre-headless\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libfontenc1 libice-dev libsm-dev libxkbfile1\n",
      "  libxt-dev libxtst6 libxxf86dga1 openjdk-11-jdk openjdk-11-jre x11-utils\n",
      "0 upgraded, 18 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 5,528 kB of archives.\n",
      "After this operation, 15.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.26+4-1ubuntu1~22.04 [214 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jdk-headless amd64 2:1.11-72build2 [942 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.26+4-1ubuntu1~22.04 [1,341 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jdk amd64 2:1.11-72build2 [908 B]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
      "Fetched 5,528 kB in 0s (14.2 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 18.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package default-jre-headless.\n",
      "(Reading database ... 125044 files and directories currently installed.)\n",
      "Preparing to unpack .../00-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n",
      "Unpacking default-jre-headless (2:1.11-72build2) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
      "Selecting previously unselected package openjdk-11-jre:amd64.\n",
      "Preparing to unpack .../02-openjdk-11-jre_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking openjdk-11-jre:amd64 (11.0.26+4-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package default-jre.\n",
      "Preparing to unpack .../03-default-jre_2%3a1.11-72build2_amd64.deb ...\n",
      "Unpacking default-jre (2:1.11-72build2) ...\n",
      "Selecting previously unselected package default-jdk-headless.\n",
      "Preparing to unpack .../04-default-jdk-headless_2%3a1.11-72build2_amd64.deb ...\n",
      "Unpacking default-jdk-headless (2:1.11-72build2) ...\n",
      "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
      "Preparing to unpack .../05-openjdk-11-jdk_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk:amd64 (11.0.26+4-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package default-jdk.\n",
      "Preparing to unpack .../06-default-jdk_2%3a1.11-72build2_amd64.deb ...\n",
      "Unpacking default-jdk (2:1.11-72build2) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../07-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
      "Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../08-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
      "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
      "Selecting previously unselected package libfontenc1:amd64.\n",
      "Preparing to unpack .../09-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
      "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
      "Selecting previously unselected package libxkbfile1:amd64.\n",
      "Preparing to unpack .../10-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
      "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+5build2) ...\n",
      "Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
      "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
      "Selecting previously unselected package libice-dev:amd64.\n",
      "Preparing to unpack .../15-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
      "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
      "Selecting previously unselected package libsm-dev:amd64.\n",
      "Preparing to unpack .../16-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
      "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
      "Selecting previously unselected package libxt-dev:amd64.\n",
      "Preparing to unpack .../17-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
      "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
      "Setting up default-jre-headless (2:1.11-72build2) ...\n",
      "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
      "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
      "Setting up openjdk-11-jre:amd64 (11.0.26+4-1ubuntu1~22.04) ...\n",
      "Setting up default-jre (2:1.11-72build2) ...\n",
      "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
      "Setting up default-jdk-headless (2:1.11-72build2) ...\n",
      "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
      "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
      "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
      "Setting up openjdk-11-jdk:amd64 (11.0.26+4-1ubuntu1~22.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
      "Setting up default-jdk (2:1.11-72build2) ...\n",
      "Setting up x11-utils (7.7+5build2) ...\n",
      "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
      "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
      "openjdk version \"11.0.26\" 2025-01-21\n",
      "OpenJDK Runtime Environment (build 11.0.26+4-post-Ubuntu-1ubuntu122.04)\n",
      "OpenJDK 64-Bit Server VM (build 11.0.26+4-post-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n",
      "javac 11.0.26\n"
     ]
    }
   ],
   "source": [
    "# Installing Java\n",
    "\n",
    "!sudo apt update\n",
    "\n",
    "!sudo apt install default-jdk\n",
    "\n",
    "!java -version\n",
    "!javac -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeHdR2iIpEAF"
   },
   "source": [
    "### Starting Java servers: Port 3 for King and Courtesan server and port 9 for ID Alpha Beta agent server. You can change the ports if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5q3MfDbUePyA"
   },
   "outputs": [],
   "source": [
    "# Starting the Java server in the background\n",
    "!nohup java -cp \"RL_KAC.jar:json-20250107.jar:commons-cli-1.4.jar\" games.kac.RL_Agents_KingAndCourtesanServer -p 3 > server1.log 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmdlBDpGpC3I"
   },
   "outputs": [],
   "source": [
    "!nohup java -cp \"RL_KAC.jar:json-20250107.jar:commons-cli-1.4.jar\" games.kac.IDAlphaBetaServer -t 30 -p 9 > server2.log 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5200,
     "status": "ok",
     "timestamp": 1742263927352,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "4fHJIc11ePyA",
    "outputId": "4271d8c6-1b8e-4f9e-b484-35dc8cb5c7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server to start...\n",
      "Mar 18, 2025 2:12:04 AM games.kac.RL_Agents_KingAndCourtesanServer main\n",
      "INFO: King and Courtesan server started on port 3\n",
      "Mar 18, 2025 2:12:04 AM games.kac.RL_Agents_KingAndCourtesanServer main\n",
      "INFO: Configuration: boardSize=6, threads=10, clientTimeout=60s, verbose=false\n",
      "ID Alpha-Beta server started on port 9\n",
      "Configuration: depth=8, timeLimit=30s\n"
     ]
    }
   ],
   "source": [
    "# Giving the server time to start\n",
    "import time\n",
    "\n",
    "print(\"Waiting for server to start...\")\n",
    "time.sleep(5)\n",
    "!cat server1.log  # Server log\n",
    "!cat server2.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTBH1rF1YSvp"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLeNOCbkYSvq"
   },
   "source": [
    "This notebook relies on several libraries like `gymnasium`, `torch`, `numpy`, `tqdm`, `matplotlib`, etc.\n",
    "A complete list of dependencies can be found in the `requirements.txt` file at the root of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67808,
     "status": "ok",
     "timestamp": 1742263995161,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "qSd9om4cjW0R",
    "outputId": "b58b653d-e85d-4ae1-9afe-4bd8c92a535d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.6.0+cu124)\n",
      "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->-r requirements.txt (line 7)) (3.1.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium->-r requirements.txt (line 7)) (0.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 6)) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-YX6bCeYSvq"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpFbkX67YSvq"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from importlib import reload\n",
    "\n",
    "import gymnasium as gym\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "from typing import Union, List, Tuple, Optional, Callable\n",
    "\n",
    "import test_functions\n",
    "import KingAndCourtesanEnv as kac\n",
    "import joblib\n",
    "from importlib import reload\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lq5oxThYSvr"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chTVmEAgYSvr"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnFbNdosYSvr"
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKZ3UpKaYSvr"
   },
   "outputs": [],
   "source": [
    "PLOTS_DIR = Path(\"figs/\") / \"RL Agents\"  # Where to save plots (.png or .svg files)\n",
    "MODELS_DIR = Path(\"models/\") / \"RL Agents\"  # Where to save models (.pth files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWYSqaXuYSvr"
   },
   "outputs": [],
   "source": [
    "if not PLOTS_DIR.exists():\n",
    "    PLOTS_DIR.mkdir(parents=True)\n",
    "if not MODELS_DIR.exists():\n",
    "    MODELS_DIR.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpAYwEHBYSvr"
   },
   "outputs": [],
   "source": [
    "DEFAULT_NUMBER_OF_TRAININGS = 3\n",
    "BOARD_SIZE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtO2lKdmYSvs"
   },
   "source": [
    "## PyTorch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWBf6yXAYSvs"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# Set the device to CUDA if available, otherwise use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1742264000595,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "e86WohFKYSvs",
    "outputId": "75b2f321-3a38-42a4-d2ef-f824a48c0055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      "- Device 0: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Available GPUs:\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"- Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using Metal Performance Shaders (MPS)\")\n",
    "    print(f\"{torch.mps.device_count()} GPU(s) available.\")\n",
    "else:\n",
    "    print(\"- No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742264000602,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "lrB_x1MsYSvs",
    "outputId": "e5c94ba1-aa80-4698-ab8e-dfe681eec180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch will train and test neural networks on cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch will train and test neural networks on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742264000610,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "IkRyN0_4lHVC",
    "outputId": "26420517-08f3-4972-a969-4fe36f9376b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session active depuis 0h 0m 0s\n",
      "Traitement en cours... Dernière activité: 02:13:20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>setTimeout(()=>{google.colab.kernel.invokeFunction('notebook.keep_alive')}, 60000)</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to keep the session active\n",
    "def keep_alive():\n",
    "    import IPython\n",
    "    import time\n",
    "    from IPython.display import clear_output\n",
    "    import datetime\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    def refresh_session():\n",
    "        clear_output(wait=True)\n",
    "        current_time = time.time()\n",
    "        elapsed = current_time - start_time\n",
    "        hours, rem = divmod(elapsed, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "        print(f\"Session active depuis {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "        print(f\"Traitement en cours... Dernière activité: {datetime.datetime.now().strftime('%H:%M:%S')}\")\n",
    "        return IPython.display.HTML(\n",
    "            \"<script>setTimeout(()=>{google.colab.kernel.invokeFunction('notebook.keep_alive')}, 60000)</script>\")\n",
    "\n",
    "    IPython.display.display(refresh_session())\n",
    "    IPython.get_ipython().kernel.comm_manager.register_target('notebook',\n",
    "                                                              lambda comm, msg: comm.on_msg(\n",
    "                                                                  lambda msg: refresh_session()))\n",
    "\n",
    "\n",
    "keep_alive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylbNrngZYSvs"
   },
   "source": [
    "## 1. Python King And Courtesan Environment Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mx1WV1y1YSvt"
   },
   "source": [
    "#### The environement and ID Alpha Beta client are implemented in modules `KingAndCourtesanEnv.py` and `IDAlphaBetaClient.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QMZjPUKYSvt"
   },
   "source": [
    "Print some information about the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1741368240721,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "K55ddJu1YSvt",
    "outputId": "c0f63d32-e492-4e93-bca7-63de23814851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "Available legal moves: ['A0-A1', 'A0-B0', 'A0-B1', 'A3-B4', 'A4-A5', 'A4-B4', 'A4-B5', 'B2-C3', 'B3-B4', 'B3-C3', 'B3-C4', 'C1-D2', 'C2-C3', 'C2-D2', 'C2-D3', 'D0-E1', 'D1-D2', 'D1-E1', 'D1-E2', 'E0-E1', 'E0-F0', 'E0-F1']\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "env = kac.KingAndCourtesanEnv(host='localhost', port=3, render_mode='human')\n",
    "\n",
    "# Use environment for training/testing\n",
    "state, info = env.reset()\n",
    "print(f\"Available legal moves: {info['legal_moves']}\")\n",
    "\n",
    "# For rendering\n",
    "env.render()\n",
    "\n",
    "# Close when done\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1741368246352,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "UR7Qhv2nYSvt",
    "outputId": "8ad7b1d9-818a-49d7-d4ac-dcaf58c1162a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'legal_moves': ['A0-A1',\n",
       "  'A0-B0',\n",
       "  'A0-B1',\n",
       "  'A3-B4',\n",
       "  'A4-A5',\n",
       "  'A4-B4',\n",
       "  'A4-B5',\n",
       "  'B2-C3',\n",
       "  'B3-B4',\n",
       "  'B3-C3',\n",
       "  'B3-C4',\n",
       "  'C1-D2',\n",
       "  'C2-C3',\n",
       "  'C2-D2',\n",
       "  'C2-D3',\n",
       "  'D0-E1',\n",
       "  'D1-D2',\n",
       "  'D1-E1',\n",
       "  'D1-E2',\n",
       "  'E0-E1',\n",
       "  'E0-F0',\n",
       "  'E0-F1'],\n",
       " 'is_first_player': True,\n",
       " 'current_player_role': 'RED'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gn9e1A6gYSvt"
   },
   "source": [
    "#### Testing the environment with two random policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1741368267465,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "UihId4EGYSvt",
    "outputId": "df5ef28c-88e4-414a-a856-d3f83df44b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "step 0\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C RR--BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "step 1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRRB-B\n",
      "C RR-BBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "step 2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R-RB-B\n",
      "C RR-BBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "step 3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E RBRBBB\n",
      "D R-RB-B\n",
      "C RR-BBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "step 4\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E RB-BBB\n",
      "D R-RB-B\n",
      "C RR-BBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "step 5\n",
      "  012345\n",
      "F -B-RQB\n",
      "E RB-BBB\n",
      "D R-RB-B\n",
      "C RR-BBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 6\n",
      "  012345\n",
      "F -B-RQB\n",
      "E RB-BBB\n",
      "D R-RB-B\n",
      "C RR-RBB\n",
      "B RRR--B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 7\n",
      "  012345\n",
      "F -B-RQB\n",
      "E B--BBB\n",
      "D R-RB-B\n",
      "C RR-RBB\n",
      "B RRR--B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 8\n",
      "  012345\n",
      "F -B-RQB\n",
      "E B--BBB\n",
      "D R-RB-B\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A KRR-R-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 9\n",
      "  012345\n",
      "F B--RQB\n",
      "E B--BBB\n",
      "D R-RB-B\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A KRR-R-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 10\n",
      "  012345\n",
      "F B--RQB\n",
      "E B--BBB\n",
      "D R-RB-B\n",
      "C RR-RBB\n",
      "B RRRRRB\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 11\n",
      "  012345\n",
      "F B--BQB\n",
      "E B---BB\n",
      "D R-RB-B\n",
      "C RR-RBB\n",
      "B RRRRRB\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 12\n",
      "  012345\n",
      "F B--BQB\n",
      "E B---BB\n",
      "D RRRB-B\n",
      "C -R-RBB\n",
      "B RRRRRB\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 13\n",
      "  012345\n",
      "F B--BQB\n",
      "E B---BB\n",
      "D RRRB-B\n",
      "C -R-RB-\n",
      "B RRRRBB\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 14\n",
      "  012345\n",
      "F B--BQB\n",
      "E B---BB\n",
      "D RRRB-B\n",
      "C -R--R-\n",
      "B RRRRBB\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 15\n",
      "  012345\n",
      "F B---QB\n",
      "E B-B-BB\n",
      "D RRRB-B\n",
      "C -R--R-\n",
      "B RRRRBB\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 16\n",
      "  012345\n",
      "F B---QB\n",
      "E B-B-BB\n",
      "D RRRB-B\n",
      "C -R-RR-\n",
      "B RR-RBB\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 17\n",
      "  012345\n",
      "F B---QB\n",
      "E B-B-BB\n",
      "D RRRB-B\n",
      "C -R-RR-\n",
      "B RR-RB-\n",
      "A KRR-B-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 18\n",
      "  012345\n",
      "F B---QB\n",
      "E B-B-BB\n",
      "D RRRBRB\n",
      "C -R--R-\n",
      "B RR-RB-\n",
      "A KRR-B-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 19\n",
      "  012345\n",
      "F B---QB\n",
      "E BB--BB\n",
      "D RRRBRB\n",
      "C -R--R-\n",
      "B RR-RB-\n",
      "A KRR-B-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 20\n",
      "  012345\n",
      "F B---QB\n",
      "E BBR-BB\n",
      "D RR-BRB\n",
      "C -R--R-\n",
      "B RR-RB-\n",
      "A KRR-B-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 21\n",
      "  012345\n",
      "F B---QB\n",
      "E BBR-BB\n",
      "D RR-BRB\n",
      "C -R--R-\n",
      "B RR-BB-\n",
      "A KRR---\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 22\n",
      "  012345\n",
      "F B---QB\n",
      "E BBR-BB\n",
      "D RR-BRB\n",
      "C -R--R-\n",
      "B RRRBB-\n",
      "A KR----\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 23\n",
      "  012345\n",
      "F B---QB\n",
      "E BBR-B-\n",
      "D RR-BBB\n",
      "C -R--R-\n",
      "B RRRBB-\n",
      "A KR----\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 24\n",
      "  012345\n",
      "F B---QB\n",
      "E BBR-B-\n",
      "D RR-BBB\n",
      "C -R-RR-\n",
      "B RR-BB-\n",
      "A KR----\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "step 25\n",
      "  012345\n",
      "F B---BB\n",
      "E BBR-Q-\n",
      "D RR-BBB\n",
      "C -R-RR-\n",
      "B RR-BB-\n",
      "A KR----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 26\n",
      "  012345\n",
      "F B---BB\n",
      "E BBR-Q-\n",
      "D RR-BRB\n",
      "C -R-R--\n",
      "B RR-BB-\n",
      "A KR----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 27\n",
      "  012345\n",
      "F B---BB\n",
      "E BBR-Q-\n",
      "D RR-BRB\n",
      "C -R-R--\n",
      "B RR--B-\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 28\n",
      "  012345\n",
      "F B---BB\n",
      "E BBR-QR\n",
      "D RR-B-B\n",
      "C -R-R--\n",
      "B RR--B-\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 29\n",
      "  012345\n",
      "F B--B-B\n",
      "E BBR-QR\n",
      "D RR-B-B\n",
      "C -R-R--\n",
      "B RR--B-\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 30\n",
      "  012345\n",
      "F B--B-B\n",
      "E BBR-QR\n",
      "D RR-B-B\n",
      "C -R----\n",
      "B RR--R-\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 31\n",
      "  012345\n",
      "F B--B-B\n",
      "E BBR-QR\n",
      "D RRB--B\n",
      "C -R----\n",
      "B RR--R-\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 32\n",
      "  012345\n",
      "F B--B-B\n",
      "E BBR-QR\n",
      "D RRB--B\n",
      "C -RR---\n",
      "B R---R-\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 33\n",
      "  012345\n",
      "F B--B-B\n",
      "E B-B-QR\n",
      "D RRB--B\n",
      "C -RR---\n",
      "B R---R-\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 34\n",
      "  012345\n",
      "F B--B-B\n",
      "E B-B-QR\n",
      "D RRB--B\n",
      "C -RR---\n",
      "B R-----\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 35\n",
      "  012345\n",
      "F B-B--B\n",
      "E B-B-QR\n",
      "D RRB--B\n",
      "C -RR---\n",
      "B R-----\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 36\n",
      "  012345\n",
      "F B-B--B\n",
      "E B-B-QR\n",
      "D RRB--B\n",
      "C -RR---\n",
      "B RR----\n",
      "A K--R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 37\n",
      "  012345\n",
      "F BB---B\n",
      "E B-B-QR\n",
      "D RRB--B\n",
      "C -RR---\n",
      "B RR----\n",
      "A K--R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 38\n",
      "  012345\n",
      "F BB---B\n",
      "E B-R-QR\n",
      "D R-B--B\n",
      "C -RR---\n",
      "B RR----\n",
      "A K--R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 39\n",
      "  012345\n",
      "F BB---B\n",
      "E --R-QR\n",
      "D B-B--B\n",
      "C -RR---\n",
      "B RR----\n",
      "A K--R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 40\n",
      "  012345\n",
      "F BB---B\n",
      "E --R-QR\n",
      "D B-B--B\n",
      "C -RR---\n",
      "B RR--R-\n",
      "A K-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "step 41\n",
      "  012345\n",
      "F BB---B\n",
      "E --R--Q\n",
      "D B-B--B\n",
      "C -RR---\n",
      "B RR--R-\n",
      "A K-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,0)\n",
      "step 42\n",
      "  012345\n",
      "F BB---B\n",
      "E ---R-Q\n",
      "D B-B--B\n",
      "C -RR---\n",
      "B RR--R-\n",
      "A K-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,0)\n",
      "step 43\n",
      "  012345\n",
      "F BB--B-\n",
      "E ---R-Q\n",
      "D B-B--B\n",
      "C -RR---\n",
      "B RR--R-\n",
      "A K-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,0)\n",
      "step 44\n",
      "  012345\n",
      "F BB--B-\n",
      "E ---R-Q\n",
      "D B-B--B\n",
      "C -RR---\n",
      "B KR--R-\n",
      "A R-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "step 45\n",
      "  012345\n",
      "F BB-B--\n",
      "E ---R-Q\n",
      "D B-B--B\n",
      "C -RR---\n",
      "B KR--R-\n",
      "A R-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "step 46\n",
      "  012345\n",
      "F BB-B--\n",
      "E ---R-Q\n",
      "D B-B--B\n",
      "C -RR--R\n",
      "B KR----\n",
      "A R-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "step 47\n",
      "  012345\n",
      "F B--B--\n",
      "E -B-R-Q\n",
      "D B-B--B\n",
      "C -RR--R\n",
      "B KR----\n",
      "A R-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "step 48\n",
      "  012345\n",
      "F B--B--\n",
      "E -B-R-Q\n",
      "D B-B--R\n",
      "C -RR---\n",
      "B KR----\n",
      "A R-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "step 49\n",
      "  012345\n",
      "F ---B--\n",
      "E BB-R-Q\n",
      "D B-B--R\n",
      "C -RR---\n",
      "B KR----\n",
      "A R-----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "env = kac.KingAndCourtesanEnv(host='localhost', port=3, render_mode='human')\n",
    "\n",
    "_, _ = env.reset()\n",
    "\n",
    "for t in range(50):\n",
    "    print(\"step\", t)\n",
    "    action = env.sample_legal_action()\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Game Over\")\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlaL5J74YSvt"
   },
   "source": [
    "### Testing a random agent against ID Alpha-Beta agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4981,
     "status": "ok",
     "timestamp": 1741368302454,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "LpSLyocpYSvt",
    "outputId": "43048515-b112-4618-ddb9-821356d729e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "Connection attempt 1/3 failed: [Errno 111] Connection refused\n",
      "Retrying in 2 seconds...\n",
      "Connection attempt 2/3 failed: [Errno 111] Connection refused\n",
      "Retrying in 2 seconds...\n",
      "Connection attempt 3/3 failed: [Errno 111] Connection refused\n",
      "All connection attempts failed - will use random legal moves instead\n",
      "Random agent plays first (RED)\n",
      "ID Alpha-Beta agent plays second (BLUE)\n",
      "Move 0\n",
      "Random agent's turn\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 1\n",
      "ID Alpha-Beta agent's turn\n",
      "Error during game: ID Alpha-Beta agent is not connected to the server\n",
      "Connection to Java server closed\n",
      "\n",
      "Game Results:\n",
      "Winner: None\n",
      "Steps: 1\n",
      "Random played as: RED\n",
      "Alpha-Beta played as: BLUE\n"
     ]
    }
   ],
   "source": [
    "result = test_functions.test_random_vs_alphabeta(\n",
    "    env_port=3,\n",
    "    agent_port=9,\n",
    "    render_mode='human',\n",
    "    delay_between_moves=1.0,\n",
    "    response_timeout=50,\n",
    ")\n",
    "\n",
    "print(\"\\nGame Results:\")\n",
    "print(f\"Winner: {result['winner']}\")\n",
    "print(f\"Steps: {result['steps']}\")\n",
    "print(f\"Random played as: {result['random_player_role']}\")\n",
    "print(f\"Alpha-Beta played as: {result['alphabeta_player_role']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjsGflMHYSvt"
   },
   "source": [
    "## 2. Deep value-based Reinforcement Learning with Deep Q-Networks (DQN)\n",
    "## Deep Q-Networks v2 (DQN version 2015) with infrequent weight updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q6-LDE3YSvt"
   },
   "source": [
    "## 2.1. The Q-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1742281498766,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "ex7owrPiYSvu"
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Q-Network for King and Courtesan game.\"\"\"\n",
    "\n",
    "    def __init__(self, board_size=6, action_space_size=None):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        # Input: 6 channels representing the board state\n",
    "        self.board_size = board_size\n",
    "        if action_space_size is None:\n",
    "            self.action_space_size = board_size * board_size * board_size * board_size\n",
    "        else:\n",
    "            self.action_space_size = action_space_size\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(6, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Calculate the size after convolutions\n",
    "        conv_output_size = 128 * board_size * board_size\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(conv_output_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, self.action_space_size)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with batch normalization and ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Output layer (no activation, as we want raw Q-values)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_params(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the parameters.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            The parameters of the model.\n",
    "        \"\"\"\n",
    "        # return self.params.copy()\n",
    "        return torch.nn.utils.parameters_to_vector(self.parameters()).detach().cpu().numpy()\n",
    "\n",
    "    def set_params(self, params: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Set the parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : np.ndarray\n",
    "            The parameters of the model.\n",
    "        \"\"\"\n",
    "        #self.params = params.copy()\n",
    "        flat_params = torch.tensor(params, dtype=torch.float32).to(device)\n",
    "        torch.nn.utils.vector_to_parameters(flat_params, self.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNm0xFZ2YSvu"
   },
   "source": [
    "### 2.1.1 Inference Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48bfSY_PYSvu"
   },
   "source": [
    "#### Testing on the untrained agent against itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kS1wAmwLYSvu"
   },
   "outputs": [],
   "source": [
    "render_mode = 'human'\n",
    "num_episodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uo5ob_kKYSvu",
    "outputId": "ed6d09a0-a07d-4c86-b278-06b1673e79ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "Starting Q-Network vs Q-Network test...\n",
      "Board size: 6x6\n",
      "Adversary plays first (RED)\n",
      "Main agent plays second (BLUE)\n",
      "Move 1, Player: RED\n",
      "Selected move: E0-F1\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 2, Player: BLUE\n",
      "Selected move: F2-F1\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 3, Player: RED\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 4, Player: BLUE\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E --BBBB\n",
      "D RR--BB\n",
      "C RRRBBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 5, Player: RED\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E --BBBB\n",
      "D RR--BB\n",
      "C RRRBBB\n",
      "B RRRR-B\n",
      "A KR-RR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 6, Player: BLUE\n",
      "Selected move: B5-A4\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E --BBBB\n",
      "D RR--BB\n",
      "C RRRBBB\n",
      "B RRRR--\n",
      "A KR-RB-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 7, Player: RED\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E --BBBB\n",
      "D RR--BB\n",
      "C RRRBBB\n",
      "B RRRR--\n",
      "A K-RRB-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "Move 8, Player: BLUE\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F -B-BQB\n",
      "E --BBBB\n",
      "D RR--BB\n",
      "C RRRBBB\n",
      "B RRRR--\n",
      "A K-RRB-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 9, Player: RED\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RBBBB\n",
      "D R---BB\n",
      "C RRRBBB\n",
      "B RRRR--\n",
      "A K-RRB-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 10, Player: BLUE\n",
      "Selected move: A4-A3\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RBBBB\n",
      "D R---BB\n",
      "C RRRBBB\n",
      "B RRRR--\n",
      "A K-RB--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 11, Player: RED\n",
      "Selected move: B2-A3\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RBBBB\n",
      "D R---BB\n",
      "C RRRBBB\n",
      "B RR-R--\n",
      "A K-RR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 12, Player: BLUE\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R--BBB\n",
      "C RRRBBB\n",
      "B RR-R--\n",
      "A K-RR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 13, Player: RED\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R--BBB\n",
      "C RRRBBB\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 14, Player: BLUE\n",
      "Selected move: C3-C2\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R--BBB\n",
      "C RRB-BB\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 15, Player: RED\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R--BBB\n",
      "C R-R-BB\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 16, Player: BLUE\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R-RBBB\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "Move 17, Player: RED\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R-RBBB\n",
      "B RRRR--\n",
      "A -K-R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,1)\n",
      "Move 18, Player: BLUE\n",
      "Selected move: C3-C2\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R-B-BB\n",
      "B RRRR--\n",
      "A -K-R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,1)\n",
      "Move 19, Player: RED\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R-B-BB\n",
      "B RKRR--\n",
      "A -R-R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 20, Player: BLUE\n",
      "Selected move: C2-B2\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R---BB\n",
      "B RKBR--\n",
      "A -R-R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 21, Player: RED\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R---BB\n",
      "B RKBR--\n",
      "A --RR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 22, Player: BLUE\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R---BB\n",
      "B RK-B--\n",
      "A --RR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 23, Player: RED\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R---BB\n",
      "B RKRB--\n",
      "A ---R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 24, Player: BLUE\n",
      "Selected move: B3-A3\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R---BB\n",
      "B RKR---\n",
      "A ---B--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 25, Player: RED\n",
      "Selected move: B2-A3\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -RB-BB\n",
      "D R---BB\n",
      "C R---BB\n",
      "B RK----\n",
      "A ---R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 26, Player: BLUE\n",
      "Selected move: E2-D1\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -R--BB\n",
      "D RB--BB\n",
      "C R---BB\n",
      "B RK----\n",
      "A ---R--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 27, Player: RED\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -R--BB\n",
      "D RB--BB\n",
      "C R---BB\n",
      "B RK--R-\n",
      "A ------\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 28, Player: BLUE\n",
      "Selected move: D1-C1\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -R--BB\n",
      "D R---BB\n",
      "C RB--BB\n",
      "B RK--R-\n",
      "A ------\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 29, Player: RED\n",
      "Selected move: B4-C4\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -R--BB\n",
      "D R---BB\n",
      "C RB--RB\n",
      "B RK----\n",
      "A ------\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 30, Player: BLUE\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -R--BB\n",
      "D R---B-\n",
      "C RB--BB\n",
      "B RK----\n",
      "A ------\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 31, Player: RED\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F -B-BQB\n",
      "E -R--BB\n",
      "D R---B-\n",
      "C -R--BB\n",
      "B RK----\n",
      "A ------\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 32, Player: BLUE\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -R--QB\n",
      "D R---B-\n",
      "C -R--BB\n",
      "B RK----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 33, Player: RED\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -R--QB\n",
      "D R---B-\n",
      "C --R-BB\n",
      "B RK----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 34, Player: BLUE\n",
      "Selected move: F3-E2\n",
      "  012345\n",
      "F -B--BB\n",
      "E -RB-QB\n",
      "D R---B-\n",
      "C --R-BB\n",
      "B RK----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 35, Player: RED\n",
      "Selected move: B0-C0\n",
      "  012345\n",
      "F -B--BB\n",
      "E -RB-QB\n",
      "D R---B-\n",
      "C R-R-BB\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 36, Player: BLUE\n",
      "Selected move: F1-E1\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R---B-\n",
      "C R-R-BB\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 37, Player: RED\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R---B-\n",
      "C R--RBB\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 38, Player: BLUE\n",
      "Selected move: F4-E3\n",
      "  012345\n",
      "F -----B\n",
      "E -BBBQB\n",
      "D R---B-\n",
      "C R--RBB\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 39, Player: RED\n",
      "Selected move: C3-D3\n",
      "  012345\n",
      "F -----B\n",
      "E -BBBQB\n",
      "D R--RB-\n",
      "C R---BB\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 40, Player: BLUE\n",
      "Selected move: C4-D3\n",
      "  012345\n",
      "F -----B\n",
      "E -BBBQB\n",
      "D R--BB-\n",
      "C R----B\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 41, Player: RED\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F -----B\n",
      "E -BBBQB\n",
      "D R--BB-\n",
      "C -R---B\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 42, Player: BLUE\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F -----B\n",
      "E -BBBQB\n",
      "D R---B-\n",
      "C -R-B-B\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 43, Player: RED\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F -----B\n",
      "E -BBBQB\n",
      "D R---B-\n",
      "C --RB-B\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 44, Player: BLUE\n",
      "Selected move: C3-C2\n",
      "  012345\n",
      "F -----B\n",
      "E -BBBQB\n",
      "D R---B-\n",
      "C --B--B\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 45, Player: RED\n",
      "Selected move: D0-E0\n",
      "  012345\n",
      "F -----B\n",
      "E RBBBQB\n",
      "D ----B-\n",
      "C --B--B\n",
      "B -K----\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 46, Player: BLUE\n",
      "Selected move: C2-B2\n",
      "  012345\n",
      "F -----B\n",
      "E RBBBQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -KB---\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 47, Player: RED\n",
      "Selected move: E0-F1\n",
      "  012345\n",
      "F -R---B\n",
      "E -BBBQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -KB---\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 48, Player: BLUE\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BBBQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -KB---\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 49, Player: RED\n",
      "Selected move: F1-F2\n",
      "  012345\n",
      "F --R-B-\n",
      "E -BBBQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -KB---\n",
      "A ------\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 50, Player: BLUE\n",
      "Selected move: B2-A1\n",
      "  012345\n",
      "F --R-B-\n",
      "E -BBBQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -K----\n",
      "A -B----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 51, Player: RED\n",
      "Selected move: F2-E2\n",
      "  012345\n",
      "F ----B-\n",
      "E -BRBQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -K----\n",
      "A -B----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 52, Player: BLUE\n",
      "Selected move: A1-A0\n",
      "  012345\n",
      "F ----B-\n",
      "E -BRBQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -K----\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 53, Player: RED\n",
      "Selected move: E2-F2\n",
      "  012345\n",
      "F --R-B-\n",
      "E -B-BQB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -K----\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 54, Player: BLUE\n",
      "Selected move: E3-F2\n",
      "  012345\n",
      "F --B-B-\n",
      "E -B--QB\n",
      "D ----B-\n",
      "C -----B\n",
      "B -K----\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "Move 55, Player: RED\n",
      "Selected move: B1-C1\n",
      "  012345\n",
      "F --B-B-\n",
      "E -B--QB\n",
      "D ----B-\n",
      "C -K---B\n",
      "B ------\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (2,1)\n",
      "Move 56, Player: BLUE\n",
      "Selected move: F2-F1\n",
      "  012345\n",
      "F -B--B-\n",
      "E -B--QB\n",
      "D ----B-\n",
      "C -K---B\n",
      "B ------\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (2,1)\n",
      "Move 57, Player: RED\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F -B--B-\n",
      "E -B--QB\n",
      "D ----B-\n",
      "C --K--B\n",
      "B ------\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (2,2)\n",
      "Move 58, Player: BLUE\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -B--B-\n",
      "E -B--QB\n",
      "D ----B-\n",
      "C --K---\n",
      "B ----B-\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (2,2)\n",
      "Move 59, Player: RED\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F -B--B-\n",
      "E -B--QB\n",
      "D ----B-\n",
      "C ---K--\n",
      "B ----B-\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (2,3)\n",
      "Move 60, Player: BLUE\n",
      "Selected move: B4-C3\n",
      "  012345\n",
      "F -B--B-\n",
      "E -B--QB\n",
      "D ----B-\n",
      "C ---B--\n",
      "B ------\n",
      "A B-----\n",
      "BLUE KING Position: (4,4)\n",
      "\n",
      "Game Over!\n",
      "Winner: BLUE\n",
      "Connection to Java server closed\n",
      "\n",
      "Game Results:\n",
      "Winner: BLUE\n",
      "Steps: 60\n",
      "Main Network played as: BLUE\n",
      "Adversary Network played as: RED\n"
     ]
    }
   ],
   "source": [
    "# Initialize Q-Networks\n",
    "q_network = QNetwork(board_size=BOARD_SIZE).to(device)\n",
    "q_network_adversary = QNetwork(board_size=BOARD_SIZE).to(device)\n",
    "\n",
    "print(f\"Starting Q-Network vs Q-Network test...\")\n",
    "print(f\"Board size: {BOARD_SIZE}x{BOARD_SIZE}\")\n",
    "\n",
    "# Run test\n",
    "stats = test_functions.test_q_network_agent(\n",
    "    env_port=9,\n",
    "    q_network=q_network,\n",
    "    q_network_adversary=q_network_adversary,\n",
    "    num_episode=num_episodes,\n",
    "    render=(render_mode == 'human'),\n",
    ")\n",
    "\n",
    "print(\"\\nGame Results:\")\n",
    "print(f\"Winner: {stats['winner']}\")\n",
    "print(f\"Steps: {stats['steps']}\")\n",
    "print(f\"Main Network played as: {stats['main_network_role']}\")\n",
    "print(f\"Adversary Network played as: {stats['adversary_role']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww_jCh0OYSvu"
   },
   "source": [
    "#### Testing the untrained agent against random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejbcL7L4YSvu",
    "outputId": "b6b2a353-7fe9-4f63-bfea-f3fabb352ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "\n",
      "Episode 1/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B KRRR-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B KRRR--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F1-E0\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RR-RBB\n",
      "C RR-RBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RR-B-B\n",
      "C RR-RBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RR-B-B\n",
      "C R-RRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RR---B\n",
      "C R-RBBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RR---B\n",
      "C R-RBBB\n",
      "B KRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-D2\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B--BBB\n",
      "D RRB--B\n",
      "C R-RBBB\n",
      "B KRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B--BBB\n",
      "D RRBR-B\n",
      "C R--BBB\n",
      "B KRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D2-D3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B--BBB\n",
      "D RR-B-B\n",
      "C R--BBB\n",
      "B KRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E0\n",
      "  012345\n",
      "F --BBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C R--BBB\n",
      "B KRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-E5\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBQ\n",
      "D -R-B-B\n",
      "C R--BBB\n",
      "B KRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: B0-C0\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBQ\n",
      "D -R-B-B\n",
      "C K--BBB\n",
      "B RRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E5-D5\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBB\n",
      "D -R-B-Q\n",
      "C K--BBB\n",
      "B RRR-R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B5\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBB\n",
      "D -R-B-Q\n",
      "C K--BBB\n",
      "B RRR-RR\n",
      "A RRR--B\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBB\n",
      "D -RB--Q\n",
      "C K--BBB\n",
      "B RRR-RR\n",
      "A RRR--B\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: B4-A5\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBB\n",
      "D -RB--Q\n",
      "C K--BBB\n",
      "B RRR--R\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C4-B4\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBB\n",
      "D -RB--Q\n",
      "C K--B-B\n",
      "B RRR-BR\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: B5-B4\n",
      "  012345\n",
      "F --BBBB\n",
      "E R--BBB\n",
      "D -RB--Q\n",
      "C K--B-B\n",
      "B RRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 22\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F --BBBB\n",
      "E R---BB\n",
      "D -RBB-Q\n",
      "C K--B-B\n",
      "B RRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-R-BB\n",
      "D --BB-Q\n",
      "C K--B-B\n",
      "B RRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 24\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-E2\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-BB\n",
      "D --B--Q\n",
      "C K--B-B\n",
      "B RRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: B4-B5\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-BB\n",
      "D --B--Q\n",
      "C K--B-B\n",
      "B RRR--R\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 26\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F3-E3\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BBBB\n",
      "D --B--Q\n",
      "C K--B-B\n",
      "B RRR--R\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F0\n",
      "  012345\n",
      "F R-B-BB\n",
      "E --BBBB\n",
      "D --B--Q\n",
      "C K--B-B\n",
      "B RRR--R\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 28\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F R-B-BB\n",
      "E --B-BB\n",
      "D --BB-Q\n",
      "C K--B-B\n",
      "B RRR--R\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: F0-F1\n",
      "  012345\n",
      "F -RB-BB\n",
      "E --B-BB\n",
      "D --BB-Q\n",
      "C K--B-B\n",
      "B RRR--R\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 30\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F -RB-BB\n",
      "E --B-BB\n",
      "D --BB-Q\n",
      "C K--BB-\n",
      "B RRR--R\n",
      "A RRR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: A2-A3\n",
      "  012345\n",
      "F -RB-BB\n",
      "E --B-BB\n",
      "D --BB-Q\n",
      "C K--BB-\n",
      "B RRR--R\n",
      "A RR-R-R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 32\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F -RB-BB\n",
      "E --B--B\n",
      "D --BBBQ\n",
      "C K--BB-\n",
      "B RRR--R\n",
      "A RR-R-R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: B5-C4\n",
      "  012345\n",
      "F -RB-BB\n",
      "E --B--B\n",
      "D --BBBQ\n",
      "C K--BR-\n",
      "B RRR---\n",
      "A RR-R-R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 34\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F -RB-B-\n",
      "E --B-BB\n",
      "D --BBBQ\n",
      "C K--BR-\n",
      "B RRR---\n",
      "A RR-R-R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F -RB-B-\n",
      "E --B-BB\n",
      "D --BBBQ\n",
      "C K--R--\n",
      "B RRR---\n",
      "A RR-R-R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 36\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F -RB-B-\n",
      "E --B-BB\n",
      "D --B-BQ\n",
      "C K--B--\n",
      "B RRR---\n",
      "A RR-R-R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: A3-A4\n",
      "  012345\n",
      "F -RB-B-\n",
      "E --B-BB\n",
      "D --B-BQ\n",
      "C K--B--\n",
      "B RRR---\n",
      "A RR--RR\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 38\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F -RB-B-\n",
      "E --B-BB\n",
      "D --BB-Q\n",
      "C K--B--\n",
      "B RRR---\n",
      "A RR--RR\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,0)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F -RB-B-\n",
      "E --B-BB\n",
      "D --BB-Q\n",
      "C -K-B--\n",
      "B RRR---\n",
      "A RR--RR\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 40\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BB-BB\n",
      "D --BB-Q\n",
      "C -K-B--\n",
      "B RRR---\n",
      "A RR--RR\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B5\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BB-BB\n",
      "D --BB-Q\n",
      "C -K-B--\n",
      "B RRR--R\n",
      "A RR---R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 42\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D2-D1\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BB-BB\n",
      "D -B-B-Q\n",
      "C -K-B--\n",
      "B RRR--R\n",
      "A RR---R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BB-BB\n",
      "D -B-B-Q\n",
      "C -K-B--\n",
      "B RRR--R\n",
      "A R-R--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 44\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BB-BB\n",
      "D -BB--Q\n",
      "C -K-B--\n",
      "B RRR--R\n",
      "A R-R--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BB-BB\n",
      "D -BB--Q\n",
      "C -K-B--\n",
      "B RRR--R\n",
      "A -RR--R\n",
      "BLUE KING Position: (3,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 46\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D1-C1\n",
      "  012345\n",
      "F -R--B-\n",
      "E -BB-BB\n",
      "D --B--Q\n",
      "C -B-B--\n",
      "B RRR--R\n",
      "A -RR--R\n",
      "BLUE KING Position: (3,5)\n",
      "\n",
      "\n",
      "Game Over! Winner: q_network\n",
      "\n",
      "Episode 2/5\n",
      "Q-Network plays first (RED)\n",
      "Random agent plays second (BLUE)\n",
      "\n",
      "Move 1\n",
      "Player: Q-Network (RED)\n",
      "Selected move: E0-F0\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E --BBBB\n",
      "D RRB-BB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E --BBBB\n",
      "D RRB-BB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Random (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E --BBBB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRRBB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A3-A4\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E --BBBB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRRBB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Random (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E --BBBB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRRB-\n",
      "A KRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E --BBBB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRRR-\n",
      "A KRR--B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F RBBBBB\n",
      "E --BBQB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRRR-\n",
      "A KRR--B\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B4-B5\n",
      "  012345\n",
      "F RBBBBB\n",
      "E --BBQB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRR-R\n",
      "A KRR--B\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Random (BLUE)\n",
      "Selected move: F1-E1\n",
      "  012345\n",
      "F R-BBBB\n",
      "E -BBBQB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRR-R\n",
      "A KRR--B\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Q-Network (RED)\n",
      "Selected move: F0-F1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -BBBQB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B RRRR-R\n",
      "A KRR--B\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Random (BLUE)\n",
      "Selected move: D5-C5\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -BBBQB\n",
      "D RRB-B-\n",
      "C RRR-BB\n",
      "B RRRR-R\n",
      "A KRR--B\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -BBBQB\n",
      "D RRB-B-\n",
      "C RRR-BB\n",
      "B RKRR-R\n",
      "A RRR--B\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 14\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -BBBBB\n",
      "D RRB-Q-\n",
      "C RRR-BB\n",
      "B RKRR-R\n",
      "A RRR--B\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 15\n",
      "Player: Q-Network (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D R-B-Q-\n",
      "C RRR-BB\n",
      "B RKRR-R\n",
      "A RRR--B\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 16\n",
      "Player: Random (BLUE)\n",
      "Selected move: A5-A4\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D R-B-Q-\n",
      "C RRR-BB\n",
      "B RKRR-R\n",
      "A RRR-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 17\n",
      "Player: Q-Network (RED)\n",
      "Selected move: C0-D1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D RRB-Q-\n",
      "C -RR-BB\n",
      "B RKRR-R\n",
      "A RRR-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 18\n",
      "Player: Random (BLUE)\n",
      "Selected move: D2-D1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D RB--Q-\n",
      "C -RR-BB\n",
      "B RKRR-R\n",
      "A RRR-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 19\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A2-A3\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D RB--Q-\n",
      "C -RR-BB\n",
      "B RKRR-R\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 20\n",
      "Player: Random (BLUE)\n",
      "Selected move: D1-C2\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D R---Q-\n",
      "C -RB-BB\n",
      "B RKRR-R\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 21\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A3-A4\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D R---Q-\n",
      "C -RB-BB\n",
      "B RKRR-R\n",
      "A RR--R-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 22\n",
      "Player: Random (BLUE)\n",
      "Selected move: C2-C1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D R---Q-\n",
      "C -B--BB\n",
      "B RKRR-R\n",
      "A RR--R-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 23\n",
      "Player: Q-Network (RED)\n",
      "Selected move: D0-C1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBBBB\n",
      "D ----Q-\n",
      "C -R--BB\n",
      "B RKRR-R\n",
      "A RR--R-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 24\n",
      "Player: Random (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -B-BBB\n",
      "D ----Q-\n",
      "C -R--BB\n",
      "B RKRR-R\n",
      "A RR--R-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 25\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -B-BBB\n",
      "D ----Q-\n",
      "C -R--RB\n",
      "B RKR--R\n",
      "A RR--R-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 26\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -B-BBB\n",
      "D ------\n",
      "C -R-QRB\n",
      "B RKR--R\n",
      "A RR--R-\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 27\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B1-B2\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -B-BBB\n",
      "D ------\n",
      "C -R-QRB\n",
      "B RRK--R\n",
      "A RR--R-\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 28\n",
      "Player: Random (BLUE)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -B-BBB\n",
      "D ------\n",
      "C -R-QB-\n",
      "B RRK--R\n",
      "A RR--R-\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 29\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -B-BBB\n",
      "D ------\n",
      "C -R-KB-\n",
      "B RR---R\n",
      "A RR--R-\n",
      "RED KING Position: (2,3)\n",
      "\n",
      "Game Over! Winner: q_network\n",
      "\n",
      "Episode 3/5\n",
      "Q-Network plays first (RED)\n",
      "Random agent plays second (BLUE)\n",
      "\n",
      "Move 1\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F -BBBBB\n",
      "E R-BBQB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Q-Network (RED)\n",
      "Selected move: E0-F0\n",
      "  012345\n",
      "F RBBBBB\n",
      "E --BBQB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Random (BLUE)\n",
      "Selected move: E2-D1\n",
      "  012345\n",
      "F RBBBBB\n",
      "E ---BQB\n",
      "D RB-BBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Q-Network (RED)\n",
      "Selected move: C0-D1\n",
      "  012345\n",
      "F RBBBBB\n",
      "E ---BQB\n",
      "D RR-BBB\n",
      "C -RRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Random (BLUE)\n",
      "Selected move: F2-E2\n",
      "  012345\n",
      "F RB-BBB\n",
      "E --BBQB\n",
      "D RR-BBB\n",
      "C -RRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F RB-BBB\n",
      "E --BBQB\n",
      "D RR-BBB\n",
      "C -RRRBB\n",
      "B RR-RRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Random (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B--BBB\n",
      "E --BBQB\n",
      "D RR-BBB\n",
      "C -RRRBB\n",
      "B RR-RRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A3-A4\n",
      "  012345\n",
      "F B--BBB\n",
      "E --BBQB\n",
      "D RR-BBB\n",
      "C -RRRBB\n",
      "B RR-RRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Random (BLUE)\n",
      "Selected move: F0-E0\n",
      "  012345\n",
      "F ---BBB\n",
      "E B-BBQB\n",
      "D RR-BBB\n",
      "C -RRRBB\n",
      "B RR-RRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Q-Network (RED)\n",
      "Selected move: C3-D3\n",
      "  012345\n",
      "F ---BBB\n",
      "E B-BBQB\n",
      "D RR-RBB\n",
      "C -RR-BB\n",
      "B RR-RRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Random (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F ---BBB\n",
      "E BB-BQB\n",
      "D RR-RBB\n",
      "C -RR-BB\n",
      "B RR-RRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B4-B5\n",
      "  012345\n",
      "F ---BBB\n",
      "E BB-BQB\n",
      "D RR-RBB\n",
      "C -RR-BB\n",
      "B RR-R-R\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Random (BLUE)\n",
      "Selected move: C4-B4\n",
      "  012345\n",
      "F ---BBB\n",
      "E BB-BQB\n",
      "D RR-RBB\n",
      "C -RR--B\n",
      "B RR-RBR\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F ---BBB\n",
      "E BB-BQB\n",
      "D RR-RBB\n",
      "C -RR--B\n",
      "B RK-RBR\n",
      "A RRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 16\n",
      "Player: Random (BLUE)\n",
      "Selected move: E1-D0\n",
      "  012345\n",
      "F ---BBB\n",
      "E B--BQB\n",
      "D BR-RBB\n",
      "C -RR--B\n",
      "B RK-RBR\n",
      "A RRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 17\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F ---BBB\n",
      "E B--BQB\n",
      "D BR-RBB\n",
      "C -RR--B\n",
      "B RK-RRR\n",
      "A RRR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 18\n",
      "Player: Random (BLUE)\n",
      "Selected move: E3-E2\n",
      "  012345\n",
      "F ---BBB\n",
      "E B-B-QB\n",
      "D BR-RBB\n",
      "C -RR--B\n",
      "B RK-RRR\n",
      "A RRR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 19\n",
      "Player: Q-Network (RED)\n",
      "Selected move: C1-D0\n",
      "  012345\n",
      "F ---BBB\n",
      "E B-B-QB\n",
      "D RR-RBB\n",
      "C --R--B\n",
      "B RK-RRR\n",
      "A RRR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 20\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F ---BBB\n",
      "E B-B-BB\n",
      "D RR-RQB\n",
      "C --R--B\n",
      "B RK-RRR\n",
      "A RRR---\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 21\n",
      "Player: Q-Network (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F ---BBB\n",
      "E BRB-BB\n",
      "D R--RQB\n",
      "C --R--B\n",
      "B RK-RRR\n",
      "A RRR---\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 22\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F ---BBB\n",
      "E BRB-BB\n",
      "D R--Q-B\n",
      "C --R--B\n",
      "B RK-RRR\n",
      "A RRR---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 23\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B4-C5\n",
      "  012345\n",
      "F ---BBB\n",
      "E BRB-BB\n",
      "D R--Q-B\n",
      "C --R--R\n",
      "B RK-R-R\n",
      "A RRR---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 24\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F ---BBB\n",
      "E BRB--B\n",
      "D R--QBB\n",
      "C --R--R\n",
      "B RK-R-R\n",
      "A RRR---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 25\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A2-A3\n",
      "  012345\n",
      "F ---BBB\n",
      "E BRB--B\n",
      "D R--QBB\n",
      "C --R--R\n",
      "B RK-R-R\n",
      "A RR-R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 26\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F ---BBB\n",
      "E BRB--B\n",
      "D R---BB\n",
      "C --RQ-R\n",
      "B RK-R-R\n",
      "A RR-R--\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 27\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A3-A4\n",
      "  012345\n",
      "F ---BBB\n",
      "E BRB--B\n",
      "D R---BB\n",
      "C --RQ-R\n",
      "B RK-R-R\n",
      "A RR--R-\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 28\n",
      "Player: Random (BLUE)\n",
      "Selected move: E0-D0\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB--B\n",
      "D B---BB\n",
      "C --RQ-R\n",
      "B RK-R-R\n",
      "A RR--R-\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 29\n",
      "Player: Q-Network (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB--B\n",
      "D B---BB\n",
      "C --RQ-R\n",
      "B RK-RRR\n",
      "A RR----\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 30\n",
      "Player: Random (BLUE)\n",
      "Selected move: E2-D2\n",
      "  012345\n",
      "F ---BBB\n",
      "E -R---B\n",
      "D B-B-BB\n",
      "C --RQ-R\n",
      "B RK-RRR\n",
      "A RR----\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 31\n",
      "Player: Q-Network (RED)\n",
      "Selected move: B4-C4\n",
      "  012345\n",
      "F ---BBB\n",
      "E -R---B\n",
      "D B-B-BB\n",
      "C --RQRR\n",
      "B RK-R-R\n",
      "A RR----\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 32\n",
      "Player: Random (BLUE)\n",
      "Selected move: C3-C4\n",
      "  012345\n",
      "F ---BBB\n",
      "E -R---B\n",
      "D B-B-BB\n",
      "C --R-QR\n",
      "B RK-R-R\n",
      "A RR----\n",
      "BLUE KING Position: (2,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 33\n",
      "Player: Q-Network (RED)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F ---BBB\n",
      "E -R---B\n",
      "D B-B-BB\n",
      "C --R-R-\n",
      "B RK-R-R\n",
      "A RR----\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Game Over! Winner: q_network\n",
      "\n",
      "Episode 4/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F1-E0\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D RRRBBB\n",
      "C RR--BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-BBQB\n",
      "D RRRBBB\n",
      "C RR--BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: B5-C4\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-BBQB\n",
      "D RRRBBB\n",
      "C RR--RB\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-BBQB\n",
      "D RRRB-B\n",
      "C RR--BB\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E0\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-BBQB\n",
      "D R-RB-B\n",
      "C RR--BB\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-BBQB\n",
      "D R-R--B\n",
      "C RR-BBB\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-BBQB\n",
      "D R-R--B\n",
      "C R-RBBB\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-QB\n",
      "D R-RB-B\n",
      "C R-RBBB\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C1\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-QB\n",
      "D R-RB-B\n",
      "C RRRBBB\n",
      "B R-RR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-QB\n",
      "D R-B--B\n",
      "C RRRBBB\n",
      "B R-RR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: B3-B4\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-QB\n",
      "D R-B--B\n",
      "C RRRBBB\n",
      "B R-R-R-\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-QB\n",
      "D R-B--B\n",
      "C RRR-BB\n",
      "B R-RBR-\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: B4-B3\n",
      "  012345\n",
      "F --BBBB\n",
      "E R-B-QB\n",
      "D R-B--B\n",
      "C RRR-BB\n",
      "B R-RR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F3-E3\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BBQB\n",
      "D R-B--B\n",
      "C RRR-BB\n",
      "B R-RR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BBQB\n",
      "D R-B--B\n",
      "C RRR-RB\n",
      "B R-R---\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BBQB\n",
      "D R-B--B\n",
      "C RRR-B-\n",
      "B R-R---\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BBQB\n",
      "D R-B--B\n",
      "C RRR-B-\n",
      "B RRR---\n",
      "A K-RR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R-B-QB\n",
      "C RRR-B-\n",
      "B RRR---\n",
      "A K-RR--\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R-R-QB\n",
      "C RR--B-\n",
      "B RRR---\n",
      "A K-RR--\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 22\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R-RQ-B\n",
      "C RR--B-\n",
      "B RRR---\n",
      "A K-RR--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B3\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R-RQ-B\n",
      "C RR--B-\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 24\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R-R--B\n",
      "C RR-QB-\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: D2-D3\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R--R-B\n",
      "C RR-QB-\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 26\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C3-D3\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R--Q-B\n",
      "C RR--B-\n",
      "B RRRR--\n",
      "A K--R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F --B-BB\n",
      "E R-BB-B\n",
      "D R--Q-B\n",
      "C RR--B-\n",
      "B KRRR--\n",
      "A R--R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 28\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-BBBB\n",
      "D R--Q-B\n",
      "C RR--B-\n",
      "B KRRR--\n",
      "A R--R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-BBBB\n",
      "D R--Q-B\n",
      "C RRR-B-\n",
      "B K-RR--\n",
      "A R--R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 30\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C4-B4\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-BBBB\n",
      "D R--Q-B\n",
      "C RRR---\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F --B-B-\n",
      "E RRBBBB\n",
      "D ---Q-B\n",
      "C RRR---\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 32\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F --B-B-\n",
      "E RRBBBB\n",
      "D --Q--B\n",
      "C RRR---\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-RBBB\n",
      "D --Q--B\n",
      "C RRR---\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 34\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-R-BB\n",
      "D --QB-B\n",
      "C RRR---\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: C0-D0\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-R-BB\n",
      "D R-QB-B\n",
      "C -RR---\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 36\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D2-E2\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-Q-BB\n",
      "D R--B-B\n",
      "C -RR---\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-Q-BB\n",
      "D R--R-B\n",
      "C -R----\n",
      "B K-RRB-\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 38\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B4-B3\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-Q-BB\n",
      "D R--R-B\n",
      "C -R----\n",
      "B K-RB--\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: D0-D1\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-Q-BB\n",
      "D -R-R-B\n",
      "C -R----\n",
      "B K-RB--\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 40\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D3\n",
      "  012345\n",
      "F --B-B-\n",
      "E R-Q--B\n",
      "D -R-B-B\n",
      "C -R----\n",
      "B K-RB--\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F --B-B-\n",
      "E -RQ--B\n",
      "D -R-B-B\n",
      "C -R----\n",
      "B K-RB--\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 42\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F --B-B-\n",
      "E -RQ--B\n",
      "D -R---B\n",
      "C -R-B--\n",
      "B K-RB--\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F --B-B-\n",
      "E -RR--B\n",
      "D -----B\n",
      "C -R-B--\n",
      "B K-RB--\n",
      "A R--R--\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Game Over! Winner: random\n",
      "\n",
      "Episode 5/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B KRRR-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B KRRR--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C R-R-BB\n",
      "B KRRR--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRB-BB\n",
      "C R-R-BB\n",
      "B KRRR--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRB-BB\n",
      "C R-RRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRBB-B\n",
      "C R-RRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: D1-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D R-RB-B\n",
      "C R-RRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F1-E0\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D R-RB-B\n",
      "C R-RRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F --BBBQ\n",
      "E B-BBBB\n",
      "D R-RB-B\n",
      "C -RRRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-BBQB\n",
      "D R-RB-B\n",
      "C -RRRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-BBQB\n",
      "D RRRB-B\n",
      "C --RRBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-BBQB\n",
      "D RRR--B\n",
      "C --RBBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-BBQB\n",
      "D RRR--B\n",
      "C ---RBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F --BBBB\n",
      "E B-B-QB\n",
      "D RRRB-B\n",
      "C ---RBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F --BBBB\n",
      "E BRB-QB\n",
      "D R-RB-B\n",
      "C ---RBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F --BBBB\n",
      "E -BB-QB\n",
      "D R-RB-B\n",
      "C ---RBB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: C3-D4\n",
      "  012345\n",
      "F --BBBB\n",
      "E -BB-QB\n",
      "D R-RBRB\n",
      "C ----BB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F3-E3\n",
      "  012345\n",
      "F --B-BB\n",
      "E -BBBQB\n",
      "D R-RBRB\n",
      "C ----BB\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F --B-BB\n",
      "E -BBBQB\n",
      "D R-RBRB\n",
      "C ----BB\n",
      "B KR-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-D4\n",
      "  012345\n",
      "F --B-BB\n",
      "E -BBBQB\n",
      "D R-RBBB\n",
      "C ----B-\n",
      "B KR-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: B0-B1\n",
      "  012345\n",
      "F --B-BB\n",
      "E -BBBQB\n",
      "D R-RBBB\n",
      "C ----B-\n",
      "B RK-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 22\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F --B-BB\n",
      "E -BBBQB\n",
      "D R-R-BB\n",
      "C ---BB-\n",
      "B RK-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: B0-C0\n",
      "  012345\n",
      "F --B-BB\n",
      "E -BBBQB\n",
      "D R-R-BB\n",
      "C R--BB-\n",
      "B -K-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 24\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F --B-BB\n",
      "E -BBBQB\n",
      "D R-RB-B\n",
      "C R--BB-\n",
      "B -K-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E0\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D --RB-B\n",
      "C R--BB-\n",
      "B -K-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 26\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D --B--B\n",
      "C R--BB-\n",
      "B -K-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: C0-D0\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D R-B--B\n",
      "C ---BB-\n",
      "B -K-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 28\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C4-B4\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -K-RB-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -K-RR-\n",
      "A RRRR-B\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 30\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: A5-A4\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -K-RR-\n",
      "A RRRRB-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: A3-A4\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -K-RR-\n",
      "A RRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 32\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D R-B--B\n",
      "C ------\n",
      "B -K-BR-\n",
      "A RRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBBBQB\n",
      "D R-B--B\n",
      "C ------\n",
      "B -KRBR-\n",
      "A RR--R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 34\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBB-QB\n",
      "D R-BB-B\n",
      "C ------\n",
      "B -KRBR-\n",
      "A RR--R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBB-QB\n",
      "D R-BB-B\n",
      "C ------\n",
      "B -KRBR-\n",
      "A RR---R\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 36\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-C3\n",
      "  012345\n",
      "F --B-BB\n",
      "E RBB-QB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -KRBR-\n",
      "A RR---R\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F --B-BB\n",
      "E -RB-QB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -KRBR-\n",
      "A RR---R\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 38\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -KRBR-\n",
      "A RR---R\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: A5-B5\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -KRBRR\n",
      "A RR----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 40\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B3-A2\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -KR-RR\n",
      "A RRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: B1-B2\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B--B\n",
      "C ---B--\n",
      "B -RK-RR\n",
      "A RRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 42\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B---\n",
      "C ---BB-\n",
      "B -RK-RR\n",
      "A RRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B---\n",
      "C --RBB-\n",
      "B --K-RR\n",
      "A RRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 44\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C4-B4\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B---\n",
      "C --RB--\n",
      "B --K-BR\n",
      "A RRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: B2-A2\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B---\n",
      "C --RB--\n",
      "B ----BR\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 46\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B4-B5\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B---\n",
      "C --RB--\n",
      "B -----B\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 47\n",
      "Player: Random (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-QB\n",
      "D R-B---\n",
      "C --RB--\n",
      "B -R---B\n",
      "A R-K---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 48\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E5-D5\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-Q-\n",
      "D R-B--B\n",
      "C --RB--\n",
      "B -R---B\n",
      "A R-K---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 49\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F ----BB\n",
      "E -RB-Q-\n",
      "D --B--B\n",
      "C --RB--\n",
      "B -R---B\n",
      "A R-K---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 50\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D2-E1\n",
      "  012345\n",
      "F ----BB\n",
      "E -BB-Q-\n",
      "D -----B\n",
      "C --RB--\n",
      "B -R---B\n",
      "A R-K---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Test Results Summary:\n",
      "Episodes: 5\n",
      "Q-Network wins: 3 (60.0%)\n",
      "Random agent wins: 1 (20.0%)\n",
      "Ties: 0 (0.0%)\n",
      "Average steps per episode: 40.2\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "q_network = QNetwork(board_size=BOARD_SIZE).to(device)\n",
    "results = test_functions.test_q_network_vs_random(env_port=3, num_episodes=5, q_network=q_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h6A0iXkYSvv"
   },
   "source": [
    "### Epsilon Greedy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqMlTFCDYSvv"
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedy:\n",
    "    \"\"\"\n",
    "    An Epsilon-Greedy policy.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    epsilon : float\n",
    "        The initial probability of choosing a random action.\n",
    "    epsilon_min : float\n",
    "        The minimum probability of choosing a random action.\n",
    "    epsilon_decay : float\n",
    "        The decay rate for the epsilon value after each action.\n",
    "    env : gym.Env\n",
    "        The environment in which the agent is acting.\n",
    "    q_network : torch.nn.Module\n",
    "        The Q-Network used to estimate action values.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __call__(state: np.ndarray) -> np.int64\n",
    "        Select an action for the given state using the epsilon-greedy policy.\n",
    "    decay_epsilon()\n",
    "        Decay the epsilon value after each action.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            epsilon_start: float,\n",
    "            epsilon_min: float,\n",
    "            epsilon_decay: float,\n",
    "            env: gym.Env,\n",
    "            q_network: torch.nn.Module,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize a new instance of EpsilonGreedy.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epsilon_start : float\n",
    "            The initial probability of choosing a random action.\n",
    "        epsilon_min : float\n",
    "            The minimum probability of choosing a random action.\n",
    "        epsilon_decay : float\n",
    "            The decay rate for the epsilon value after each episode.\n",
    "        env : gym.Env\n",
    "            The environment in which the agent is acting.\n",
    "        q_network : torch.nn.Module\n",
    "            The Q-Network used to estimate action values.\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon_start\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.env = env\n",
    "        self.q_network = q_network\n",
    "\n",
    "    def __call__(self, state: torch.Tensor) -> np.int64:\n",
    "        \"\"\"\n",
    "        Select an action for the given state using the epsilon-greedy policy.\n",
    "\n",
    "        If a randomly chosen number is less than epsilon, a random action is chosen.\n",
    "        Otherwise, the action with the highest estimated action value is chosen.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : numpy.ndarray\n",
    "            The current state of the environment.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.int64\n",
    "            The chosen action.\n",
    "        \"\"\"\n",
    "\n",
    "        legal_moves = self.env.legal_moves\n",
    "\n",
    "        # Exploration: random legal move\n",
    "        if random.random() < self.epsilon:\n",
    "            # Randomly select from legal moves\n",
    "            return self.env._move_to_index(random.choice(legal_moves))\n",
    "\n",
    "        # Exploitation: best legal move based on Q-values\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                q_values = self.q_network(state_tensor)\n",
    "\n",
    "                # Create legal moves mask\n",
    "                mask = torch.ones_like(q_values) * float('-inf')\n",
    "                for move in legal_moves:\n",
    "                    move_idx = self.env._move_to_index(move)\n",
    "                    mask[0, move_idx] = 0\n",
    "\n",
    "                # Apply mask to get legal Q-values\n",
    "                masked_q_values = q_values + mask\n",
    "\n",
    "                # Find the maximum Q-value\n",
    "                max_q_value = masked_q_values.max().item()\n",
    "\n",
    "                # Find all indices that have the maximum Q-value\n",
    "                max_indices = torch.where(masked_q_values[0] == max_q_value)[0]\n",
    "\n",
    "                # Randomly select one of the max indices\n",
    "                selected_index = max_indices[torch.randint(0, len(max_indices), (1,))].item()\n",
    "\n",
    "        return selected_index\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        \"\"\"\n",
    "        Decay the epsilon value after each episode.\n",
    "\n",
    "        The new epsilon value is the maximum of `epsilon_min` and the product of the current\n",
    "        epsilon value and `epsilon_decay`.\n",
    "        \"\"\"\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpZVAe84YSvv"
   },
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAkTLMs-YSvv"
   },
   "outputs": [],
   "source": [
    "class MinimumExponentialLR(torch.optim.lr_scheduler.ExponentialLR):\n",
    "    def __init__(\n",
    "            self,\n",
    "            optimizer: torch.optim.Optimizer,\n",
    "            lr_decay: float,\n",
    "            last_epoch: int = -1,\n",
    "            min_lr: float = 1e-6,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize a new instance of MinimumExponentialLR.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        optimizer : torch.optim.Optimizer\n",
    "            The optimizer whose learning rate should be scheduled.\n",
    "        lr_decay : float\n",
    "            The multiplicative factor of learning rate decay.\n",
    "        last_epoch : int, optional\n",
    "            The index of the last epoch. Default is -1.\n",
    "        min_lr : float, optional\n",
    "            The minimum learning rate. Default is 1e-6.\n",
    "        \"\"\"\n",
    "        self.min_lr = min_lr\n",
    "        super().__init__(optimizer, lr_decay, last_epoch=-1)\n",
    "\n",
    "    def get_lr(self) -> List[float]:\n",
    "        \"\"\"\n",
    "        Compute learning rate using chainable form of the scheduler.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[float]\n",
    "            The learning rates of each parameter group.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            max(base_lr * self.gamma ** self.last_epoch, self.min_lr)\n",
    "            for base_lr in self.base_lrs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9L_8RUxYSvw"
   },
   "source": [
    "### 2.1.2. Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytiDZ4WcYSvw"
   },
   "source": [
    "To compute the target value, we can eliminate the need for an if statement to differentiate between terminal and non-terminal states by using the following formula:\n",
    "\n",
    "$$\n",
    "y = r + \\gamma \\max_{\\mathbf{a}^\\star \\in \\mathcal{A}} \\hat{Q}_{\\mathbf{\\omega}}(\\mathbf{s'})_{\\mathbf{a}^\\star} \\times (1 - \\text{done})\n",
    "$$\n",
    "\n",
    "where $\\text{done} = 1$ if $s'$ is a terminal state and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftiYWq13YSvw"
   },
   "source": [
    "### Replay Buffer\n",
    "\n",
    "Memory buffer where experiences are stored. We sample a random batch of experiences from this buffer to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcickLJeYSvw"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A Replay Buffer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    buffer : collections.deque\n",
    "        A double-ended queue where the transitions are stored.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    add(state: np.ndarray, action: np.int64, reward: float, next_state: np.ndarray, done: bool)\n",
    "        Add a new transition to the buffer.\n",
    "    sample(batch_size: int) -> Tuple[np.ndarray, float, float, np.ndarray, bool]\n",
    "        Sample a batch of transitions from the buffer.\n",
    "    __len__()\n",
    "        Return the current size of the buffer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int, env: kac.KingAndCourtesanEnv):\n",
    "        \"\"\"\n",
    "        Initializes a ReplayBuffer instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        capacity : int\n",
    "            The maximum number of transitions that can be stored in the buffer.\n",
    "        env : KingAndCourtesanEnv\n",
    "            The environment\n",
    "        \"\"\"\n",
    "        self.buffer: collections.deque = collections.deque(maxlen=capacity)\n",
    "        self.env = env\n",
    "        self.action_space_size = self.env.action_space.n\n",
    "\n",
    "    def add(\n",
    "            self,\n",
    "            state: torch.Tensor,\n",
    "            action: np.int64,\n",
    "            reward: float,\n",
    "            next_state: np.ndarray,\n",
    "            done: bool,\n",
    "            legal_moves\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Add a new transition to the buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : numpy.ndarray\n",
    "            The state array of the added state.\n",
    "        action : np.int64\n",
    "            The action of the added transition.\n",
    "        reward : float\n",
    "            The reward of the added transition.\n",
    "        next_state : numpy.ndarray\n",
    "            The next state vector of the added transition.\n",
    "        done : bool\n",
    "            The final state of the added transition.\n",
    "        legal_moves : list\n",
    "            The next legal moves\n",
    "        \"\"\"\n",
    "        if legal_moves is not None:\n",
    "            # Store move indices rather than move strings\n",
    "            legal_move_indices = [self.env._move_to_index(move) for move in legal_moves]\n",
    "            # legal moves actually correspond to the next state's legal moves, so adversary turn\n",
    "            legal_move_indices = set(range(self.action_space_size)) - set(legal_move_indices)\n",
    "            self.buffer.append((state, action, reward, next_state, done, list(legal_move_indices)))\n",
    "\n",
    "        else:\n",
    "            self.buffer.append((state, action, reward, next_state, done, []))\n",
    "\n",
    "    def sample(\n",
    "            self, batch_size: int\n",
    "    ) -> Tuple[np.ndarray, Tuple[int], Tuple[float], np.ndarray, Tuple[bool]]:\n",
    "        \"\"\"\n",
    "        Sample a batch of transitions from the buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            The number of transitions to sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, float, float, np.ndarray, bool, List[int]]\n",
    "            A batch of `batch_size` transitions.\n",
    "        \"\"\"\n",
    "        # Here, `random.sample(self.buffer, batch_size)`\n",
    "        # returns a list of tuples `(state, action, reward, next_state, done)`\n",
    "        # where:\n",
    "        # - `state`  and `next_state` are numpy arrays\n",
    "        # - `action` and `reward` are floats\n",
    "        # - `done` is a boolean\n",
    "        #\n",
    "        # `states, actions, rewards, next_states, dones = zip(*random.sample(self.buffer, batch_size))`\n",
    "        # generates 5 tuples `state`, `action`, `reward`, `next_state` and `done`, each having `batch_size` elements.\n",
    "        samples = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones, legal_moves_batch = zip(*samples)\n",
    "\n",
    "        # Convert to tensors\n",
    "        states = torch.FloatTensor(np.array(states)).to(device)\n",
    "        actions = torch.LongTensor(actions).to(device)\n",
    "        rewards = torch.FloatTensor(rewards).to(device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(device)\n",
    "        dones = torch.FloatTensor(dones).to(device)\n",
    "\n",
    "        # Create legal moves mask tensor (batch_size x action_space_size)\n",
    "        # Initialize with large negative value to mask illegal moves\n",
    "        legal_moves_mask = torch.ones((batch_size, self.action_space_size), device=device) * float('-inf')\n",
    "\n",
    "        # Fill in mask for each sample in batch\n",
    "        for i, moves in enumerate(legal_moves_batch):\n",
    "            if moves:  # Check if we have legal moves stored\n",
    "                legal_moves_mask[i, moves] = 0  # Set 0 for legal moves\n",
    "\n",
    "        return states, actions, rewards, next_states, dones, legal_moves_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the current size of the buffer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The current size of the buffer.\n",
    "        \"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX6S66e3YSvw"
   },
   "source": [
    "In 2015, DeepMind further advanced the field of reinforcement learning with the publication of the paper \"Human-level control through deep reinforcement learning\" by Volodymyr Mnih and colleagues (https://www.nature.com/articles/nature14236). This work introduced the second version of Deep Q-Networks (DQN).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jeremiedecock/polytechnique-csc-52081-ep-2025-students/main/assets/lab6_dqn_nature_journal.jpg\" width=\"200px\" />\n",
    "\n",
    "The key contribution of this paper was the introduction of a method to stabilize the learning process by infrequently updating the target weights. This technique, known as *infrequent updates of target weights*, significantly improved the stability of the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGc5JnncYSvw"
   },
   "source": [
    "#### Infrequent weight updates\n",
    "\n",
    "Infrequent weight updates, also known as the use of a target network, is a technique used in Deep Q-Networks (DQN) to address the issue of learning from a moving target.\n",
    "\n",
    "In a typical DQN setup, there are two neural networks: the Q-network and the target network. The Q-network is used to predict the Q-values and is updated at every time step. The target network is used to compute the target Q-values for the update, and its weights are updated less frequently, typically every few thousand steps, by copying the weights from the Q-network.\n",
    "\n",
    "The idea behind infrequent weight updates is to stabilize the learning process by keeping the target Q-values fixed for a number of steps. This mitigates the issue of learning from a moving target, as the target Q-values remain fixed between updates.\n",
    "\n",
    "Without infrequent weight updates, both the predicted and target Q-values would change at every step, which could lead to oscillations and divergence in the learning process. By introducing a delay between updates of the target Q-values, the risk of such oscillations is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMN70UHXYSvw"
   },
   "source": [
    "#### DQN v2015 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-dN4XVAYSvx"
   },
   "source": [
    "Note: main differences with the previous algorithm are highlighted in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qhh0_TSVYSvx"
   },
   "source": [
    "<b>Input</b>:<br>\n",
    "\t$\\quad\\quad$ none<br>\n",
    "<b>Algorithm parameter</b>:<br>\n",
    "\t$\\quad\\quad$ discount factor $\\gamma$<br>\n",
    "\t$\\quad\\quad$ step size $\\alpha \\in (0,1]$<br>\n",
    "\t$\\quad\\quad$ small $\\epsilon > 0$<br>\n",
    "\t$\\quad\\quad$ capacity of the experience replay memory $M$<br>\n",
    "\t$\\quad\\quad$ batch size $m$<br>\n",
    "\t$\\quad\\quad$ target network update frequency $\\color{red}{\\tau}$<br><br>\n",
    "\n",
    "<b>Initialize</b> replay memory $\\mathcal{D}$ to capacity $M$<br>\n",
    "<b>Initialize</b> action-value function $\\hat{Q}_{\\mathbf{\\omega_1}}$ with random weights $\\mathbf{\\omega_1}$<br>\n",
    "<b>Initialize</b> target action-value function $\\hat{Q}_{\\mathbf{\\omega_2}}$ with weights $\\color{red}{\\mathbf{\\omega_2} = \\mathbf{\\omega_1}}$<br><br>\n",
    "\n",
    "<b>FOR EACH</b> episode<br>\n",
    "\t$\\quad$ $\\mathbf{s} \\leftarrow \\text{env.reset}()$<br>\n",
    "\t$\\quad$ <b>DO</b> <br>\n",
    "\t\t$\\quad\\quad$ $\\mathbf{a} \\leftarrow \\epsilon\\text{-greedy}(\\mathbf{s}, \\hat{Q}_{\\mathbf{\\omega_1}})$<br>\n",
    "\t\t$\\quad\\quad$ $r, \\mathbf{s'} \\leftarrow \\text{env.step}(\\mathbf{a})$<br>\n",
    "\t\t$\\quad\\quad$ Store transition $(\\mathbf{s}, \\mathbf{a}, r, \\mathbf{s'})$ in $\\mathcal{D}$<br>\n",
    "\t\t$\\quad\\quad$ If $\\mathcal{D}$ contains \"enough\" transitions<br>\n",
    "\t\t\t$\\quad\\quad\\quad$ Sample random batch of transitions $(\\mathbf{s}_j, \\mathbf{a}_j, r_j, \\mathbf{s'}_j)$ from $\\mathcal{D}$ with $j=1$ to $m$<br>\n",
    "\t\t\t$\\quad\\quad\\quad$ For each $j$, set $y_j =\n",
    "\t\t\t\\begin{cases}\n",
    "\t\t\tr_j & \\text{for terminal } \\mathbf{s'}_j\\\\\n",
    "\t\t\tr_j + \\gamma \\max_{\\mathbf{a}^\\star} \\hat{Q}_{\\mathbf{\\omega_{\\color{red}{2}}}} (\\mathbf{s'}_j)_{\\mathbf{a}^\\star} & \\text{for non-terminal } \\mathbf{s'}_j\n",
    "\t\t\t\\end{cases}$<br>\n",
    "\t\t\t$\\quad\\quad\\quad$ Perform a gradient descent step on $\\left( y_j - \\hat{Q}_{\\mathbf{\\omega_1}}(\\mathbf{s}_j)_{\\mathbf{a}_j} \\right)^2$ with respect to the weights $\\mathbf{\\omega_1}$<br>\n",
    "\t\t\t$\\quad\\quad\\quad$ Every $\\color{red}{\\tau}$ steps reset $\\hat{Q}_{\\mathbf{\\omega_2}}$ to $\\hat{Q}_{\\mathbf{\\omega_1}}$, i.e., set $\\color{red}{\\mathbf{\\omega_2} \\leftarrow \\mathbf{\\omega_1}}$<br>\n",
    "\t\t$\\quad\\quad$ $\\mathbf{s} \\leftarrow \\mathbf{s'}$ <br>\n",
    "\t$\\quad$ <b>UNTIL</b> $\\mathbf{s}$ is final<br><br>\n",
    "<b>RETURN</b> $\\mathbf{\\omega_1}$ <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmsuPeOxYSvx"
   },
   "source": [
    "Infrequent weight updates in the training function:\n",
    "\n",
    "1. **Update the Target Network Infrequently**: Instead of updating the weights of the target network at every time step, update them less frequently, for example, every few thousand steps. The weights of the target network are updated by copying the weights from the Q-network.\n",
    "\n",
    "2. **Compute Target Q-values with the Target Network**: When computing the target Q-values for the update, use the target network instead of the Q-network. This ensures that the target Q-values remain fixed between updates, which stabilizes the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn2_agent(\n",
    "        env,\n",
    "        q_network,\n",
    "        q_network_adversary,\n",
    "        target_q_network,\n",
    "        target_q_network_adversary,\n",
    "        optimizer,\n",
    "        optimizer_adversary,\n",
    "        loss_fn,\n",
    "        epsilon_greedy,\n",
    "        epsilon_greedy_adversary=None,  # Added parameter for adversary's exploration policy\n",
    "        lr_scheduler=None,\n",
    "        lr_scheduler_adversary=None,\n",
    "        num_episodes=5000,\n",
    "        gamma=0.99,\n",
    "        batch_size=256,\n",
    "        replay_buffer=None,\n",
    "        replay_buffer_adversary=None,\n",
    "        target_q_network_sync_period=1000,\n",
    "        grad_clip=10.0,  # Added gradient clipping\n",
    "        double_q=True,  # Added Double-Q learning option\n",
    "        soft_update=False,  # Added soft update option\n",
    "        tau=0.005,  # Polyak averaging factor for soft updates\n",
    "        init_exploration_steps=5000,  # Initial random exploration steps\n",
    "        reward_scale=1.0,  # Reward scaling factor\n",
    "        eval_frequency=100,  # How often to evaluate and print\n",
    "        checkpoint_dir='checkpoints/dqnv2',\n",
    "        checkpoint_frequency=50,\n",
    "        save_best_only=False,\n",
    "        verbose=True,\n",
    "        heuristic_scale=0.3,  # Scaling for heuristic-based rewards\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced DQN agent training with self-play and additional optimizations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    env : KingAndCourtesanEnv\n",
    "        The game environment\n",
    "    q_network, q_network_adversary : QNetwork\n",
    "        The main and adversary Q-Networks\n",
    "    target_q_network, target_q_network_adversary : QNetwork\n",
    "        Target networks for more stable learning\n",
    "    optimizer, optimizer_adversary : torch.optim.Optimizer\n",
    "        Optimizers for both networks\n",
    "    loss_fn : callable\n",
    "        Loss function for training\n",
    "    epsilon_greedy, epsilon_greedy_adversary : EpsilonGreedy\n",
    "        Exploration policies for both agents\n",
    "    device : torch.device\n",
    "        Device for computation\n",
    "    lr_scheduler, lr_scheduler_adversary : torch.optim.lr_scheduler\n",
    "        Learning rate schedulers\n",
    "    num_episodes : int\n",
    "        Number of training episodes\n",
    "    gamma : float\n",
    "        Discount factor\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    replay_buffer, replay_buffer_adversary : ReplayBuffer\n",
    "        Experience replay buffers for both agents\n",
    "    target_q_network_sync_period : int\n",
    "        How often to update target networks\n",
    "    grad_clip : float\n",
    "        Maximum gradient norm for clipping\n",
    "    double_q : bool\n",
    "        Whether to use Double-Q learning\n",
    "    soft_update : bool\n",
    "        Whether to use soft updates for target networks\n",
    "    tau : float\n",
    "        Soft update interpolation factor\n",
    "    init_exploration_steps : int\n",
    "        Number of initial steps with purely random actions\n",
    "    reward_scale : float\n",
    "        Factor to scale rewards by\n",
    "    eval_frequency : int\n",
    "        How often to evaluate and print\n",
    "    checkpoint_dir : str\n",
    "        Directory for checkpointing\n",
    "    checkpoint_frequency : int\n",
    "        How often to save checkpoints\n",
    "    save_best_only : bool\n",
    "        Whether to save only the best model\n",
    "    verbose : bool\n",
    "        Wether to print progress information\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[List[float], List[float], List[float]]\n",
    "        Episode win rates and losses\n",
    "    \"\"\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    best_win_rate = float('-inf')\n",
    "    # Use the same epsilon policy for adversary if not provided\n",
    "    if epsilon_greedy_adversary is None:\n",
    "        epsilon_greedy_adversary = epsilon_greedy\n",
    "\n",
    "    iteration = 0\n",
    "    episodes_win_rates = []\n",
    "    main_network_episodes_losses = []\n",
    "    adversary_network_episodes_losses = []\n",
    "\n",
    "    # Initialize exploration counters\n",
    "    exploration_steps = 0\n",
    "    pure_exploration = exploration_steps < init_exploration_steps\n",
    "\n",
    "    # Create running stats for loss tracking\n",
    "    running_loss_main = 0.0\n",
    "    running_loss_adv = 0.0\n",
    "\n",
    "    for episode_index in tqdm(range(1, num_episodes + 1)):\n",
    "        # Switch roles every episode to ensure balanced training\n",
    "        main_player_first = (episode_index % 2 == 1)\n",
    "        optimizer_steps = 0\n",
    "        optimizer_adversary_steps = 0\n",
    "\n",
    "        # Reset environment\n",
    "        state, info = env.reset(options={'is_first_player': main_player_first})\n",
    "        episode_reward = 0.0\n",
    "        done = False\n",
    "\n",
    "        # Initial player\n",
    "        current_player = 0  # 0 for first player (RED), 1 for second player (BLUE)\n",
    "\n",
    "        # Episode metrics\n",
    "        episode_steps = 0\n",
    "\n",
    "        while not done:\n",
    "            episode_steps += 1\n",
    "\n",
    "            # Determine which network to use based on current player and first player assignment\n",
    "            is_main_network_turn = (current_player == 0 and main_player_first) or (\n",
    "                    current_player == 1 and not main_player_first)\n",
    "\n",
    "            # Select action based on current player\n",
    "            if pure_exploration:\n",
    "                # During initial exploration, use completely random actions\n",
    "                action = env.sample_legal_action()\n",
    "                exploration_steps += 1\n",
    "                pure_exploration = exploration_steps < init_exploration_steps\n",
    "            else:\n",
    "                # Use epsilon-greedy policies after initial exploration\n",
    "                if is_main_network_turn:\n",
    "                    # Main network's turn\n",
    "                    current_network = q_network\n",
    "                    current_epsilon = epsilon_greedy\n",
    "                else:\n",
    "                    # Adversary network's turn\n",
    "                    current_network = q_network_adversary\n",
    "                    current_epsilon = epsilon_greedy_adversary\n",
    "\n",
    "                # Use appropriate epsilon-greedy policy\n",
    "                current_epsilon.q_network = current_network\n",
    "                action = current_epsilon(state)\n",
    "\n",
    "            # Take action in environment\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # Scaling the reward differently based on terminal vs non-terminal\n",
    "            if done:\n",
    "                adjusted_reward = reward * reward_scale\n",
    "            else:\n",
    "                # Heuristic-based rewards - applying separate scaling\n",
    "                adjusted_reward = reward * heuristic_scale\n",
    "\n",
    "            # print(\"Adjusted reward: %.3f\" % adjusted_reward)\n",
    "\n",
    "            # Store experience for the current player\n",
    "            current_buffer = replay_buffer if is_main_network_turn else replay_buffer_adversary\n",
    "\n",
    "            current_buffer.add(state, action, adjusted_reward, next_state, done, info['legal_moves'])\n",
    "\n",
    "            # Track reward (from main player's perspective only)\n",
    "            if is_main_network_turn:\n",
    "                episode_reward += reward  # Use original reward for tracking\n",
    "\n",
    "            # Train networks if enough experiences and past initial exploration\n",
    "            if not pure_exploration:\n",
    "                # Train main network if enough experiences\n",
    "                if len(replay_buffer) > batch_size:\n",
    "                    optimizer_steps += 1\n",
    "                    loss_main = update_network(\n",
    "                        q_network, target_q_network, optimizer,\n",
    "                        replay_buffer, batch_size, gamma, loss_fn,\n",
    "                        grad_clip, double_q\n",
    "                    )\n",
    "                    running_loss_main = loss_main / optimizer_steps\n",
    "\n",
    "                    # Update learning rate if scheduler provided\n",
    "                    if lr_scheduler is not None:\n",
    "                        lr_scheduler.step()\n",
    "\n",
    "                # Train adversary network if enough experiences\n",
    "                if len(replay_buffer_adversary) > batch_size:\n",
    "                    optimizer_adversary_steps += 1\n",
    "                    loss_adv = update_network(\n",
    "                        q_network_adversary, target_q_network_adversary, optimizer_adversary,\n",
    "                        replay_buffer_adversary, batch_size, gamma, loss_fn,\n",
    "                        grad_clip, double_q\n",
    "                    )\n",
    "                    running_loss_adv = loss_adv / optimizer_adversary_steps\n",
    "\n",
    "                    # Update learning rate if scheduler provided\n",
    "                    if lr_scheduler_adversary is not None:\n",
    "                        lr_scheduler_adversary.step()\n",
    "\n",
    "                # Update target networks\n",
    "                iteration += 1\n",
    "                if soft_update:\n",
    "                    # Soft update of target networks\n",
    "                    soft_update_target_network(q_network, target_q_network, tau)\n",
    "                    soft_update_target_network(q_network_adversary, target_q_network_adversary, tau)\n",
    "                elif iteration % target_q_network_sync_period == 0:\n",
    "                    # Hard update of target networks\n",
    "                    target_q_network.load_state_dict(q_network.state_dict())\n",
    "                    target_q_network_adversary.load_state_dict(q_network_adversary.state_dict())\n",
    "\n",
    "            # Prepare for next step\n",
    "            state = next_state\n",
    "            current_player = 1 - current_player  # Switch player\n",
    "\n",
    "        # Decay exploration rates\n",
    "        epsilon_greedy.decay_epsilon()\n",
    "        if epsilon_greedy_adversary is not epsilon_greedy:\n",
    "            epsilon_greedy_adversary.decay_epsilon()\n",
    "\n",
    "        # Print progress periodically\n",
    "        if (episode_index + 1) % eval_frequency == 0 or episode_index == 0:\n",
    "            print(f\"\\nEpisode {episode_index + 1}/{num_episodes}\")\n",
    "            print(f\"Epsilon: {epsilon_greedy.epsilon:.4f}\")\n",
    "            print(f\"Running Loss - Main: {running_loss_main:.4f}, Adv: {running_loss_adv:.4f}\")\n",
    "            if lr_scheduler is not None:\n",
    "                print(f\"Learning rate - Main: {lr_scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "            test_win_rate = (\n",
    "                test_functions.test_q_network_vs_alpha_beta(env_port=3, agent_port=9, num_episodes=1,\n",
    "                                                            q_network=q_network,\n",
    "                                                            ))['q_network_win_rate']\n",
    "\n",
    "            episodes_win_rates.append(test_win_rate)\n",
    "\n",
    "            # Print progress if verbose\n",
    "            if verbose:\n",
    "                print(f\"\\nEpisode {episode_index + 1}/{num_episodes}\")\n",
    "                print(f\"Win rate: {test_win_rate:.4f}\")\n",
    "                print(f\"Learning Rate: {lr_scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "            # Save best model if performance improved\n",
    "            if test_win_rate > best_win_rate:\n",
    "                best_win_rate = test_win_rate\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "                torch.save({\n",
    "                    'episode': episode_index,\n",
    "                    'q_network_state_dict': q_network.state_dict(),\n",
    "                    'q_network_adversary_state_dict': q_network_adversary.state_dict(),\n",
    "                    'target_q_network_state_dict': target_q_network.state_dict(),\n",
    "                    'target_q_network_adversary_state_dict': target_q_network_adversary.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'optimizer_adversary_state_dict': optimizer_adversary.state_dict(),\n",
    "                    'lr_scheduler_state_dict': lr_scheduler.state_dict() if lr_scheduler else None,\n",
    "                    'lr_scheduler_adversary_state_dict': lr_scheduler_adversary.state_dict() if lr_scheduler_adversary else None,\n",
    "                    'epsilon': epsilon_greedy.epsilon,\n",
    "                    'epsilon_adversary': epsilon_greedy_adversary.epsilon if epsilon_greedy_adversary is not epsilon_greedy else None,\n",
    "                    'best_win_rate': best_win_rate\n",
    "                }, checkpoint_path)\n",
    "                print(\n",
    "                    f\"Saved best model with win rate: {best_win_rate:.2f} at episode {episode_index + 1}/{num_episodes}\")\n",
    "\n",
    "        # Save checkpoint at regular intervals\n",
    "        if (\n",
    "                episode_index + 1) % checkpoint_frequency == 0 and not save_best_only and optimizer_steps and optimizer_adversary_steps:\n",
    "            main_network_episodes_losses.append(running_loss_main)\n",
    "            adversary_network_episodes_losses.append(running_loss_adv)\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_episode_{episode_index}.pt')\n",
    "            torch.save({\n",
    "                'episode': episode_index,\n",
    "                'q_network_state_dict': q_network.state_dict(),\n",
    "                'q_network_adversary_state_dict': q_network_adversary.state_dict(),\n",
    "                'target_q_network_state_dict': target_q_network.state_dict(),\n",
    "                'target_q_network_adversary_state_dict': target_q_network_adversary.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'optimizer_adversary_state_dict': optimizer_adversary.state_dict(),\n",
    "                'lr_scheduler_state_dict': lr_scheduler.state_dict() if lr_scheduler else None,\n",
    "                'lr_scheduler_adversary_state_dict': lr_scheduler_adversary.state_dict() if lr_scheduler_adversary else None,\n",
    "                'epsilon': epsilon_greedy.epsilon,\n",
    "                'epsilon_adversary': epsilon_greedy_adversary.epsilon if epsilon_greedy_adversary is not epsilon_greedy else None,\n",
    "                'win_rates_list': episodes_win_rates,\n",
    "                'main_network_episodes_losses': main_network_episodes_losses,\n",
    "                'adversary_network_episodes_losses': adversary_network_episodes_losses\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint at episode {episode_index + 1}/{num_episodes}\")\n",
    "\n",
    "    return episodes_win_rates, main_network_episodes_losses, adversary_network_episodes_losses\n",
    "\n",
    "\n",
    "def update_network(\n",
    "        q_network, target_q_network, optimizer, replay_buffer,\n",
    "        batch_size, gamma, loss_fn, grad_clip, double_q\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to update a network with legal move masking\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    q_network, target_q_network : neural networks\n",
    "    optimizer : optimizer\n",
    "    replay_buffer : experience buffer\n",
    "    env : environment (needed for legal move generation)\n",
    "    batch_size, gamma, loss_fn, grad_clip, double_q, device : other parameters\n",
    "    \"\"\"\n",
    "    # Sample with legal move masks\n",
    "    states, actions, rewards, next_states, dones, legal_moves_mask = replay_buffer.sample(int(batch_size))\n",
    "\n",
    "    # Get current Q-values for selected actions\n",
    "    current_q = q_network(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if double_q:\n",
    "            # Double Q-learning with legal move masking\n",
    "            # Use online network for action selection (with masking)\n",
    "            q_values = q_network(next_states)\n",
    "            q_values_masked = q_values + legal_moves_mask\n",
    "            next_actions = q_values_masked.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            # Use target network for value estimation\n",
    "            next_q = target_q_network(next_states).gather(1, next_actions).squeeze(1)\n",
    "        else:\n",
    "            # Standard DQN with legal move masking\n",
    "            next_q_values = target_q_network(next_states)\n",
    "            next_q_values_masked = next_q_values + legal_moves_mask\n",
    "            next_q = next_q_values_masked.max(1)[0]\n",
    "\n",
    "        # Compute target Q-values\n",
    "        target_q = rewards + gamma * next_q * (1 - dones)\n",
    "\n",
    "    # Compute loss and update network\n",
    "    loss = loss_fn(current_q, target_q)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Apply gradient clipping\n",
    "    if grad_clip > 0:\n",
    "        torch.nn.utils.clip_grad_norm_(q_network.parameters(), grad_clip)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def soft_update_target_network(source_network, target_network, tau):\n",
    "    \"\"\"Soft update target network: θ_target = τ*θ_source + (1-τ)*θ_target\"\"\"\n",
    "    for target_param, source_param in zip(target_network.parameters(), source_network.parameters()):\n",
    "        target_param.data.copy_(tau * source_param.data + (1.0 - tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd0SXX5AYSvx"
   },
   "source": [
    "### Training\n",
    "\n",
    "We need to instantiate and initialize the two neural networks.\n",
    "\n",
    "A target network that has the same architecture as the Q-network. The weights of the target network are initially copied from the Q-network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRlZ6LYgYSvx"
   },
   "outputs": [],
   "source": [
    "env = kac.KingAndCourtesanEnv(\n",
    "    port=3,\n",
    ")\n",
    "\n",
    "# Initialize networks\n",
    "dqnv2 = QNetwork(board_size=6).to(device)\n",
    "q_network_adversary = QNetwork(board_size=6).to(device)\n",
    "target_q_network = QNetwork(board_size=6).to(device)\n",
    "target_q_network_adversary = QNetwork(board_size=6).to(device)\n",
    "\n",
    "# Copy initial weights to target networks\n",
    "target_q_network.load_state_dict(dqnv2.state_dict())\n",
    "target_q_network_adversary.load_state_dict(q_network_adversary.state_dict())\n",
    "\n",
    "# Initialize optimizers with weight decay for regularization\n",
    "optimizer = torch.optim.AdamW(\n",
    "    dqnv2.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-5,  # L2 regularization\n",
    "    amsgrad=True\n",
    ")\n",
    "optimizer_adversary = torch.optim.AdamW(\n",
    "    q_network_adversary.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-5,\n",
    "    amsgrad=True\n",
    ")\n",
    "\n",
    "# Initialize cosine annealing learning rate schedulers\n",
    "total_steps = 20000  # Total number of episodes\n",
    "warmup_steps = 1000  # Initial warmup period with higher learning rate\n",
    "\n",
    "# Cosine schedulers with warm restarts every 2000 episodes\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=2000,  # Restart period\n",
    "    T_mult=2,  # Increase period after each restart\n",
    "    eta_min=5e-5  # Minimum learning rate\n",
    ")\n",
    "lr_scheduler_adversary = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_adversary,\n",
    "    T_0=2000,\n",
    "    T_mult=2,\n",
    "    eta_min=5e-5\n",
    ")\n",
    "\n",
    "# Initialize Huber loss - more robust to outliers than MSE\n",
    "loss_fn = torch.nn.SmoothL1Loss()  # Huber loss\n",
    "\n",
    "# Initialize epsilon-greedy with a more sophisticated decay schedule\n",
    "epsilon_greedy = EpsilonGreedy(\n",
    "    epsilon_start=1.0,  # Start fully exploratory\n",
    "    epsilon_min=0.01,  # Lower minimum for more exploitation in late stages\n",
    "    epsilon_decay=0.9995,  # Slower decay for longer exploration\n",
    "    env=env,\n",
    "    q_network=dqnv2,\n",
    ")\n",
    "\n",
    "# Same epsilon policy for adversary for balanced self-play\n",
    "epsilon_greedy_adversary = EpsilonGreedy(\n",
    "    epsilon_start=1.0,\n",
    "    epsilon_min=0.01,\n",
    "    epsilon_decay=0.9995,\n",
    "    env=env,\n",
    "    q_network=q_network_adversary,\n",
    ")\n",
    "\n",
    "replay_buffer = ReplayBuffer(100000, env)  # Larger buffer to store more diverse experiences\n",
    "replay_buffer_adversary = ReplayBuffer(100000, env)\n",
    "\n",
    "# Train with more sophisticated hyperparameters\n",
    "episodes_win_rates, main_network_episodes_losses, adversary_network_episodes_losses = train_dqn2_agent(\n",
    "    env,\n",
    "    dqnv2,\n",
    "    q_network_adversary,\n",
    "    target_q_network,\n",
    "    target_q_network_adversary,\n",
    "    optimizer,\n",
    "    optimizer_adversary,\n",
    "    loss_fn,\n",
    "    epsilon_greedy,\n",
    "    epsilon_greedy_adversary,\n",
    "    lr_scheduler,\n",
    "    lr_scheduler_adversary,\n",
    "    num_episodes=10000,\n",
    "    gamma=0.99,  # Higher discount factor for longer-term planning\n",
    "    batch_size=512,  # Larger batch size for more stable gradients\n",
    "    replay_buffer=replay_buffer,\n",
    "    replay_buffer_adversary=replay_buffer_adversary,\n",
    "    target_q_network_sync_period=1000,  # Less frequent updates for more stability\n",
    "    grad_clip=10.0,  # Add gradient clipping to prevent explosions\n",
    "    double_q=True,  # Use Double DQN update rule\n",
    "    soft_update=False,  # Instead of hard updates, can switch to soft updates\n",
    "    tau=0.005,  # Polyak averaging factor for soft updates\n",
    "    init_exploration_steps=5000,  # Initial random steps to fill replay buffer\n",
    "    reward_scale=1.0,  # Can scale rewards for better learning dynamics\n",
    "    eval_frequency=1000,  # Evaluate more frequently\n",
    "    heuristic_scale=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZlykkIVV5kO"
   },
   "outputs": [],
   "source": [
    "torch.save(dqnv2, MODELS_DIR / \"dqn2_q_network.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "error",
     "timestamp": 1741397804582,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "u0renVYhV5kO",
    "outputId": "709c0a36-9577-449f-e256-16c10572e08d"
   },
   "outputs": [],
   "source": [
    "joblib.dump({'episodes_win_rates': episodes_win_rates, 'main_network_episodes_losses': main_network_episodes_losses,\n",
    "             'adversary_network_episodes_losses': adversary_network_episodes_losses}, 'dqnv2_train_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcjBrrrGYSvy"
   },
   "outputs": [],
   "source": [
    "dqn2_trains_result_list: List[List[Union[int, float]]] = [[], []]\n",
    "dqn2_trains_result_list[0] = list(range(len(episodes_win_rates)))\n",
    "dqn2_trains_result_list[1] = episodes_win_rates\n",
    "\n",
    "dqn2_trains_result_df = pd.DataFrame(\n",
    "    np.array(dqn2_trains_result_list).T,\n",
    "    columns=[\"num_episodes\", \"episode_reward\"],\n",
    ")\n",
    "dqn2_trains_result_df[\"agent\"] = \"DQN 2015\"\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bACs-cGsYSvy"
   },
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTVzz1T1YSvy",
    "outputId": "d26eea3b-d5ca-4db9-f22b-43052985a00b"
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    x=\"num_episodes\",\n",
    "    y=\"episode_reward\",\n",
    "    kind=\"line\",\n",
    "    hue=\"agent\",\n",
    "    estimator=None,\n",
    "    data=dqn2_trains_result_df,\n",
    "    height=7,\n",
    "    aspect=2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.savefig(PLOTS_DIR / \"dqnv2_trains_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlHi02VBYSvy"
   },
   "source": [
    "### Testing Against a Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vGgy0ifYSvy",
    "outputId": "0e87b62f-8199-4a93-d7de-5803309b18f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "\n",
      "Episode 1/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F1\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F -RBBQB\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: F1-E2\n",
      "  012345\n",
      "F --BBQB\n",
      "E --RBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E2\n",
      "  012345\n",
      "F ---BQB\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F ---BQB\n",
      "E --BBBB\n",
      "D RRRBBB\n",
      "C RR--BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F ---BQB\n",
      "E --BBBB\n",
      "D RRRBBB\n",
      "C RR--B-\n",
      "B RRRRBB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F ---BQB\n",
      "E --BBBB\n",
      "D RRRBBB\n",
      "C RRR-B-\n",
      "B R-RRBB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F ---BQB\n",
      "E --B-BB\n",
      "D RRBBBB\n",
      "C RRR-B-\n",
      "B R-RRBB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F ---BQB\n",
      "E --B-BB\n",
      "D RRBBBB\n",
      "C RRR-B-\n",
      "B R-RRRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F ---BBB\n",
      "E --B-QB\n",
      "D RRBBBB\n",
      "C RRR-B-\n",
      "B R-RRRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: B4-C5\n",
      "  012345\n",
      "F ---BBB\n",
      "E --B-QB\n",
      "D RRBBBB\n",
      "C RRR-BR\n",
      "B R-RR-B\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D5-C5\n",
      "  012345\n",
      "F ---BBB\n",
      "E --B-QB\n",
      "D RRBBB-\n",
      "C RRR-BB\n",
      "B R-RR-B\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-QB\n",
      "D R-BBB-\n",
      "C RRR-BB\n",
      "B R-RR-B\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-QB\n",
      "D R-BBB-\n",
      "C RRR-B-\n",
      "B R-RRBB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-QB\n",
      "D R-BBB-\n",
      "C RRR-B-\n",
      "B R-RRRB\n",
      "A KRR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D3\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-BB\n",
      "D R-BQB-\n",
      "C RRR-B-\n",
      "B R-RRRB\n",
      "A KRR---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-BB\n",
      "D R-BQB-\n",
      "C RRR-B-\n",
      "B R-RRRB\n",
      "A RKR---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B R-RRRB\n",
      "A RKR---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: B0-B1\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B -RRRRB\n",
      "A RKR---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F ---BBB\n",
      "E -RB-BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B -RRRR-\n",
      "A RKR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: E1-F2\n",
      "  012345\n",
      "F --RBBB\n",
      "E --B-BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B -RRRR-\n",
      "A RKR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 22\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-F2\n",
      "  012345\n",
      "F --BBBB\n",
      "E ----BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B -RRRR-\n",
      "A RKR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F --BBBB\n",
      "E ----BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B -KRRR-\n",
      "A RRR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 24\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E2\n",
      "  012345\n",
      "F ---BBB\n",
      "E --B-BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B -KRRR-\n",
      "A RRR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F ---BBB\n",
      "E --B-BB\n",
      "D R-BQB-\n",
      "C RRRB--\n",
      "B RKRRR-\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 26\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-D1\n",
      "  012345\n",
      "F ---BBB\n",
      "E ----BB\n",
      "D RBBQB-\n",
      "C RRRB--\n",
      "B RKRRR-\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: B4-C3\n",
      "  012345\n",
      "F ---BBB\n",
      "E ----BB\n",
      "D RBBQB-\n",
      "C RRRR--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 28\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D1-C2\n",
      "  012345\n",
      "F ---BBB\n",
      "E ----BB\n",
      "D R-BQB-\n",
      "C RRBR--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F ---BBB\n",
      "E -R--BB\n",
      "D --BQB-\n",
      "C RRBR--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 30\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F ---BBB\n",
      "E -R--BB\n",
      "D --BQ--\n",
      "C RRBB--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: E1-F1\n",
      "  012345\n",
      "F -R-BBB\n",
      "E ----BB\n",
      "D --BQ--\n",
      "C RRBB--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 32\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E5-D4\n",
      "  012345\n",
      "F -R-BBB\n",
      "E ----B-\n",
      "D --BQB-\n",
      "C RRBB--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F -R-BBB\n",
      "E ----B-\n",
      "D --BQB-\n",
      "C R-RB--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 34\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F3-E2\n",
      "  012345\n",
      "F -R--BB\n",
      "E --B-B-\n",
      "D --BQB-\n",
      "C R-RB--\n",
      "B RKRR--\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C3\n",
      "  012345\n",
      "F -R--BB\n",
      "E --B-B-\n",
      "D --BQB-\n",
      "C R-RR--\n",
      "B RKR---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 36\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-F1\n",
      "  012345\n",
      "F -B--BB\n",
      "E ----B-\n",
      "D --BQB-\n",
      "C R-RR--\n",
      "B RKR---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C1\n",
      "  012345\n",
      "F -B--BB\n",
      "E ----B-\n",
      "D --BQB-\n",
      "C RKRR--\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 38\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B---BB\n",
      "E ----B-\n",
      "D --BQB-\n",
      "C RKRR--\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: C3-D4\n",
      "  012345\n",
      "F B---BB\n",
      "E ----B-\n",
      "D --BQR-\n",
      "C RKR---\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 40\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F B---BB\n",
      "E ---B--\n",
      "D --BQR-\n",
      "C RKR---\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: C0-D1\n",
      "  012345\n",
      "F B---BB\n",
      "E ---B--\n",
      "D -RBQR-\n",
      "C -KR---\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 42\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F B----B\n",
      "E ---BB-\n",
      "D -RBQR-\n",
      "C -KR---\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F B----B\n",
      "E ---BB-\n",
      "D -RRQR-\n",
      "C -K----\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 44\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F B----B\n",
      "E ----B-\n",
      "D -RBQR-\n",
      "C -K----\n",
      "B R-R---\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F B----B\n",
      "E ----B-\n",
      "D -RBQR-\n",
      "C -K-R--\n",
      "B R-----\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 46\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D2-C1\n",
      "  012345\n",
      "F B----B\n",
      "E ----B-\n",
      "D -R-QR-\n",
      "C -B-R--\n",
      "B R-----\n",
      "A -RR--B\n",
      "BLUE KING Position: (3,3)\n",
      "\n",
      "\n",
      "Game Over! Winner: q_network\n",
      "\n",
      "Episode 2/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B RR-R-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B RR-R-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRRRRB\n",
      "B RR---R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-B-BB\n",
      "D RRBBBB\n",
      "C RRRRRB\n",
      "B RR---R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: B1-B2\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-B-BB\n",
      "D RRBBBB\n",
      "C RRRRRB\n",
      "B R-R--R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-B-BB\n",
      "D RRBBBB\n",
      "C RRRRR-\n",
      "B R-R-BR\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: C4-D5\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-B-BB\n",
      "D RRBBBR\n",
      "C RRRR--\n",
      "B R-R-BR\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-B-QB\n",
      "D RRBBBR\n",
      "C RRRR--\n",
      "B R-R-BR\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-B-QB\n",
      "D RRBBBR\n",
      "C RRRR--\n",
      "B R-RRBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-B-QB\n",
      "D RRBB-R\n",
      "C RRRB--\n",
      "B R-RRBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-QB\n",
      "D R-BB-R\n",
      "C RRRB--\n",
      "B R-RRBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C3-B2\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-QB\n",
      "D R-BB-R\n",
      "C RRR---\n",
      "B R-BRBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-QB\n",
      "D R-RB-R\n",
      "C R-R---\n",
      "B R-BRBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-QB\n",
      "D R-RB-R\n",
      "C R-R---\n",
      "B R--BBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: D0-D1\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-QB\n",
      "D -RRB-R\n",
      "C R-R---\n",
      "B R--BBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RRB-R\n",
      "C R-R---\n",
      "B R--BBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBR-QB\n",
      "D --RB-R\n",
      "C R-R---\n",
      "B R--BBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F B--BBB\n",
      "E R-B-QB\n",
      "D --RB-R\n",
      "C R-R---\n",
      "B R--BBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F B--BBB\n",
      "E -RB-QB\n",
      "D --RB-R\n",
      "C R-R---\n",
      "B R--BBR\n",
      "A KR-R--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 22\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B3-A3\n",
      "  012345\n",
      "F B--BBB\n",
      "E -RB-QB\n",
      "D --RB-R\n",
      "C R-R---\n",
      "B R---BR\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --R-QB\n",
      "D --RB-R\n",
      "C R-R---\n",
      "B R---BR\n",
      "A KR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 24\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: A3-A2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --R-QB\n",
      "D --RB-R\n",
      "C R-R---\n",
      "B R---BR\n",
      "A KRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F B--BBB\n",
      "E --R-QB\n",
      "D --RB-R\n",
      "C R--R--\n",
      "B R---BR\n",
      "A KRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 26\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B4-A4\n",
      "  012345\n",
      "F B--BBB\n",
      "E --R-QB\n",
      "D --RB-R\n",
      "C R--R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: E2-F2\n",
      "  012345\n",
      "F B-RBBB\n",
      "E ----QB\n",
      "D --RB-R\n",
      "C R--R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 28\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F B-RBBB\n",
      "E -----B\n",
      "D --RBQR\n",
      "C R--R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E2\n",
      "  012345\n",
      "F B-RBBB\n",
      "E --R--B\n",
      "D ---BQR\n",
      "C R--R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 30\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F0-E0\n",
      "  012345\n",
      "F --RBBB\n",
      "E B-R--B\n",
      "D ---BQR\n",
      "C R--R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F --RBBB\n",
      "E B-R--B\n",
      "D ---BQR\n",
      "C -R-R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 32\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F --RBBB\n",
      "E B-R--B\n",
      "D ---QBR\n",
      "C -R-R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: E2-F3\n",
      "  012345\n",
      "F --RRBB\n",
      "E B----B\n",
      "D ---QBR\n",
      "C -R-R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 34\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-F3\n",
      "  012345\n",
      "F --RB-B\n",
      "E B----B\n",
      "D ---QBR\n",
      "C -R-R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: D5-D4\n",
      "  012345\n",
      "F --RB-B\n",
      "E B----B\n",
      "D ---QR-\n",
      "C -R-R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 36\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E5-D5\n",
      "  012345\n",
      "F --RB-B\n",
      "E B-----\n",
      "D ---QRB\n",
      "C -R-R--\n",
      "B R----R\n",
      "A KRB-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: A1-B2\n",
      "  012345\n",
      "F --RB-B\n",
      "E B-----\n",
      "D ---QRB\n",
      "C -R-R--\n",
      "B R-R--R\n",
      "A K-B-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 38\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D5-C5\n",
      "  012345\n",
      "F --RB-B\n",
      "E B-----\n",
      "D ---QR-\n",
      "C -R-R-B\n",
      "B R-R--R\n",
      "A K-B-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F --RB-B\n",
      "E B-----\n",
      "D ---QR-\n",
      "C --RR-B\n",
      "B R-R--R\n",
      "A K-B-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 40\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E0-D0\n",
      "  012345\n",
      "F --RB-B\n",
      "E ------\n",
      "D B--QR-\n",
      "C --RR-B\n",
      "B R-R--R\n",
      "A K-B-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: B5-C5\n",
      "  012345\n",
      "F --RB-B\n",
      "E ------\n",
      "D B--QR-\n",
      "C --RR-R\n",
      "B R-R---\n",
      "A K-B-B-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 42\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-D4\n",
      "  012345\n",
      "F --RB-B\n",
      "E ------\n",
      "D B---Q-\n",
      "C --RR-R\n",
      "B R-R---\n",
      "A K-B-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: C3-D4\n",
      "  012345\n",
      "F --RB-B\n",
      "E ------\n",
      "D B---R-\n",
      "C --R--R\n",
      "B R-R---\n",
      "A K-B-B-\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Game Over! Winner: random\n",
      "\n",
      "Episode 3/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E RRBBBB\n",
      "D R--BBB\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRBBBB\n",
      "D R--BBB\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRBBBB\n",
      "D R--BBB\n",
      "C RR-RRB\n",
      "B RRR--B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB-BB\n",
      "D R-BBBB\n",
      "C RR-RRB\n",
      "B RRR--B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB-BB\n",
      "D R-BBBB\n",
      "C R-RRRB\n",
      "B RRR--B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB-BB\n",
      "D R-BBBB\n",
      "C R-RRR-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB-BB\n",
      "D R-BBBB\n",
      "C R-RRR-\n",
      "B KRR-BB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB-BB\n",
      "D R-BBB-\n",
      "C R-RRB-\n",
      "B KRR-BB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB-BB\n",
      "D R-BRB-\n",
      "C R--RB-\n",
      "B KRR-BB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D3\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB--B\n",
      "D R-BBB-\n",
      "C R--RB-\n",
      "B KRR-BB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: C3-B4\n",
      "  012345\n",
      "F B-BBQB\n",
      "E RRB--B\n",
      "D R-BBB-\n",
      "C R---B-\n",
      "B KRR-RB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F B--BQB\n",
      "E RBB--B\n",
      "D R-BBB-\n",
      "C R---B-\n",
      "B KRR-RB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F B--BQB\n",
      "E RBB--B\n",
      "D R-BBB-\n",
      "C R---B-\n",
      "B KR-RRB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F B--BQB\n",
      "E RBB--B\n",
      "D R-BBB-\n",
      "C R--B--\n",
      "B KR-RRB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: A1-B2\n",
      "  012345\n",
      "F B--BQB\n",
      "E RBB--B\n",
      "D R-BBB-\n",
      "C R--B--\n",
      "B KRRRRB\n",
      "A R-RRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F B--B-B\n",
      "E RBB-QB\n",
      "D R-BBB-\n",
      "C R--B--\n",
      "B KRRRRB\n",
      "A R-RRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F B--B-B\n",
      "E RBB-QB\n",
      "D R-BBB-\n",
      "C -R-B--\n",
      "B KRRRRB\n",
      "A R-RRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F B--BB-\n",
      "E RBB-QB\n",
      "D R-BBB-\n",
      "C -R-B--\n",
      "B KRRRRB\n",
      "A R-RRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: B4-C5\n",
      "  012345\n",
      "F B--BB-\n",
      "E RBB-QB\n",
      "D R-BBB-\n",
      "C -R-B-R\n",
      "B KRRR-B\n",
      "A R-RRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 22\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F B--BB-\n",
      "E RBB-QB\n",
      "D R-BBB-\n",
      "C -R-B-R\n",
      "B KRRR--\n",
      "A R-RRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F B--BB-\n",
      "E RRB-QB\n",
      "D --BBB-\n",
      "C -R-B-R\n",
      "B KRRR--\n",
      "A R-RRRB\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 24\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D3\n",
      "  012345\n",
      "F B--BB-\n",
      "E RRB-BB\n",
      "D --BQB-\n",
      "C -R-B-R\n",
      "B KRRR--\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F0\n",
      "  012345\n",
      "F R--BB-\n",
      "E -RB-BB\n",
      "D --BQB-\n",
      "C -R-B-R\n",
      "B KRRR--\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 26\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F R--BB-\n",
      "E -B--BB\n",
      "D --BQB-\n",
      "C -R-B-R\n",
      "B KRRR--\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C3\n",
      "  012345\n",
      "F R--BB-\n",
      "E -B--BB\n",
      "D --BQB-\n",
      "C -R-R-R\n",
      "B KRR---\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 28\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F3-E2\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D --BQB-\n",
      "C -R-R-R\n",
      "B KRR---\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D -RBQB-\n",
      "C ---R-R\n",
      "B KRR---\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 30\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D -RBQ--\n",
      "C ---B-R\n",
      "B KRR---\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C1\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D -RBQ--\n",
      "C -R-B-R\n",
      "B K-R---\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 32\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C3-B2\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D -RBQ--\n",
      "C -R---R\n",
      "B K-B---\n",
      "A R-RRRB\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D -RBQ--\n",
      "C -R---R\n",
      "B K-B---\n",
      "A R-RR-R\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 34\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B2-C1\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D -RBQ--\n",
      "C -B---R\n",
      "B K-----\n",
      "A R-RR-R\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F R---B-\n",
      "E -BB-BB\n",
      "D -RBQ--\n",
      "C -B---R\n",
      "B K---R-\n",
      "A R-R--R\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 36\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E1-D1\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D -BBQ--\n",
      "C -B---R\n",
      "B K---R-\n",
      "A R-R--R\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: A5-B5\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D -BBQ--\n",
      "C -B---R\n",
      "B K---RR\n",
      "A R-R---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 38\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C1-C0\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D -BBQ--\n",
      "C B----R\n",
      "B K---RR\n",
      "A R-R---\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D -BBQ--\n",
      "C B----R\n",
      "B K-R-RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 40\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D2-C1\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D -B-Q--\n",
      "C BB---R\n",
      "B K-R-RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: B2-C1\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D -B-Q--\n",
      "C BR---R\n",
      "B K---RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 42\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D1-C1\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D ---Q--\n",
      "C BB---R\n",
      "B K---RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: B0-C1\n",
      "  012345\n",
      "F R---B-\n",
      "E --B-BB\n",
      "D ---Q--\n",
      "C BK---R\n",
      "B ----RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 44\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-D1\n",
      "  012345\n",
      "F R---B-\n",
      "E ----BB\n",
      "D -B-Q--\n",
      "C BK---R\n",
      "B ----RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F R---B-\n",
      "E ----BB\n",
      "D -BKQ--\n",
      "C B----R\n",
      "B ----RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (3,2)\n",
      "\n",
      "Move 46\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D1-C1\n",
      "  012345\n",
      "F R---B-\n",
      "E ----BB\n",
      "D --KQ--\n",
      "C BB---R\n",
      "B ----RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (3,2)\n",
      "\n",
      "Move 47\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E2\n",
      "  012345\n",
      "F R---B-\n",
      "E --K-BB\n",
      "D ---Q--\n",
      "C BB---R\n",
      "B ----RR\n",
      "A R-----\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (4,2)\n",
      "\n",
      "Move 48\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D3-E2\n",
      "  012345\n",
      "F R---B-\n",
      "E --Q-BB\n",
      "D ------\n",
      "C BB---R\n",
      "B ----RR\n",
      "A R-----\n",
      "BLUE KING Position: (4,2)\n",
      "\n",
      "\n",
      "Game Over! Winner: q_network\n",
      "\n",
      "Episode 4/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F1\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F -RBBQB\n",
      "E --BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F -RBBQB\n",
      "E -RBBBB\n",
      "D R--BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -RBBQB\n",
      "E -RBBBB\n",
      "D R--BBB\n",
      "C RRR-B-\n",
      "B RRRRBB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F -RBBQB\n",
      "E -RBBBB\n",
      "D RR-BBB\n",
      "C R-R-B-\n",
      "B RRRRBB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F -RBBQB\n",
      "E -RB-BB\n",
      "D RRBBBB\n",
      "C R-R-B-\n",
      "B RRRRBB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F -RBBQB\n",
      "E -RB-BB\n",
      "D RRBBBB\n",
      "C R-R-R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RB-QB\n",
      "D RRBBBB\n",
      "C R-R-R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RB-QB\n",
      "D RRBBBB\n",
      "C -RR-R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F -R-BBB\n",
      "E -BB-QB\n",
      "D RRBBBB\n",
      "C -RR-R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F -R-BBB\n",
      "E -BB-QB\n",
      "D RRBRBB\n",
      "C -R--R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D3\n",
      "  012345\n",
      "F -R-BBB\n",
      "E -BB--B\n",
      "D RRBQBB\n",
      "C -R--R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F -R-BBB\n",
      "E -RB--B\n",
      "D -RBQBB\n",
      "C -R--R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F -R-B-B\n",
      "E -RB-BB\n",
      "D -RBQBB\n",
      "C -R--R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F -R-B-B\n",
      "E -RB-BB\n",
      "D -RBQBB\n",
      "C --R-R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F -R-BB-\n",
      "E -RB-BB\n",
      "D -RBQBB\n",
      "C --R-R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: E1-F2\n",
      "  012345\n",
      "F -RRBB-\n",
      "E --B-BB\n",
      "D -RBQBB\n",
      "C --R-R-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F -RRBB-\n",
      "E --B-BB\n",
      "D -RBQB-\n",
      "C --R-B-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F -RRBB-\n",
      "E --B-BB\n",
      "D -RRQB-\n",
      "C ----B-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-F2\n",
      "  012345\n",
      "F -RBBB-\n",
      "E ----BB\n",
      "D -RRQB-\n",
      "C ----B-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: D2-D3\n",
      "  012345\n",
      "F -RBBB-\n",
      "E ----BB\n",
      "D -R-RB-\n",
      "C ----B-\n",
      "B RRR-BB\n",
      "A KRRRR-\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Game Over! Winner: random\n",
      "\n",
      "Episode 5/5\n",
      "Q-Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C R-R-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C R-R-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B5\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C R-R-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C R-R-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C -RR-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-B-BB\n",
      "D RRBBBB\n",
      "C -RR-BB\n",
      "B RRRR-R\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: B5-C5\n",
      "  012345\n",
      "F B-BBQB\n",
      "E R-B-BB\n",
      "D RRBBBB\n",
      "C -RR-BR\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-B-QB\n",
      "D RRBBBB\n",
      "C -RR-BR\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-QB\n",
      "D -RBBBB\n",
      "C -RR-BR\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBBB\n",
      "C -RR-BR\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBBB\n",
      "C -RR-R-\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBB-\n",
      "C -RR-B-\n",
      "B RRRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: B0-C0\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBB-\n",
      "C RRR-B-\n",
      "B -RRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBB-\n",
      "C RRRB--\n",
      "B -RRR--\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBB-\n",
      "C RRRB--\n",
      "B -RRR--\n",
      "A RKRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 16\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C3-B2\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBB-\n",
      "C RRR---\n",
      "B -RBR--\n",
      "A RKRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C3\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBB-\n",
      "C RRRR--\n",
      "B -RB---\n",
      "A RKRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 18\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B2-C1\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D -RBBB-\n",
      "C RBRR--\n",
      "B -R----\n",
      "A RKRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: C0-D0\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D RRBBB-\n",
      "C -BRR--\n",
      "B -R----\n",
      "A RKRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 20\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D2-C3\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D RR-BB-\n",
      "C -BRB--\n",
      "B -R----\n",
      "A RKRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D RR-BB-\n",
      "C -BRB--\n",
      "B -R--R-\n",
      "A RKR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 22\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D RR-BB-\n",
      "C --BB--\n",
      "B -R--R-\n",
      "A RKR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: B4-C3\n",
      "  012345\n",
      "F B--BBB\n",
      "E RBB-QB\n",
      "D RR-BB-\n",
      "C --BR--\n",
      "B -R----\n",
      "A RKR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 24\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E1-D1\n",
      "  012345\n",
      "F B--BBB\n",
      "E R-B-QB\n",
      "D RB-BB-\n",
      "C --BR--\n",
      "B -R----\n",
      "A RKR---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F B--BBB\n",
      "E R-B-QB\n",
      "D RB-BB-\n",
      "C --BR--\n",
      "B -R----\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 26\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D1-E0\n",
      "  012345\n",
      "F B--BBB\n",
      "E B-B-QB\n",
      "D R--BB-\n",
      "C --BR--\n",
      "B -R----\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: C3-C2\n",
      "  012345\n",
      "F B--BBB\n",
      "E B-B-QB\n",
      "D R--BB-\n",
      "C --R---\n",
      "B -R----\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 28\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F B--BBB\n",
      "E B-B-QB\n",
      "D R--B--\n",
      "C --RB--\n",
      "B -R----\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F B--BBB\n",
      "E B-B-QB\n",
      "D R--R--\n",
      "C ---B--\n",
      "B -R----\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 30\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F B--BBB\n",
      "E B-B-QB\n",
      "D R--R--\n",
      "C ------\n",
      "B -R-B--\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: D0-D1\n",
      "  012345\n",
      "F B--BBB\n",
      "E B-B-QB\n",
      "D -R-R--\n",
      "C ------\n",
      "B -R-B--\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 32\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E0-D1\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D -B-R--\n",
      "C ------\n",
      "B -R-B--\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: D3-D4\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D -B--R-\n",
      "C ------\n",
      "B -R-B--\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 34\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: B3-A3\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D -B--R-\n",
      "C ------\n",
      "B -R----\n",
      "A RRKB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D -B--R-\n",
      "C ------\n",
      "B -RK---\n",
      "A RR-B--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 36\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: A3-A2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D -B--R-\n",
      "C ------\n",
      "B -RK---\n",
      "A RRB---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: B2-A2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D -B--R-\n",
      "C ------\n",
      "B -R----\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 38\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D1-C1\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D ----R-\n",
      "C -B----\n",
      "B -R----\n",
      "A RRK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D ----R-\n",
      "C -B----\n",
      "B RR----\n",
      "A -RK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 40\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C1-C0\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D ----R-\n",
      "C B-----\n",
      "B RR----\n",
      "A -RK---\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B-QB\n",
      "D ----R-\n",
      "C B-----\n",
      "B RRK---\n",
      "A -R----\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 42\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B--B\n",
      "D ----Q-\n",
      "C B-----\n",
      "B RRK---\n",
      "A -R----\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: B0-C1\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B--B\n",
      "D ----Q-\n",
      "C BR----\n",
      "B -RK---\n",
      "A -R----\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 44\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B--B\n",
      "D ----Q-\n",
      "C -B----\n",
      "B -RK---\n",
      "A -R----\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --B--B\n",
      "D ----Q-\n",
      "C -BR---\n",
      "B --K---\n",
      "A -R----\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 46\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F B--BBB\n",
      "E -B---B\n",
      "D ----Q-\n",
      "C -BR---\n",
      "B --K---\n",
      "A -R----\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 47\n",
      "Player: Random (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F B--BBB\n",
      "E -B---B\n",
      "D ----Q-\n",
      "C -BR---\n",
      "B -RK---\n",
      "A ------\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 48\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: E1-D1\n",
      "  012345\n",
      "F B--BBB\n",
      "E -----B\n",
      "D -B--Q-\n",
      "C -BR---\n",
      "B -RK---\n",
      "A ------\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 49\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D1\n",
      "  012345\n",
      "F B--BBB\n",
      "E -----B\n",
      "D -R--Q-\n",
      "C -B----\n",
      "B -RK---\n",
      "A ------\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 50\n",
      "Player: Q-Network (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F B--BBB\n",
      "E -----B\n",
      "D -R----\n",
      "C -B-Q--\n",
      "B -RK---\n",
      "A ------\n",
      "BLUE KING Position: (2,3)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Test Results Summary:\n",
      "Episodes: 5\n",
      "Q-Network wins: 2 (40.0%)\n",
      "Random agent wins: 2 (40.0%)\n",
      "Ties: 0 (0.0%)\n",
      "Average steps per episode: 41.6\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "results = test_functions.test_q_network_vs_random(env_port=3, num_episodes=5, q_network=dqnv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Olr0Sh6wYSvy"
   },
   "source": [
    "### Testing Against our Java ID Alpha Beta Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9f8b56b48ebf4c669dde520081b7f10e"
     ]
    },
    "id": "2Dwgh06-YSvy",
    "outputId": "ebcc51a8-7100-480d-9162-f165588b77c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward: 185.0\n",
      "Episode reward: 206.0\n",
      "Episode reward: 207.0\n",
      "\n",
      "Select the episode to play here 👇\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8b56b48ebf4c669dde520081b7f10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='file_path', options=(PosixPath('figs/lab6/lab6_ex4_dqn2_tained-epi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = test_functions.test_q_network_vs_alpha_beta(env_port=3, num_episodes=1, q_network=dqnv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBRlq60oYSvy"
   },
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h2dKk3CYSvy",
    "outputId": "9e929b0f-f62f-41f7-cbc9-6f5912ea228b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_final_episode_reward    418.333333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score_dqn2 = dqn2_trains_result_df[[\"num_episodes\", \"mean_final_episode_reward\"]].groupby(\n",
    "    \"num_episodes\").mean().max()\n",
    "train_score_dqn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A3wd4D5YSvy"
   },
   "source": [
    "## 3. Deep policy-based Reinforcement Learning with Monte Carlo Policy Gradient (REINFORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUQVeZUlYSvy"
   },
   "source": [
    "### The Policy Gradient theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXmM5uqPYSvy"
   },
   "source": [
    "This is a policy gradient method that directly searchs in a family of parameterized policies $\\pi_\\theta$ for the optimal policy.\n",
    "\n",
    "This method performs gradient ascent in the policy space so that the total return is maximized.\n",
    "We will restrict our work to episodic tasks, *i.e.* tasks that have a starting states and last for a finite and fixed number of steps $T$, called horizon.\n",
    "\n",
    "More formally, we define an optimization criterion that we want to maximize:\n",
    "\n",
    "$$J(\\theta) = \\mathbb{E}_{\\pi_\\theta}\\left[\\sum_{t=1}^T r(s_t,a_t)\\right],$$\n",
    "\n",
    "where $\\mathbb{E}_{\\pi_\\theta}$ means $a \\sim \\pi_\\theta(\\cdot|s)$ and $T$ is the horizon of the episode.\n",
    "In other words, we want to maximize the value of the starting state: $V^{\\pi_\\theta}(s)$.\n",
    "The policy gradient theorem tells us that:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = \\nabla_\\theta V^{\\pi_\\theta}(s) = \\mathbb{E}_{\\pi_\\theta} \\left[\\nabla_\\theta \\log \\pi_\\theta (a|s) ~ Q^{\\pi_\\theta}(s,a) \\right],\n",
    "$$\n",
    "\n",
    "where the $Q$-function is defined as:\n",
    "\n",
    "$$Q^{\\pi_\\theta}(a|s) = \\mathbb{E}^{\\pi_\\theta} \\left[\\sum_{t=1}^T r(s_t,a_t)|s=s_1, a=a_1\\right].$$\n",
    "\n",
    "The policy gradient theorem is particularly effective because it allows gradient computation without needing to understand the system's dynamics, as long as the $Q$-function for the current policy is computable. By simply applying the policy and observing the one-step transitions, sufficient information is gathered. Implementing a stochastic gradient ascent and substituting $Q^{\\pi_\\theta}(s_t,a_t)$ with a Monte Carlo estimate $R_t = \\sum_{t'=t}^T r(s_{t'},a_{t'})$ for a single trajectory, we derive the REINFORCE algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9MpTW2IYSvz"
   },
   "source": [
    "The REINFORCE algorithm, introduced by Williams in 1992, is a Monte Carlo policy gradient method. It updates the policy in the direction that maximizes rewards, using full-episode returns as an unbiased estimate of the gradient. Each step involves generating an episode using the current policy, computing the gradient estimate, and updating the policy parameters. This algorithm is simple yet powerful, and it's particularly effective in environments where the policy gradient is noisy or the dynamics are complex.\n",
    "\n",
    "For further reading and a deeper understanding, refer to Williams' seminal paper (https://link.springer.com/article/10.1007/BF00992696) and the comprehensive text on reinforcement learning by Richard S. Sutton and Andrew G. Barto: \"Reinforcement Learning: An Introduction\", chap.13 (http://incompleteideas.net/book/RLbook2020.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ua6UYXqYSvz"
   },
   "source": [
    "Here is the REINFORCE algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xDI94O0YSvz"
   },
   "source": [
    "### Monte Carlo policy gradient (REINFORCE)\n",
    "\n",
    "<b>REQUIRE</b> <br>\n",
    "$\\quad$ A differentiable policy $\\pi_{\\boldsymbol{\\theta}}$ <br>\n",
    "$\\quad$ A learning rate $\\alpha \\in \\mathbb{R}^+$ <br>\n",
    "<b>INITIALIZATION</b> <br>\n",
    "$\\quad$ Initialize parameters $\\boldsymbol{\\theta} \\in \\mathbb{R}^d$ <br>\n",
    "<br>\n",
    "<b>FOR EACH</b> episode <br>\n",
    "$\\quad$ Generate full trace $\\tau = \\{ \\boldsymbol{s}_0, \\boldsymbol{a}_0, r_1, \\boldsymbol{s}_1, \\boldsymbol{a}_1, \\dots, r_T, \\boldsymbol{s}_T \\}$ following $\\pi_{\\boldsymbol{\\theta}}$ <br>\n",
    "$\\quad$ <b>FOR</b> $~ t=0,\\dots,T-1$ <br>\n",
    "$\\quad\\quad$ $G \\leftarrow \\sum_{k=t}^{T-1} r_k$ <br>\n",
    "$\\quad\\quad$ $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\alpha ~ \\underbrace{G ~ \\nabla_{\\boldsymbol{\\theta}} \\ln \\pi_{\\boldsymbol{\\theta}}(\\boldsymbol{a}_t|\\boldsymbol{s}_t)}_{\\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta})}$ <br>\n",
    "<br>\n",
    "<b>RETURN</b> $\\boldsymbol{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XVCq-yFYSvz"
   },
   "source": [
    "### 3.1 Policy Implementation\n",
    "\n",
    "We will implement a stochastic policy to control the agent's actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNYAnaSMYSvz"
   },
   "source": [
    "The network takes an input tensor representing the state of the environment and outputs a tensor of action probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network used as a policy for the REINFORCE algorithm.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    layer1 : torch.nn.Linear\n",
    "        A fully connected layer.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(state: torch.Tensor) -> torch.Tensor\n",
    "        Define the forward pass of the PolicyNetwork.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, board_size=6, action_space_size=None):\n",
    "        \"\"\"\n",
    "       Initialize a new instance of PolicyNetwork.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       n_observations : int\n",
    "           The size of the observation space.\n",
    "       n_actions : int\n",
    "           The size of the action space.\n",
    "       \"\"\"\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "\n",
    "        # Input: 6 channels representing the board state\n",
    "        self.board_size = board_size\n",
    "        if action_space_size is None:\n",
    "            self.action_space_size = board_size * board_size * board_size * board_size\n",
    "        else:\n",
    "            self.action_space_size = action_space_size\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(6, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Calculate the size after convolutions\n",
    "        conv_output_size = 128 * board_size * board_size\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(conv_output_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, self.action_space_size)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Calculate the probability of each action for the given state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state_tensor : torch.Tensor\n",
    "            The input tensor (state).\n",
    "            The shape of the tensor should be (N, dim),\n",
    "            where N is the number of states vectors in the batch\n",
    "            and dim is the dimension of state vectors.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The output tensor (the probability of each action for the given state).\n",
    "        \"\"\"\n",
    "        # Convolutional layers with batch normalization and ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Output layer with logits (will be converted to probabilities with softmax)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_params(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get the parameters.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            The parameters of the model.\n",
    "        \"\"\"\n",
    "        # return self.params.copy()\n",
    "        return torch.nn.utils.parameters_to_vector(self.parameters()).detach().cpu().numpy()\n",
    "\n",
    "    def set_params(self, params: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Set the parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : np.ndarray\n",
    "            The parameters of the model.\n",
    "        \"\"\"\n",
    "        #self.params = params.copy()\n",
    "        flat_params = torch.tensor(params, dtype=torch.float32).to(device)\n",
    "        torch.nn.utils.vector_to_parameters(flat_params, self.parameters())\n",
    "\n",
    "    def sample_discrete_action(\n",
    "            self,\n",
    "            env,\n",
    "            state: torch.Tensor,\n",
    "            train: bool = False\n",
    "    ) -> Tuple[int, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Sample a discrete action based on the given state and policy network.\n",
    "\n",
    "        This function takes a state and a policy network, and returns a sampled action and its log probability.\n",
    "        The action is sampled from a categorical distribution defined by the output of the policy network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        env: KingAndCourtesanEnv\n",
    "            The gane environment\n",
    "        state : numpy.ndarray\n",
    "            The state based on which an action needs to be sampled.\n",
    "\n",
    "        train: bool\n",
    "            Wether we're training the network or not\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[int, torch.Tensor]\n",
    "            The sampled action and its log probability.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert state to tensor\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Get action logits from policy network\n",
    "        if not train:\n",
    "            with torch.no_grad():\n",
    "                action_logits = self(state_tensor)\n",
    "        else:\n",
    "            action_logits = self(state_tensor)\n",
    "\n",
    "        # Create mask for legal moves\n",
    "        legal_moves = env.legal_moves\n",
    "        mask = torch.ones_like(action_logits) * float('-inf')\n",
    "\n",
    "        for move in legal_moves:\n",
    "            move_idx = env._move_to_index(move)\n",
    "            mask[0, move_idx] = 0\n",
    "\n",
    "        # Apply mask to logits\n",
    "        masked_logits = action_logits + mask\n",
    "\n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(masked_logits, dim=1)\n",
    "\n",
    "        # Create categorical distribution\n",
    "        m = torch.distributions.Categorical(probs)\n",
    "\n",
    "        # Sample action\n",
    "        action = m.sample()\n",
    "\n",
    "        # Get log probability\n",
    "        log_prob = m.log_prob(action)\n",
    "\n",
    "        return action.item(), log_prob\n",
    "\n",
    "    @classmethod\n",
    "    def sample_one_episode(\n",
    "            cls,\n",
    "            env,\n",
    "            policy_nn,\n",
    "            policy_nn_adversary=None,\n",
    "            main_player_first=True,\n",
    "            max_episode_duration=500,\n",
    "            gamma=0.99,\n",
    "            train=False,\n",
    "            heuristic_scale=0.4,  # scaling heuristic rewards\n",
    "            opponent_reward_weight=0.5  # Weight for opponent's reward\n",
    "    ) -> Tuple[\n",
    "        List[np.ndarray], List[int], List[float], List[torch.Tensor],\n",
    "        List[np.ndarray], List[int], List[float], List[torch.Tensor]\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Execute one episode within the `env` environment utilizing the policy defined by the `policy_nn` parameter.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        env : gym.Env\n",
    "            The environment to play in.\n",
    "        policy_nn : PolicyNetwork\n",
    "            The policy neural network.\n",
    "        policy_nn_adversary : PolicyNetwork\n",
    "            The adversary policy neural network.\n",
    "        max_episode_duration : int\n",
    "            The maximum duration of the episode.\n",
    "        gamma : float\n",
    "            Discount factor.\n",
    "        train : bool\n",
    "            Wether we're training the networks or not\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[List[np.ndarray], List[int], List[float], List[torch.Tensor]]\n",
    "            The states, actions, rewards, and log probability of action for each time step in the episode.\n",
    "        \"\"\"\n",
    "        policy1_states = []\n",
    "        policy1_actions = []\n",
    "        policy1_rewards = []\n",
    "        policy1_log_probs = []\n",
    "\n",
    "        policy2_states = []\n",
    "        policy2_actions = []\n",
    "        policy2_rewards = []\n",
    "        policy2_log_probs = []\n",
    "\n",
    "        # Tracking move-by-move rewards for both players\n",
    "        all_p1_rewards = []  # Rewards when policy1 makes moves\n",
    "        all_p2_rewards = []  # Rewards when policy2 makes moves\n",
    "        move_indices = []  # Track which player made each move\n",
    "\n",
    "        state, info = env.reset(options={'is_first_player': main_player_first})\n",
    "        done = False\n",
    "        is_policy1_red = env.is_first_player\n",
    "        current_player = 0  # Start with RED (0)\n",
    "\n",
    "        t = 0\n",
    "        while t < max_episode_duration and not done:\n",
    "            is_policy1_turn = (current_player == 0 and is_policy1_red) or \\\n",
    "                              (current_player == 1 and not is_policy1_red)\n",
    "\n",
    "            # Record state and get action\n",
    "            if is_policy1_turn:\n",
    "                policy1_states.append(state)\n",
    "                action, log_prob = policy_nn.sample_discrete_action(env, state, train=train)\n",
    "                policy1_actions.append(action)\n",
    "                policy1_log_probs.append(log_prob)\n",
    "            else:\n",
    "                policy2_states.append(state)\n",
    "                action, log_prob = policy_nn_adversary.sample_discrete_action(env, state, train=train)\n",
    "                policy2_actions.append(action)\n",
    "                policy2_log_probs.append(log_prob)\n",
    "\n",
    "            # Execute action\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # Store raw reward and player index for this move\n",
    "            if is_policy1_turn:\n",
    "                all_p1_rewards.append(reward)\n",
    "                move_indices.append(1)  # Policy 1 made this move\n",
    "            else:\n",
    "                all_p2_rewards.append(reward if is_policy1_red else -reward)  # Adjust perspective\n",
    "                move_indices.append(2)  # Policy 2 made this move\n",
    "\n",
    "            # Apply heuristic scaling for non-terminal rewards\n",
    "            if not done:\n",
    "                if is_policy1_turn:\n",
    "                    all_p1_rewards[-1] *= heuristic_scale\n",
    "                else:\n",
    "                    all_p2_rewards[-1] *= heuristic_scale\n",
    "\n",
    "            # Prepare for next step\n",
    "            state = next_state\n",
    "            current_player = 1 - current_player\n",
    "            t += 1\n",
    "\n",
    "        # Reconstruct rewards with opponent consideration\n",
    "        p1_idx = 0\n",
    "        p2_idx = 0\n",
    "\n",
    "        for i, player in enumerate(move_indices):\n",
    "            if player == 1:  # Policy 1's move\n",
    "                own_reward = all_p1_rewards[p1_idx]\n",
    "                p1_idx += 1\n",
    "\n",
    "                # Add opponent's negated reward from previous move if available\n",
    "                if i > 0 and move_indices[i - 1] == 2:\n",
    "                    opp_reward = -all_p2_rewards[p2_idx - 1] * opponent_reward_weight\n",
    "                    policy1_rewards.append(own_reward + opp_reward)\n",
    "                else:\n",
    "                    policy1_rewards.append(own_reward)\n",
    "\n",
    "            else:  # Policy 2's move\n",
    "                own_reward = all_p2_rewards[p2_idx]\n",
    "                p2_idx += 1\n",
    "\n",
    "                # Add opponent's negated reward from previous move if available\n",
    "                if i > 0 and move_indices[i - 1] == 1:\n",
    "                    opp_reward = -all_p1_rewards[p1_idx - 1] * opponent_reward_weight\n",
    "                    policy2_rewards.append(own_reward + opp_reward)\n",
    "                else:\n",
    "                    policy2_rewards.append(own_reward)\n",
    "\n",
    "        # Calculate returns\n",
    "        policy1_returns = []\n",
    "        G = 0\n",
    "        for r in reversed(policy1_rewards):\n",
    "            # print(\"Policy 1 reward:\", r)\n",
    "            G = r + gamma * G\n",
    "            policy1_returns.insert(0, G)\n",
    "\n",
    "        policy2_returns = []\n",
    "        G = 0\n",
    "        for r in reversed(policy2_rewards):\n",
    "            # print(\"Policy 2 reward:\", r)\n",
    "            G = r + gamma * G\n",
    "            policy2_returns.insert(0, G)\n",
    "\n",
    "        return (\n",
    "            policy1_states, policy1_actions, policy1_returns, policy1_log_probs,\n",
    "            policy2_states, policy2_actions, policy2_returns, policy2_log_probs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the untrained agent against itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7yA2QDRYSvz"
   },
   "outputs": [],
   "source": [
    "# Initialize Policy-Networks\n",
    "policy_network = PolicyNetwork(board_size=BOARD_SIZE).to(device)\n",
    "policy_network_adversary = PolicyNetwork(board_size=BOARD_SIZE).to(device)\n",
    "\n",
    "print(f\"Starting Policy-Network vs Policy-Network test...\")\n",
    "print(f\"Board size: {BOARD_SIZE}x{BOARD_SIZE}\")\n",
    "\n",
    "# Run test\n",
    "stats = test_functions.test_policy_network_agent(\n",
    "    env_port=3,\n",
    "    policy_network=policy_network,\n",
    "    policy_network_adversary=policy_network_adversary,\n",
    "    num_episode=num_episodes,\n",
    "    render=(render_mode == 'human'),\n",
    ")\n",
    "\n",
    "print(\"\\nGame Results:\")\n",
    "print(f\"Winner: {stats['winner']}\")\n",
    "print(f\"Steps: {stats['steps']}\")\n",
    "print(f\"Main Network played as: {stats['main_network_role']}\")\n",
    "print(f\"Adversary Network played as: {stats['adversary_role']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOfQXo8fYSvz"
   },
   "source": [
    "#### Testing the untrained agent against random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkEBw_WOYSvz",
    "outputId": "705594bd-6ba9-4e1a-9ef1-de5d21985f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "\n",
      "Episode 1/5\n",
      "Policy Network plays first (RED)\n",
      "Random agent plays second (BLUE)\n",
      "\n",
      "Move 1\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R--BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Random (BLUE)\n",
      "Selected move: C4-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R--BBB\n",
      "C RRR--B\n",
      "B RRRRBB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R--BBB\n",
      "C RRR--B\n",
      "B RRRRRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R--B-B\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E -RRBBB\n",
      "D R--B-B\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E -RRBBB\n",
      "D R-B--B\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B4-C5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E -RRBBB\n",
      "D R-B--B\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Random (BLUE)\n",
      "Selected move: F3-E2\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E -RBBBB\n",
      "D R-B--B\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E --RBBB\n",
      "D R-B--B\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Random (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F -B--BQ\n",
      "E -BRBBB\n",
      "D R-B--B\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F -B--BQ\n",
      "E -BRBBB\n",
      "D R-B--B\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A RKRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 12\n",
      "Player: Random (BLUE)\n",
      "Selected move: E5-D4\n",
      "  012345\n",
      "F -B--BQ\n",
      "E -BRBB-\n",
      "D R-B-BB\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A RKRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 13\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E2-F3\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E -B-BB-\n",
      "D R-B-BB\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A RKRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 14\n",
      "Player: Random (BLUE)\n",
      "Selected move: D2-C1\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E -B-BB-\n",
      "D R---BB\n",
      "C RBR-BR\n",
      "B RRRR-B\n",
      "A RKRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 15\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D0-C1\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E -B-BB-\n",
      "D ----BB\n",
      "C RRR-BR\n",
      "B RRRR-B\n",
      "A RKRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 16\n",
      "Player: Random (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E -B-BB-\n",
      "D ----BB\n",
      "C RRR-BR\n",
      "B RRRR--\n",
      "A RKRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 17\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E -B-BB-\n",
      "D ----BB\n",
      "C RRR-BR\n",
      "B RKRR--\n",
      "A RRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 18\n",
      "Player: Random (BLUE)\n",
      "Selected move: A5-A4\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E -B-BB-\n",
      "D ----BB\n",
      "C RRR-BR\n",
      "B RKRR--\n",
      "A RRRRB-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 19\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F -B-RBQ\n",
      "E -B-BB-\n",
      "D ---RBB\n",
      "C RR--BR\n",
      "B RKRR--\n",
      "A RRRRB-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 20\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -B-BQ-\n",
      "D ---RBB\n",
      "C RR--BR\n",
      "B RKRR--\n",
      "A RRRRB-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 21\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -B-BQ-\n",
      "D -R-RBB\n",
      "C R---BR\n",
      "B RKRR--\n",
      "A RRRRB-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 22\n",
      "Player: Random (BLUE)\n",
      "Selected move: A4-B3\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -B-BQ-\n",
      "D -R-RBB\n",
      "C R---BR\n",
      "B RKRB--\n",
      "A RRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 23\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D3-E3\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -B-RQ-\n",
      "D -R--BB\n",
      "C R---BR\n",
      "B RKRB--\n",
      "A RRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 24\n",
      "Player: Random (BLUE)\n",
      "Selected move: B3-B2\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -B-RQ-\n",
      "D -R--BB\n",
      "C R---BR\n",
      "B RKB---\n",
      "A RRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 25\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -BRRQ-\n",
      "D ----BB\n",
      "C R---BR\n",
      "B RKB---\n",
      "A RRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 26\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -BRQ--\n",
      "D ----BB\n",
      "C R---BR\n",
      "B RKB---\n",
      "A RRRR--\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 27\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C0-D0\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -BRQ--\n",
      "D R---BB\n",
      "C ----BR\n",
      "B RKB---\n",
      "A RRRR--\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 28\n",
      "Player: Random (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -BR---\n",
      "D R--QBB\n",
      "C ----BR\n",
      "B RKB---\n",
      "A RRRR--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 29\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B0-C0\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -BR---\n",
      "D R--QBB\n",
      "C R---BR\n",
      "B -KB---\n",
      "A RRRR--\n",
      "BLUE KING Position: (3,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 30\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -BR---\n",
      "D R-Q-BB\n",
      "C R---BR\n",
      "B -KB---\n",
      "A RRRR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 31\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F -B-RBB\n",
      "E -BR---\n",
      "D R-Q-BB\n",
      "C R-K-BR\n",
      "B --B---\n",
      "A RRRR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 32\n",
      "Player: Random (BLUE)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F -B-RBB\n",
      "E --B---\n",
      "D R-Q-BB\n",
      "C R-K-BR\n",
      "B --B---\n",
      "A RRRR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 33\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F -B-RBB\n",
      "E --B---\n",
      "D R-Q-BB\n",
      "C R-K-BR\n",
      "B -RB---\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 34\n",
      "Player: Random (BLUE)\n",
      "Selected move: B2-B1\n",
      "  012345\n",
      "F -B-RBB\n",
      "E --B---\n",
      "D R-Q-BB\n",
      "C R-K-BR\n",
      "B -B----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 35\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C2-B1\n",
      "  012345\n",
      "F -B-RBB\n",
      "E --B---\n",
      "D R-Q-BB\n",
      "C R---BR\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 36\n",
      "Player: Random (BLUE)\n",
      "Selected move: F4-F3\n",
      "  012345\n",
      "F -B-B-B\n",
      "E --B---\n",
      "D R-Q-BB\n",
      "C R---BR\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 37\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F -B-B-B\n",
      "E --B---\n",
      "D R-Q-BB\n",
      "C R---R-\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 38\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F -B-B-B\n",
      "E --B---\n",
      "D R-QB-B\n",
      "C R---R-\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 39\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C4-D4\n",
      "  012345\n",
      "F -B-B-B\n",
      "E --B---\n",
      "D R-QBRB\n",
      "C R-----\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 40\n",
      "Player: Random (BLUE)\n",
      "Selected move: D5-C5\n",
      "  012345\n",
      "F -B-B-B\n",
      "E --B---\n",
      "D R-QBR-\n",
      "C R----B\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 41\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D4-E5\n",
      "  012345\n",
      "F -B-B-B\n",
      "E --B--R\n",
      "D R-QB--\n",
      "C R----B\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 42\n",
      "Player: Random (BLUE)\n",
      "Selected move: E2-D1\n",
      "  012345\n",
      "F -B-B-B\n",
      "E -----R\n",
      "D RBQB--\n",
      "C R----B\n",
      "B -K----\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 43\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F -B-B-B\n",
      "E -----R\n",
      "D RBQB--\n",
      "C R-K--B\n",
      "B ------\n",
      "A R-RR--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 44\n",
      "Player: Random (BLUE)\n",
      "Selected move: D2-C1\n",
      "  012345\n",
      "F -B-B-B\n",
      "E -----R\n",
      "D RB-B--\n",
      "C RQK--B\n",
      "B ------\n",
      "A R-RR--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 45\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F -B-B-B\n",
      "E -----R\n",
      "D RB-B--\n",
      "C RQK--B\n",
      "B --R---\n",
      "A R--R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 46\n",
      "Player: Random (BLUE)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F -B-B-B\n",
      "E -----R\n",
      "D RB-B--\n",
      "C RQK-B-\n",
      "B --R---\n",
      "A R--R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 47\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F -B-B-B\n",
      "E -----R\n",
      "D RB-B--\n",
      "C RQK-B-\n",
      "B -RR---\n",
      "A ---R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 48\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-C2\n",
      "  012345\n",
      "F -B-B-B\n",
      "E -----R\n",
      "D RB----\n",
      "C RQB-B-\n",
      "B -RR---\n",
      "A ---R--\n",
      "BLUE KING Position: (2,1)\n",
      "\n",
      "\n",
      "Game Over! Winner: random\n",
      "\n",
      "Episode 2/5\n",
      "Policy Network plays first (RED)\n",
      "Random agent plays second (BLUE)\n",
      "\n",
      "Move 1\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R--BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F -BBBBB\n",
      "E R-RBQB\n",
      "D R--BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E2-F1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E R--BQB\n",
      "D R--BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Random (BLUE)\n",
      "Selected move: E3-E2\n",
      "  012345\n",
      "F -RBBBB\n",
      "E R-B-QB\n",
      "D R--BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F -RBBBB\n",
      "E R-B-QB\n",
      "D R-RBBB\n",
      "C RR--BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F -RBBBB\n",
      "E R-BQ-B\n",
      "D R-RBBB\n",
      "C RR--BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBQ-B\n",
      "D R-RBBB\n",
      "C RR--BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Random (BLUE)\n",
      "Selected move: B5-B4\n",
      "  012345\n",
      "F -RBBBB\n",
      "E -RBQ-B\n",
      "D R-RBBB\n",
      "C RR--BB\n",
      "B RRRRB-\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F -RBBBB\n",
      "E --RQ-B\n",
      "D R-RBBB\n",
      "C RR--BB\n",
      "B RRRRB-\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Random (BLUE)\n",
      "Selected move: F2-F1\n",
      "  012345\n",
      "F -B-BBB\n",
      "E --RQ-B\n",
      "D R-RBBB\n",
      "C RR--BB\n",
      "B RRRRB-\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F -B-BBB\n",
      "E --RQ-B\n",
      "D R-RBBB\n",
      "C RRR-BB\n",
      "B R-RRB-\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-C2\n",
      "  012345\n",
      "F -B-BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C RRB-BB\n",
      "B R-RRB-\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F -B-BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C RRB-BB\n",
      "B RRRRB-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Random (BLUE)\n",
      "Selected move: C2-C1\n",
      "  012345\n",
      "F -B-BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C RB--BB\n",
      "B RRRRB-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B3-B4\n",
      "  012345\n",
      "F -B-BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C RB--BB\n",
      "B RRR-R-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Random (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B--BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C RB--BB\n",
      "B RRR-R-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F B--BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C RB--BB\n",
      "B RKR-R-\n",
      "A R-RRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 18\n",
      "Player: Random (BLUE)\n",
      "Selected move: C1-B2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C R---BB\n",
      "B RKB-R-\n",
      "A R-RRR-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 19\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A3-B3\n",
      "  012345\n",
      "F B--BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C R---BB\n",
      "B RKBRR-\n",
      "A R-R-R-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 20\n",
      "Player: Random (BLUE)\n",
      "Selected move: B2-A2\n",
      "  012345\n",
      "F B--BBB\n",
      "E --RQ-B\n",
      "D R-R-BB\n",
      "C R---BB\n",
      "B RK-RR-\n",
      "A R-B-R-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 21\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E2-F3\n",
      "  012345\n",
      "F B--RBB\n",
      "E ---Q-B\n",
      "D R-R-BB\n",
      "C R---BB\n",
      "B RK-RR-\n",
      "A R-B-R-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 22\n",
      "Player: Random (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F B--RBB\n",
      "E ---Q-B\n",
      "D R-R-BB\n",
      "C R----B\n",
      "B RK-BR-\n",
      "A R-B-R-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 23\n",
      "Player: Policy Network (RED)\n",
      "Selected move: F3-F4\n",
      "  012345\n",
      "F B---RB\n",
      "E ---Q-B\n",
      "D R-R-BB\n",
      "C R----B\n",
      "B RK-BR-\n",
      "A R-B-R-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 24\n",
      "Player: Random (BLUE)\n",
      "Selected move: B3-B2\n",
      "  012345\n",
      "F B---RB\n",
      "E ---Q-B\n",
      "D R-R-BB\n",
      "C R----B\n",
      "B RKB-R-\n",
      "A R-B-R-\n",
      "BLUE KING Position: (4,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 25\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D2-E3\n",
      "  012345\n",
      "F B---RB\n",
      "E ---R-B\n",
      "D R---BB\n",
      "C R----B\n",
      "B RKB-R-\n",
      "A R-B-R-\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Game Over! Winner: policy_network\n",
      "\n",
      "Episode 3/5\n",
      "Policy Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F5-E5\n",
      "  012345\n",
      "F -BBBBB\n",
      "E R-BBBQ\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A KRR-R-\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F -BBBBB\n",
      "E R-BBBQ\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A RKR-R-\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-BBBQ\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A RKR-R-\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-RBBQ\n",
      "D R--BBB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A RKR-R-\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-E2\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-BBBQ\n",
      "D R---BB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A RKR-R-\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: A1-B2\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-BBBQ\n",
      "D R---BB\n",
      "C RRR-BB\n",
      "B RRKRRB\n",
      "A RRR-R-\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E5-D4\n",
      "  012345\n",
      "F B-BBBB\n",
      "E R-BBBB\n",
      "D R---QB\n",
      "C RRR-BB\n",
      "B RRKRRB\n",
      "A RRR-R-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBBBB\n",
      "D ----QB\n",
      "C RRR-BB\n",
      "B RRKRRB\n",
      "A RRR-R-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-A4\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBBBB\n",
      "D ----QB\n",
      "C RRR-BB\n",
      "B RRKRR-\n",
      "A RRR-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: A2-A3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBBBB\n",
      "D ----QB\n",
      "C RRR-BB\n",
      "B RRKRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-BB\n",
      "D ---BQB\n",
      "C RRR-BB\n",
      "B RRKRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,2)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: B2-C2\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRB-BB\n",
      "D ---BQB\n",
      "C RRK-BB\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBB-B\n",
      "D ---BQB\n",
      "C RRK-BB\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBB-B\n",
      "D --KBQB\n",
      "C RR--BB\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (3,2)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBB-B\n",
      "D --KBQB\n",
      "C RR-B-B\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (3,2)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: E1-F2\n",
      "  012345\n",
      "F B-RBBB\n",
      "E R-BB-B\n",
      "D --KBQB\n",
      "C RR-B-B\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (3,2)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E5-E4\n",
      "  012345\n",
      "F B-RBBB\n",
      "E R-BBB-\n",
      "D --KBQB\n",
      "C RR-B-B\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (3,2)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: D2-D3\n",
      "  012345\n",
      "F B-RBBB\n",
      "E R-BBB-\n",
      "D ---KQB\n",
      "C RR-B-B\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (3,3)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F B-RBBB\n",
      "E R-BBB-\n",
      "D ---K-B\n",
      "C RR-BQB\n",
      "B RRRRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (2,4)\n",
      "RED KING Position: (3,3)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F B-RBBB\n",
      "E R-BBB-\n",
      "D ---K-B\n",
      "C RRRBQB\n",
      "B R-RRR-\n",
      "A RR-RB-\n",
      "BLUE KING Position: (2,4)\n",
      "RED KING Position: (3,3)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-B5\n",
      "  012345\n",
      "F B-RBBB\n",
      "E R-BBB-\n",
      "D ---K-B\n",
      "C RRRBQ-\n",
      "B R-RRRB\n",
      "A RR-RB-\n",
      "BLUE KING Position: (2,4)\n",
      "RED KING Position: (3,3)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F0\n",
      "  012345\n",
      "F R-RBBB\n",
      "E --BBB-\n",
      "D ---K-B\n",
      "C RRRBQ-\n",
      "B R-RRRB\n",
      "A RR-RB-\n",
      "BLUE KING Position: (2,4)\n",
      "RED KING Position: (3,3)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C3-D3\n",
      "  012345\n",
      "F R-RBBB\n",
      "E --BBB-\n",
      "D ---B-B\n",
      "C RRR-Q-\n",
      "B R-RRRB\n",
      "A RR-RB-\n",
      "BLUE KING Position: (2,4)\n",
      "\n",
      "\n",
      "Game Over! Winner: policy_network\n",
      "\n",
      "Episode 4/5\n",
      "Policy Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: D1-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D R-RBBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-F0\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E R-BBBB\n",
      "D R-RBBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E RRBBBB\n",
      "D --RBBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E RRBBBB\n",
      "D --RBBB\n",
      "C RRRB-B\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E RRBBBB\n",
      "D -RRBBB\n",
      "C R-RB-B\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E RRBBBB\n",
      "D -RRBBB\n",
      "C R-RBB-\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: B3-B4\n",
      "  012345\n",
      "F B-BBBQ\n",
      "E RRBBBB\n",
      "D -RRBBB\n",
      "C R-RBB-\n",
      "B RRR-RB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBBQB\n",
      "D -RRBBB\n",
      "C R-RBB-\n",
      "B RRR-RB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C1\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBBQB\n",
      "D -RRBBB\n",
      "C RRRBB-\n",
      "B R-R-RB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F B-BBBB\n",
      "E RRBBQB\n",
      "D -RRBBB\n",
      "C RRR-B-\n",
      "B R-RBRB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: E1-F0\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R-BBQB\n",
      "D -RRBBB\n",
      "C RRR-B-\n",
      "B R-RBRB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-B2\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R-BBQB\n",
      "D -RRBBB\n",
      "C RRR-B-\n",
      "B R-B-RB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R-RBQB\n",
      "D --RBBB\n",
      "C RRR-B-\n",
      "B R-B-RB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R-RBBB\n",
      "D --RBQB\n",
      "C RRR-B-\n",
      "B R-B-RB\n",
      "A KRRRR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R-RBBB\n",
      "D --RBQB\n",
      "C RRR-B-\n",
      "B R-R-RB\n",
      "A KR-RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-B4\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R-RBBB\n",
      "D --RBQB\n",
      "C RRR-B-\n",
      "B R-R-B-\n",
      "A KR-RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: E2-E3\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R--RBB\n",
      "D --RBQB\n",
      "C RRR-B-\n",
      "B R-R-B-\n",
      "A KR-RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R--RBB\n",
      "D --RBQB\n",
      "C RRRB--\n",
      "B R-R-B-\n",
      "A KR-RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F R-BBBB\n",
      "E R--RBB\n",
      "D --RBQB\n",
      "C RRRB--\n",
      "B R-R-B-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F3-E3\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R--BBB\n",
      "D --RBQB\n",
      "C RRRB--\n",
      "B R-R-B-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E2\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R-RBBB\n",
      "D ---BQB\n",
      "C RRRB--\n",
      "B R-R-B-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R-RBBB\n",
      "D ---BQ-\n",
      "C RRRBB-\n",
      "B R-R-B-\n",
      "A K-RRR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B3\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R-RBBB\n",
      "D ---BQ-\n",
      "C RRRBB-\n",
      "B R-RRB-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R-RBBB\n",
      "D ---BQ-\n",
      "C RRR-B-\n",
      "B R-RBB-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R-RBBB\n",
      "D --RBQ-\n",
      "C R-R-B-\n",
      "B R-RBB-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 26\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-B2\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R-RBBB\n",
      "D --RBQ-\n",
      "C R-R-B-\n",
      "B R-B-B-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: E2-E3\n",
      "  012345\n",
      "F R-B-BB\n",
      "E R--RBB\n",
      "D --RBQ-\n",
      "C R-R-B-\n",
      "B R-B-B-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 28\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F4-E3\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--BBB\n",
      "D --RBQ-\n",
      "C R-R-B-\n",
      "B R-B-B-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: D2-D3\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--BBB\n",
      "D ---RQ-\n",
      "C R-R-B-\n",
      "B R-B-B-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 30\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-C3\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--BBB\n",
      "D ---RQ-\n",
      "C R-RB--\n",
      "B R-B-B-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--BBB\n",
      "D --RRQ-\n",
      "C R--B--\n",
      "B R-B-B-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 32\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--BBB\n",
      "D --RRQ-\n",
      "C R-----\n",
      "B R-BBB-\n",
      "A K--RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--BBB\n",
      "D --RRQ-\n",
      "C R-----\n",
      "B RKBBB-\n",
      "A ---RR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 34\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B2-A3\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--BBB\n",
      "D --RRQ-\n",
      "C R-----\n",
      "B RK-BB-\n",
      "A ---BR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E2\n",
      "  012345\n",
      "F R-B--B\n",
      "E R-RBBB\n",
      "D ---RQ-\n",
      "C R-----\n",
      "B RK-BB-\n",
      "A ---BR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 36\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-B2\n",
      "  012345\n",
      "F R-B--B\n",
      "E R-RBBB\n",
      "D ---RQ-\n",
      "C R-----\n",
      "B RKB-B-\n",
      "A ---BR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: E2-E3\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--RBB\n",
      "D ---RQ-\n",
      "C R-----\n",
      "B RKB-B-\n",
      "A ---BR-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 38\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: A3-A4\n",
      "  012345\n",
      "F R-B--B\n",
      "E R--RBB\n",
      "D ---RQ-\n",
      "C R-----\n",
      "B RKB-B-\n",
      "A ----B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: E3-F2\n",
      "  012345\n",
      "F R-R--B\n",
      "E R---BB\n",
      "D ---RQ-\n",
      "C R-----\n",
      "B RKB-B-\n",
      "A ----B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 40\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F R-R--B\n",
      "E R--B-B\n",
      "D ---RQ-\n",
      "C R-----\n",
      "B RKB-B-\n",
      "A ----B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F R-R--B\n",
      "E R--B-B\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B RKB-B-\n",
      "A ----B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 42\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B2-A1\n",
      "  012345\n",
      "F R-R--B\n",
      "E R--B-B\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B RK--B-\n",
      "A -B--B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: B1-A1\n",
      "  012345\n",
      "F R-R--B\n",
      "E R--B-B\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B R---B-\n",
      "A -K--B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 44\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F R-R-B-\n",
      "E R--B-B\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B R---B-\n",
      "A -K--B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F R-R-B-\n",
      "E R--B-B\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B R---B-\n",
      "A --K-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 46\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E3-F2\n",
      "  012345\n",
      "F R-B-B-\n",
      "E R----B\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B R---B-\n",
      "A --K-B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 47\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B3\n",
      "  012345\n",
      "F R-B-B-\n",
      "E R----B\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B R--KB-\n",
      "A ----B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,3)\n",
      "\n",
      "Move 48\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F R-B---\n",
      "E R---BB\n",
      "D ---RQ-\n",
      "C -R----\n",
      "B R--KB-\n",
      "A ----B-\n",
      "BLUE KING Position: (3,4)\n",
      "RED KING Position: (1,3)\n",
      "\n",
      "Move 49\n",
      "Player: Random (RED)\n",
      "Selected move: D3-D4\n",
      "  012345\n",
      "F R-B---\n",
      "E R---BB\n",
      "D ----R-\n",
      "C -R----\n",
      "B R--KB-\n",
      "A ----B-\n",
      "RED KING Position: (1,3)\n",
      "\n",
      "Game Over! Winner: random\n",
      "\n",
      "Episode 5/5\n",
      "Policy Network plays first (RED)\n",
      "Random agent plays second (BLUE)\n",
      "\n",
      "Move 1\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D1-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D R-RBBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F -BBBBB\n",
      "E R-BBQB\n",
      "D R-RBBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C0-D1\n",
      "  012345\n",
      "F -BBBBB\n",
      "E R-BBQB\n",
      "D RRRBBB\n",
      "C -RR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Random (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F -B-BBB\n",
      "E RBBBQB\n",
      "D RRRBBB\n",
      "C -RR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -RBBQB\n",
      "D RRRBBB\n",
      "C -RR-BB\n",
      "B RRRR-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Random (BLUE)\n",
      "Selected move: B5-B4\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -RBBQB\n",
      "D RRRBBB\n",
      "C -RR-BB\n",
      "B RRRRB-\n",
      "A KRRRR-\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A4-B5\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -RBBQB\n",
      "D RRRBBB\n",
      "C -RR-BB\n",
      "B RRRRBR\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Random (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -RBBQB\n",
      "D RRRBBB\n",
      "C -RR--B\n",
      "B RRRBBR\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D2-D3\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -RBBQB\n",
      "D RR-RBB\n",
      "C -RR--B\n",
      "B RRRBBR\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F -B-BBB\n",
      "E -RBBQB\n",
      "D RR-R-B\n",
      "C -RRB-B\n",
      "B RRRBBR\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E1-F1\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --BBQB\n",
      "D RR-R-B\n",
      "C -RRB-B\n",
      "B RRRBBR\n",
      "A KRRR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Random (BLUE)\n",
      "Selected move: B3-A2\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --BBQB\n",
      "D RR-R-B\n",
      "C -RRB-B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D3-E2\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --RBQB\n",
      "D RR---B\n",
      "C -RRB-B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Random (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --R-QB\n",
      "D RRB--B\n",
      "C -RRB-B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E2-D2\n",
      "  012345\n",
      "F -R-BBB\n",
      "E ----QB\n",
      "D RRR--B\n",
      "C -RRB-B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Random (BLUE)\n",
      "Selected move: C3-D2\n",
      "  012345\n",
      "F -R-BBB\n",
      "E ----QB\n",
      "D RRB--B\n",
      "C -RR--B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --R-QB\n",
      "D R-B--B\n",
      "C -RR--B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Random (BLUE)\n",
      "Selected move: D2-C1\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --R-QB\n",
      "D R----B\n",
      "C -BR--B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D0-C1\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --R-QB\n",
      "D -----B\n",
      "C -RR--B\n",
      "B RRR-BR\n",
      "A KRBR--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Random (BLUE)\n",
      "Selected move: B4-A3\n",
      "  012345\n",
      "F -R-BBB\n",
      "E --R-QB\n",
      "D -----B\n",
      "C -RR--B\n",
      "B RRR--R\n",
      "A KRBB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E2-F3\n",
      "  012345\n",
      "F -R-RBB\n",
      "E ----QB\n",
      "D -----B\n",
      "C -RR--B\n",
      "B RRR--R\n",
      "A KRBB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 22\n",
      "Player: Random (BLUE)\n",
      "Selected move: E5-D4\n",
      "  012345\n",
      "F -R-RBB\n",
      "E ----Q-\n",
      "D ----BB\n",
      "C -RR--B\n",
      "B RRR--R\n",
      "A KRBB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 23\n",
      "Player: Policy Network (RED)\n",
      "Selected move: F1-F2\n",
      "  012345\n",
      "F --RRBB\n",
      "E ----Q-\n",
      "D ----BB\n",
      "C -RR--B\n",
      "B RRR--R\n",
      "A KRBB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 24\n",
      "Player: Random (BLUE)\n",
      "Selected move: C5-C4\n",
      "  012345\n",
      "F --RRBB\n",
      "E ----Q-\n",
      "D ----BB\n",
      "C -RR-B-\n",
      "B RRR--R\n",
      "A KRBB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 25\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B1-A2\n",
      "  012345\n",
      "F --RRBB\n",
      "E ----Q-\n",
      "D ----BB\n",
      "C -RR-B-\n",
      "B R-R--R\n",
      "A KRRB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 26\n",
      "Player: Random (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F --RRBB\n",
      "E ----Q-\n",
      "D ----BB\n",
      "C -RR---\n",
      "B R-RB-R\n",
      "A KRRB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 27\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F --RRBB\n",
      "E ----Q-\n",
      "D ----BB\n",
      "C -RR---\n",
      "B RRRB-R\n",
      "A K-RB--\n",
      "BLUE KING Position: (4,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 28\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-F3\n",
      "  012345\n",
      "F --RQBB\n",
      "E ------\n",
      "D ----BB\n",
      "C -RR---\n",
      "B RRRB-R\n",
      "A K-RB--\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 29\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B2-A3\n",
      "  012345\n",
      "F --RQBB\n",
      "E ------\n",
      "D ----BB\n",
      "C -RR---\n",
      "B RR-B-R\n",
      "A K-RR--\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 30\n",
      "Player: Random (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F --RQBB\n",
      "E ------\n",
      "D ----BB\n",
      "C -RB---\n",
      "B RR---R\n",
      "A K-RR--\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 31\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F --RQBB\n",
      "E ------\n",
      "D ----BB\n",
      "C -RB---\n",
      "B RK---R\n",
      "A R-RR--\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 32\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F --RQBB\n",
      "E ------\n",
      "D ---B-B\n",
      "C -RB---\n",
      "B RK---R\n",
      "A R-RR--\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 33\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F --RQBB\n",
      "E ------\n",
      "D ---B-B\n",
      "C -RK---\n",
      "B R----R\n",
      "A R-RR--\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 34\n",
      "Player: Random (BLUE)\n",
      "Selected move: F3-E2\n",
      "  012345\n",
      "F --R-BB\n",
      "E --Q---\n",
      "D ---B-B\n",
      "C -RK---\n",
      "B R----R\n",
      "A R-RR--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 35\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F --R-BB\n",
      "E --Q---\n",
      "D ---B-B\n",
      "C -RK---\n",
      "B R-R--R\n",
      "A R--R--\n",
      "BLUE KING Position: (4,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 36\n",
      "Player: Random (BLUE)\n",
      "Selected move: E2-D2\n",
      "  012345\n",
      "F --R-BB\n",
      "E ------\n",
      "D --QB-B\n",
      "C -RK---\n",
      "B R-R--R\n",
      "A R--R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 37\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F --R-BB\n",
      "E ------\n",
      "D --QB-B\n",
      "C -RK---\n",
      "B R-R--R\n",
      "A -R-R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 38\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-E4\n",
      "  012345\n",
      "F --R-B-\n",
      "E ----B-\n",
      "D --QB-B\n",
      "C -RK---\n",
      "B R-R--R\n",
      "A -R-R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 39\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A1-B1\n",
      "  012345\n",
      "F --R-B-\n",
      "E ----B-\n",
      "D --QB-B\n",
      "C -RK---\n",
      "B RRR--R\n",
      "A ---R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 40\n",
      "Player: Random (BLUE)\n",
      "Selected move: F4-E3\n",
      "  012345\n",
      "F --R---\n",
      "E ---BB-\n",
      "D --QB-B\n",
      "C -RK---\n",
      "B RRR--R\n",
      "A ---R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 41\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F --R---\n",
      "E ---BB-\n",
      "D --QB-B\n",
      "C -RKR--\n",
      "B RR---R\n",
      "A ---R--\n",
      "BLUE KING Position: (3,2)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 42\n",
      "Player: Random (BLUE)\n",
      "Selected move: D2-C1\n",
      "  012345\n",
      "F --R---\n",
      "E ---BB-\n",
      "D ---B-B\n",
      "C -QKR--\n",
      "B RR---R\n",
      "A ---R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 43\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C3-D4\n",
      "  012345\n",
      "F --R---\n",
      "E ---BB-\n",
      "D ---BRB\n",
      "C -QK---\n",
      "B RR---R\n",
      "A ---R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 44\n",
      "Player: Random (BLUE)\n",
      "Selected move: E3-D2\n",
      "  012345\n",
      "F --R---\n",
      "E ----B-\n",
      "D --BBRB\n",
      "C -QK---\n",
      "B RR---R\n",
      "A ---R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 45\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D4-D3\n",
      "  012345\n",
      "F --R---\n",
      "E ----B-\n",
      "D --BR-B\n",
      "C -QK---\n",
      "B RR---R\n",
      "A ---R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 46\n",
      "Player: Random (BLUE)\n",
      "Selected move: D2-D1\n",
      "  012345\n",
      "F --R---\n",
      "E ----B-\n",
      "D -B-R-B\n",
      "C -QK---\n",
      "B RR---R\n",
      "A ---R--\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 47\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A3-B3\n",
      "  012345\n",
      "F --R---\n",
      "E ----B-\n",
      "D -B-R-B\n",
      "C -QK---\n",
      "B RR-R-R\n",
      "A ------\n",
      "BLUE KING Position: (2,1)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 48\n",
      "Player: Random (BLUE)\n",
      "Selected move: C1-C0\n",
      "  012345\n",
      "F --R---\n",
      "E ----B-\n",
      "D -B-R-B\n",
      "C Q-K---\n",
      "B RR-R-R\n",
      "A ------\n",
      "BLUE KING Position: (2,0)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 49\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F --R---\n",
      "E ----B-\n",
      "D -B-R-B\n",
      "C Q-K-R-\n",
      "B RR---R\n",
      "A ------\n",
      "BLUE KING Position: (2,0)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 50\n",
      "Player: Random (BLUE)\n",
      "Selected move: D1-D0\n",
      "  012345\n",
      "F --R---\n",
      "E ----B-\n",
      "D B--R-B\n",
      "C Q-K-R-\n",
      "B RR---R\n",
      "A ------\n",
      "BLUE KING Position: (2,0)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Test Results Summary:\n",
      "Episodes: 5\n",
      "Policy Network wins: 2 (40.0%)\n",
      "Random agent wins: 2 (40.0%)\n",
      "Ties: 0 (0.0%)\n",
      "Average steps per episode: 39.2\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "policy_network = PolicyNetwork(board_size=BOARD_SIZE).to(device)\n",
    "results = test_functions.test_policy_network_vs_random(env_port=3, num_episodes=5, policy_network=policy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUZ8umqJYSvz"
   },
   "source": [
    "#### Test Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uY_OBv-wYSvz"
   },
   "source": [
    "`avg_return_on_multiple_episodes` function tests the given policy $\\pi_\\theta$ on `num_episodes` episodes (for fixed horizon $T$) and returns the average reward on the `num_episodes` episodes.\n",
    "\n",
    "The function `avg_return_on_multiple_episodes` is designed to play multiple episodes of a given environment using a specified policy neural network and calculate the average return. It takes as input the environment to play in, the policy neural networks to use, the number of episodes to play and the maximum duration of an episode.\n",
    "In each episode, it uses the `sample_one_episode` function to play the episode and collect the rewards. The function then returns the average of these cumulated rewards.\n",
    "\n",
    "`avg_return_on_multiple_episodes` will be used for evaluating the performance of a policy over multiple episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742283514879,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "7lviUcxCYSvz"
   },
   "outputs": [],
   "source": [
    "def avg_return_on_multiple_episodes(\n",
    "        env: gym.Env,\n",
    "        policy_nn: PolicyNetwork,\n",
    "        policy_nn_adversary: PolicyNetwork,\n",
    "        num_test_episode: int,\n",
    "        max_episode_duration: int | float = 500,\n",
    "        gamma: float = 0.99,\n",
    "        verbose: bool = False,\n",
    "        heuristic_scale: float = 0.3,\n",
    "        opponent_reward_weight: float = 0.5\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Play multiple episodes of the environment and calculate the average return.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : gym.Env\n",
    "        The environment to play in.\n",
    "    policy_nn : PolicyNetwork\n",
    "        The policy neural network.\n",
    "    policy_nn_adversary : PolicyNetwork\n",
    "        The adversary policy neural network.\n",
    "    num_test_episode : int\n",
    "        The number of episodes to play.\n",
    "    max_episode_duration : int\n",
    "        The maximum duration of an episode.\n",
    "    gamma : float\n",
    "        Discount factor.\n",
    "    verbose : bool\n",
    "        Wether to print detailed information\n",
    "    heuristic_scale : float\n",
    "        Heuristic values scaling factor.\n",
    "    opponent_reward_weight : float\n",
    "        Weight of opponent reward.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The average return.\n",
    "    \"\"\"\n",
    "    policy_network_class = policy_nn.__class__\n",
    "    total_return = 0.0\n",
    "    episode_returns = []\n",
    "\n",
    "    for episode in range(num_test_episode):\n",
    "        if verbose:\n",
    "            print(f\"Evaluating episode {episode + 1}/{num_test_episode}\")\n",
    "\n",
    "        # Sample an episode using the policy networks\n",
    "        returns = policy_network_class.sample_one_episode(\n",
    "            env=env,\n",
    "            policy_nn=policy_nn,\n",
    "            policy_nn_adversary=policy_nn_adversary,\n",
    "            max_episode_duration=max_episode_duration,\n",
    "            gamma=gamma,\n",
    "            heuristic_scale=heuristic_scale,\n",
    "            opponent_reward_weight=opponent_reward_weight\n",
    "        )[2]\n",
    "\n",
    "        # Calculate the episode return\n",
    "        if returns:  # Check if returns list is not empty\n",
    "            # The first element in returns is the cumulative discounted return for the whole episode\n",
    "            episode_return = returns[0]\n",
    "            total_return += episode_return\n",
    "            episode_returns.append(episode_return)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Episode {episode + 1} return: {episode_return:.2f}\")\n",
    "        else:\n",
    "            # Handle case where no returns were collected (e.g., if the main agent never got to act)\n",
    "            if verbose:\n",
    "                print(f\"Episode {episode + 1}: No returns collected\")\n",
    "\n",
    "    # Calculate average return\n",
    "    if episode_returns:\n",
    "        average_return = total_return / len(episode_returns)\n",
    "    else:\n",
    "        average_return = 0.0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Average return over {num_test_episode} episodes: {average_return:.2f}\")\n",
    "        if len(episode_returns) > 1:\n",
    "            print(f\"Min return: {min(episode_returns):.2f}, Max return: {max(episode_returns):.2f}\")\n",
    "\n",
    "    return average_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SL9HcKSYSv0"
   },
   "source": [
    "Testing this function on the untrained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB81sQKkYSv0"
   },
   "outputs": [],
   "source": [
    "port = 3\n",
    "render_mode = 'human'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH8Hhu1NYSv0"
   },
   "outputs": [],
   "source": [
    "policy_network = PolicyNetwork(board_size=BOARD_SIZE).to(device)\n",
    "policy_network_adversary = PolicyNetwork(board_size=BOARD_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVn84OQZYSv0",
    "outputId": "6030de5c-f376-4a2a-9fc7-1b0ed3fb45c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "Evaluating episode 1/5\n",
      "Episode 1 return: 0.00\n",
      "Evaluating episode 2/5\n",
      "Episode 2 return: 0.70\n",
      "Evaluating episode 3/5\n",
      "Episode 3 return: 0.76\n",
      "Evaluating episode 4/5\n",
      "Episode 4 return: 0.00\n",
      "Evaluating episode 5/5\n",
      "Episode 5 return: 0.78\n",
      "Average return over 5 episodes: 0.45\n",
      "Min return: 0.00, Max return: 0.78\n",
      "0.4473154583591647\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "env = kac.KingAndCourtesanEnv(port=port, render_mode=render_mode)\n",
    "\n",
    "average_return = avg_return_on_multiple_episodes(env=env, policy_nn=policy_network,\n",
    "                                                 policy_nn_adversary=policy_network_adversary, num_test_episode=5,\n",
    "                                                 verbose=True)\n",
    "\n",
    "print(average_return)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKKoN6G4YSv0"
   },
   "source": [
    "### 3.2 Train Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtWm0IJnYSv0"
   },
   "source": [
    "`train_reinforce_discrete` trains a policy network using the REINFORCE algorithm in the given environment. This function takes as input the environment, the number of training episodes, the number of tests to perform per episode, the maximum duration of an episode, and the learning rate for the optimizer.\n",
    "\n",
    "The function first initializes a policy network and an AdamW optimizer. Then, for each training episode, it generates an episode using the current policies (current player and adversary) and calculates the return at each time step. It uses this return and the log probability of the action taken at that time step to compute the loss, which is the negative of the product of the return and the log probability. This loss is used to update the policy network parameters using gradient ascent.\n",
    "\n",
    "After each training episode, the function tests the current policy by playing a number of test episodes and calculating the average return. This average return is added to a list for monitoring purposes.\n",
    "\n",
    "The function returns the trained policy network and the list of average returns for each episode. This function encapsulates the main loop of the REINFORCE algorithm, including the policy update step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reinforce_discrete(\n",
    "        env: gym.Env,\n",
    "        num_episodes: int = 5000,\n",
    "        max_episode_duration: int | float = 500,\n",
    "        learning_rate: float = 0.001,\n",
    "        gamma: float = 0.99,\n",
    "        entropy_coef: float = 0.01,  # entropy regularization coefficient\n",
    "        grad_clip: float = 10.0,  # gradient clipping threshold\n",
    "        eval_frequency: int = 50,  # evaluation frequency\n",
    "        verbose: bool = False,\n",
    "        checkpoint_dir: str = 'checkpoints/reinforce',\n",
    "        checkpoint_frequency: int = 50,\n",
    "        save_best_only: bool = False,\n",
    "        heuristic_scale=0.3,\n",
    "        opponent_reward_weight: float = 0.5\n",
    ") -> Tuple[PolicyNetwork, List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Enhanced training function for REINFORCE algorithm with self-play.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : gym.Env\n",
    "        The environment to train in.\n",
    "    num_episodes : int\n",
    "        The number of training episodes.\n",
    "    num_test_per_episode : int\n",
    "        The number of tests to perform per episode.\n",
    "    max_episode_duration : int\n",
    "        The maximum length of an episode.\n",
    "    learning_rate : float\n",
    "        The initial step size.\n",
    "    gamma : float\n",
    "        Discount factor for future rewards.\n",
    "    entropy_coef : float\n",
    "        Coefficient for entropy regularization.\n",
    "    grad_clip : float\n",
    "        Gradient clipping parameter.\n",
    "    eval_frequency : int\n",
    "        Frequency of evaluation.\n",
    "    verbose : bool\n",
    "        Whether to print detailed progress information.\n",
    "    checkpoint_dir : str\n",
    "        Directory to save checkpoints.\n",
    "    checkpoint_frequency : int\n",
    "        How often to save checkpoints.\n",
    "    save_best_only : bool\n",
    "        Whether to save only the best performing policy\n",
    "    heuristic_scale : float\n",
    "        Heuristic values scaling factor.\n",
    "    opponent_reward_weight : float\n",
    "        Weight of opponent reward.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[PolicyNetwork, List[float], List[float], List[float]]\n",
    "        The final trained policy, episode win rates and losses\n",
    "    \"\"\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    best_win_rate = float('-inf')\n",
    "\n",
    "    episodes_win_rates = []\n",
    "    main_network_episodes_losses = []\n",
    "    adversary_network_episodes_losses = []\n",
    "\n",
    "    # Initialize policy networks\n",
    "    policy_nn = PolicyNetwork(board_size=env.board_size).to(device)\n",
    "    policy_nn_adversary = PolicyNetwork(board_size=env.board_size).to(device)\n",
    "\n",
    "    # Initialize optimizers with weight decay\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        policy_nn.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=1e-5  # L2 regularization\n",
    "    )\n",
    "    optimizer_adversary = torch.optim.AdamW(\n",
    "        policy_nn_adversary.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "\n",
    "    # Initialize cosine annealing learning rate schedulers with warm restarts\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=500,  # Restart period\n",
    "        T_mult=2,  # Increase period after each restart\n",
    "        eta_min=1e-5  # Minimum learning rate\n",
    "    )\n",
    "    lr_scheduler_adversary = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer_adversary,\n",
    "        T_0=500,\n",
    "        T_mult=2,\n",
    "        eta_min=1e-5\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    for episode_index in tqdm(range(num_episodes)):\n",
    "\n",
    "        main_player_first = (episode_index % 2 == 0)\n",
    "        (main_states, main_actions, main_returns, main_log_probs,\n",
    "         adv_states, adv_actions, adv_returns, adv_log_probs) = PolicyNetwork.sample_one_episode(\n",
    "            env=env,\n",
    "            policy_nn=policy_nn,\n",
    "            policy_nn_adversary=policy_nn_adversary,\n",
    "            max_episode_duration=max_episode_duration,\n",
    "            gamma=gamma,\n",
    "            train=True,\n",
    "            heuristic_scale=heuristic_scale,\n",
    "            opponent_reward_weight=opponent_reward_weight\n",
    "        )\n",
    "\n",
    "        # Update main policy if it collected any experiences\n",
    "        if main_actions:\n",
    "            # Normalize returns for more stable training\n",
    "            # if len(main_returns) > 1:\n",
    "            #    main_returns_tensor = torch.FloatTensor(main_returns).to(device)\n",
    "            #   main_returns_normalized = (main_returns_tensor - main_returns_tensor.mean()) / (main_returns_tensor.std() + 1e-8)\n",
    "            # else:\n",
    "            # main_returns_normalized = torch.FloatTensor(main_returns).to(device)\n",
    "\n",
    "            # Compute policy loss with entropy regularization\n",
    "            policy_loss = 0\n",
    "            entropy = 0\n",
    "\n",
    "            # Add baseline normalization for returns\n",
    "            #if main_returns:\n",
    "            main_returns_tensor = torch.tensor(main_returns, device=device)\n",
    "            main_returns_adv_tensor = torch.tensor(adv_returns, device=device)\n",
    "            # if len(main_returns) > 1:\n",
    "            # Normalize returns for stability\n",
    "            main_returns_mean = main_returns_tensor.mean()\n",
    "            main_returns_std = main_returns_tensor.std() + 1e-8\n",
    "            main_returns_normalized = (main_returns_tensor - main_returns_mean) / main_returns_std\n",
    "\n",
    "            main_returns_adv_mean = main_returns_adv_tensor.mean()\n",
    "            main_returns_adv_std = main_returns_adv_tensor.std() + 1e-8\n",
    "            adv_retuns_normalized = (main_returns_adv_tensor - main_returns_adv_mean) / main_returns_adv_std\n",
    "            for t in range(len(main_returns_normalized)):\n",
    "                # Policy gradient loss\n",
    "                policy_loss -= main_log_probs[t] * main_returns_normalized[t]\n",
    "\n",
    "                # Entropy regularization (encourage exploration)\n",
    "                entropy -= main_log_probs[t].exp() * main_log_probs[t]\n",
    "\n",
    "            # Combine losses with coefficients\n",
    "            total_loss = policy_loss - entropy_coef * entropy\n",
    "\n",
    "            # Gradient update for main policy\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "\n",
    "            # Apply gradient clipping\n",
    "            if grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(policy_nn.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            if verbose and episode_index % 10 == 0:\n",
    "                print(\n",
    "                    f\"Episode {episode_index + 1} - Main Policy Loss: {policy_loss.item():.4f}, Entropy: {entropy.item():.4f}\")\n",
    "\n",
    "        # ADVERSARY TRAINING\n",
    "        # Sample episode from adversary's perspective\n",
    "\n",
    "        # Update adversary policy if it collected any experiences\n",
    "        if adv_actions:\n",
    "            # Normalize returns for more stable training\n",
    "            # if len(adv_returns) > 1:\n",
    "            #     adv_returns_tensor = torch.FloatTensor(adv_returns).to(device)\n",
    "            #     adv_returns_normalized = (adv_returns_tensor - adv_returns_tensor.mean()) / (adv_returns_tensor.std() + 1e-8)\n",
    "            # else:\n",
    "            #     adv_returns_normalized = torch.FloatTensor(adv_returns).to(device)\n",
    "\n",
    "            # Compute policy loss with entropy regularization\n",
    "            adv_policy_loss = 0\n",
    "            adv_entropy = 0\n",
    "\n",
    "            for t in range(len(adv_retuns_normalized)):\n",
    "                # Policy gradient loss\n",
    "                adv_policy_loss -= adv_log_probs[t] * adv_retuns_normalized[t]\n",
    "\n",
    "                # Entropy regularization (encourage exploration)\n",
    "                adv_entropy -= adv_log_probs[t].exp() * adv_log_probs[t]\n",
    "\n",
    "            # Combine losses with coefficients\n",
    "            adv_total_loss = adv_policy_loss - entropy_coef * adv_entropy\n",
    "\n",
    "            # Gradient update for adversary policy\n",
    "            optimizer_adversary.zero_grad()\n",
    "            adv_total_loss.backward()\n",
    "\n",
    "            # Apply gradient clipping\n",
    "            if grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(policy_nn_adversary.parameters(), grad_clip)\n",
    "\n",
    "            optimizer_adversary.step()\n",
    "            lr_scheduler_adversary.step()\n",
    "\n",
    "        # Evaluate periodically\n",
    "        if (episode_index + 1) % eval_frequency == 0:  # or episode_index == 0\n",
    "            print(f\"\\nEpisode {episode_index + 1}/{num_episodes}\")\n",
    "            print(f\"Loss - Main: {total_loss.item():.4f}, Adv: {adv_total_loss.item():.4f}\")\n",
    "            if lr_scheduler is not None:\n",
    "                print(f\"Learning rate - Main: {lr_scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "            test_win_rate = (\n",
    "                test_functions.test_policy_network_vs_alpha_beta(env_port=3, agent_port=9, num_episodes=1,\n",
    "                                                                 policy_network=policy_nn,\n",
    "                                                                 ))['policy_network_win_rate']\n",
    "\n",
    "            episodes_win_rates.append(test_win_rate)\n",
    "\n",
    "            # Print progress if verbose\n",
    "            if verbose:\n",
    "                print(f\"\\nEpisode {episode_index + 1}/{num_episodes}\")\n",
    "                print(f\"Win rate: {test_win_rate:.4f}\")\n",
    "                print(f\"Learning Rate: {lr_scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "            # Save best model if performance improved\n",
    "            if test_win_rate > best_win_rate:\n",
    "                best_win_rate = test_win_rate\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "                torch.save({\n",
    "                    'episode': episode_index,\n",
    "                    'policy_nn_state_dict': policy_nn.state_dict(),\n",
    "                    'policy_nn_adversary_state_dict': policy_nn_adversary.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'optimizer_adversary_state_dict': optimizer_adversary.state_dict(),\n",
    "                    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                    'lr_scheduler_adversary_state_dict': lr_scheduler_adversary.state_dict(),\n",
    "                    'best_win_rate': best_win_rate\n",
    "                }, checkpoint_path)\n",
    "                print(\n",
    "                    f\"Saved best model with win rate: {best_win_rate:.2f} at episode {episode_index + 1}/{num_episodes}\")\n",
    "\n",
    "        # Save checkpoint at regular intervals\n",
    "        if (episode_index + 1) % checkpoint_frequency == 0 and not save_best_only:\n",
    "            main_network_episodes_losses.append(total_loss.item())\n",
    "            adversary_network_episodes_losses.append(adv_total_loss.item())\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_episode_{episode_index + 1}.pt')\n",
    "            torch.save({\n",
    "                'episode': episode_index,\n",
    "                'policy_nn_state_dict': policy_nn.state_dict(),\n",
    "                'policy_nn_adversary_state_dict': policy_nn_adversary.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'optimizer_adversary_state_dict': optimizer_adversary.state_dict(),\n",
    "                'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                'lr_scheduler_adversary_state_dict': lr_scheduler_adversary.state_dict(),\n",
    "                'win_rates_list': episodes_win_rates,\n",
    "                'main_network_episodes_losses': main_network_episodes_losses,\n",
    "                'adversary_network_episodes_losses': adversary_network_episodes_losses\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint at episode {episode_index + 1}/{num_episodes}\")\n",
    "\n",
    "    return policy_nn, episodes_win_rates, main_network_episodes_losses, adversary_network_episodes_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYLdZKgaYSv0"
   },
   "source": [
    "#### Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2950144,
     "status": "ok",
     "timestamp": 1742267762060,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "JY_iK3E8YSv0",
    "outputId": "23289510-4d7e-45eb-80c6-77cdba112702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2871 - Main Policy Loss: -1.2977, Entropy: 0.7278\n",
      "Episode 2881 - Main Policy Loss: -0.2854, Entropy: 0.4155\n",
      "Episode 2891 - Main Policy Loss: 0.5675, Entropy: 0.5626\n",
      "Episode 2901 - Main Policy Loss: -0.4557, Entropy: 0.4590\n",
      "Episode 2911 - Main Policy Loss: -1.2699, Entropy: 1.1078\n",
      "Episode 2921 - Main Policy Loss: -8.6863, Entropy: 1.5626\n",
      "Episode 2931 - Main Policy Loss: -6.9303, Entropy: 0.0987\n",
      "Episode 2941 - Main Policy Loss: -0.0236, Entropy: 0.1478\n",
      "Episode 2951 - Main Policy Loss: -0.2809, Entropy: 0.4284\n",
      "Episode 2961 - Main Policy Loss: -1.5411, Entropy: 0.8316\n",
      "Episode 2971 - Main Policy Loss: -0.6191, Entropy: 0.6178\n",
      "Episode 2981 - Main Policy Loss: -0.3899, Entropy: 0.4605\n",
      "Episode 2991 - Main Policy Loss: -1.3429, Entropy: 0.5063\n",
      "Saved checkpoint at episode 3000/10000\n",
      "Episode 3001 - Main Policy Loss: -1.0378, Entropy: 0.8229\n",
      "Episode 3011 - Main Policy Loss: -0.3168, Entropy: 0.4340\n",
      "Episode 3021 - Main Policy Loss: -0.2909, Entropy: 0.2903\n",
      "Episode 3031 - Main Policy Loss: -2.0517, Entropy: 1.0130\n",
      "Episode 3041 - Main Policy Loss: -2.2575, Entropy: 0.6148\n",
      "Episode 3051 - Main Policy Loss: -0.8700, Entropy: 0.8924\n",
      "Episode 3061 - Main Policy Loss: -0.8429, Entropy: 1.0299\n",
      "Episode 3071 - Main Policy Loss: -1.8953, Entropy: 2.3762\n",
      "Episode 3081 - Main Policy Loss: -2.2195, Entropy: 1.8351\n",
      "Episode 3091 - Main Policy Loss: -0.9766, Entropy: 1.5029\n",
      "Episode 3101 - Main Policy Loss: -0.6342, Entropy: 2.0053\n",
      "Episode 3111 - Main Policy Loss: -3.2651, Entropy: 2.0500\n",
      "Episode 3121 - Main Policy Loss: -6.3433, Entropy: 1.5136\n",
      "Episode 3131 - Main Policy Loss: -3.1590, Entropy: 0.9671\n",
      "Episode 3141 - Main Policy Loss: -2.1241, Entropy: 0.9816\n",
      "Episode 3151 - Main Policy Loss: -0.3208, Entropy: 0.2867\n",
      "Episode 3161 - Main Policy Loss: -0.7645, Entropy: 0.4905\n",
      "Episode 3171 - Main Policy Loss: 0.9179, Entropy: 1.4465\n",
      "Episode 3181 - Main Policy Loss: -4.6780, Entropy: 1.4119\n",
      "Episode 3191 - Main Policy Loss: -0.6654, Entropy: 1.1360\n",
      "Episode 3201 - Main Policy Loss: -4.6305, Entropy: 1.0598\n",
      "Episode 3211 - Main Policy Loss: -1.4416, Entropy: 0.9049\n",
      "Episode 3221 - Main Policy Loss: -3.0312, Entropy: 1.0957\n",
      "Episode 3231 - Main Policy Loss: -1.6501, Entropy: 1.1501\n",
      "Episode 3241 - Main Policy Loss: -4.0221, Entropy: 1.6307\n",
      "Episode 3251 - Main Policy Loss: -3.7729, Entropy: 1.2460\n",
      "Episode 3261 - Main Policy Loss: -1.8488, Entropy: 1.1457\n",
      "Episode 3271 - Main Policy Loss: -3.6750, Entropy: 1.8219\n",
      "Episode 3281 - Main Policy Loss: 0.3808, Entropy: 1.1079\n",
      "Episode 3291 - Main Policy Loss: -3.2423, Entropy: 1.3602\n",
      "Episode 3301 - Main Policy Loss: -2.5423, Entropy: 1.4387\n",
      "Episode 3311 - Main Policy Loss: -4.1852, Entropy: 1.5011\n",
      "Episode 3321 - Main Policy Loss: -2.4205, Entropy: 1.2230\n",
      "Episode 3331 - Main Policy Loss: -1.6979, Entropy: 1.0713\n",
      "Episode 3341 - Main Policy Loss: -1.8535, Entropy: 0.9648\n",
      "Episode 3351 - Main Policy Loss: -1.1806, Entropy: 1.7820\n",
      "Episode 3361 - Main Policy Loss: -2.4399, Entropy: 1.7592\n",
      "Episode 3371 - Main Policy Loss: -1.5053, Entropy: 1.0800\n",
      "Episode 3381 - Main Policy Loss: -1.1444, Entropy: 1.1490\n",
      "Episode 3391 - Main Policy Loss: -3.4508, Entropy: 1.6915\n",
      "Episode 3401 - Main Policy Loss: -0.0328, Entropy: 0.9723\n",
      "Episode 3411 - Main Policy Loss: -2.0056, Entropy: 1.3320\n",
      "Episode 3421 - Main Policy Loss: -3.4319, Entropy: 1.7428\n",
      "Episode 3431 - Main Policy Loss: -3.9787, Entropy: 1.7972\n",
      "Episode 3441 - Main Policy Loss: -3.7183, Entropy: 1.8767\n",
      "Episode 3451 - Main Policy Loss: -2.1304, Entropy: 1.3149\n",
      "Episode 3461 - Main Policy Loss: -1.7754, Entropy: 1.2653\n",
      "Episode 3471 - Main Policy Loss: -2.3220, Entropy: 1.2955\n",
      "Episode 3481 - Main Policy Loss: -1.7549, Entropy: 1.1741\n",
      "Episode 3491 - Main Policy Loss: -3.8221, Entropy: 1.3451\n",
      "Episode 3501 - Main Policy Loss: -1.8998, Entropy: 1.2888\n",
      "Episode 3511 - Main Policy Loss: -1.6777, Entropy: 1.1633\n",
      "Episode 3521 - Main Policy Loss: -0.1449, Entropy: 0.4346\n",
      "Episode 3531 - Main Policy Loss: -0.4147, Entropy: 0.8218\n",
      "Episode 3541 - Main Policy Loss: 0.0151, Entropy: 1.0371\n",
      "Episode 3551 - Main Policy Loss: -1.0506, Entropy: 1.9115\n",
      "Episode 3561 - Main Policy Loss: -0.6345, Entropy: 0.3029\n",
      "Episode 3571 - Main Policy Loss: 0.0285, Entropy: 0.4628\n",
      "Episode 3581 - Main Policy Loss: -4.1510, Entropy: 1.2410\n",
      "Episode 3591 - Main Policy Loss: 0.8757, Entropy: 0.8363\n",
      "Episode 3601 - Main Policy Loss: -0.7835, Entropy: 0.3755\n",
      "Episode 3611 - Main Policy Loss: 0.8867, Entropy: 0.5610\n",
      "Episode 3621 - Main Policy Loss: 3.6238, Entropy: 1.2462\n",
      "Episode 3631 - Main Policy Loss: -0.2104, Entropy: 0.1538\n",
      "Episode 3641 - Main Policy Loss: -0.2426, Entropy: 0.2167\n",
      "Episode 3651 - Main Policy Loss: -0.1697, Entropy: 0.1222\n",
      "Episode 3661 - Main Policy Loss: -0.2212, Entropy: 0.1019\n",
      "Episode 3671 - Main Policy Loss: -2.3254, Entropy: 0.9740\n",
      "Episode 3681 - Main Policy Loss: -0.6849, Entropy: 0.5223\n",
      "Episode 3691 - Main Policy Loss: -0.2139, Entropy: 0.2219\n",
      "Episode 3701 - Main Policy Loss: 0.1049, Entropy: 0.6375\n",
      "Episode 3711 - Main Policy Loss: 1.3317, Entropy: 0.2301\n",
      "Episode 3721 - Main Policy Loss: -1.7930, Entropy: 0.7256\n",
      "Episode 3731 - Main Policy Loss: -0.1261, Entropy: 0.1273\n",
      "Episode 3741 - Main Policy Loss: -0.2230, Entropy: 0.4750\n",
      "Episode 3751 - Main Policy Loss: -0.8294, Entropy: 0.3089\n",
      "Episode 3761 - Main Policy Loss: -0.0399, Entropy: 0.0765\n",
      "Episode 3771 - Main Policy Loss: -3.2083, Entropy: 0.3072\n",
      "Episode 3781 - Main Policy Loss: -0.3253, Entropy: 0.1714\n",
      "Episode 3791 - Main Policy Loss: -5.3825, Entropy: 0.1205\n",
      "Episode 3801 - Main Policy Loss: -0.1213, Entropy: 0.1676\n",
      "Episode 3811 - Main Policy Loss: 0.0800, Entropy: 0.1562\n",
      "Episode 3821 - Main Policy Loss: -1.1902, Entropy: 0.1985\n",
      "Episode 3831 - Main Policy Loss: -0.3364, Entropy: 0.2601\n",
      "Episode 3841 - Main Policy Loss: -5.3411, Entropy: 0.4503\n",
      "Episode 3851 - Main Policy Loss: 0.0434, Entropy: 0.4755\n",
      "Episode 3861 - Main Policy Loss: -1.5370, Entropy: 0.4057\n",
      "Episode 3871 - Main Policy Loss: -0.0580, Entropy: 0.2311\n",
      "Episode 3881 - Main Policy Loss: -0.0001, Entropy: 0.0003\n",
      "Episode 3891 - Main Policy Loss: -0.7783, Entropy: 0.6338\n",
      "Episode 3901 - Main Policy Loss: -0.1275, Entropy: 0.0873\n",
      "Episode 3911 - Main Policy Loss: 0.3060, Entropy: 0.3801\n",
      "Episode 3921 - Main Policy Loss: -0.0845, Entropy: 0.0636\n",
      "Episode 3931 - Main Policy Loss: 0.0210, Entropy: 0.0744\n",
      "Episode 3941 - Main Policy Loss: -0.0077, Entropy: 0.0073\n",
      "Episode 3951 - Main Policy Loss: -0.0187, Entropy: 0.0123\n",
      "Episode 3961 - Main Policy Loss: -0.0620, Entropy: 0.0344\n",
      "Episode 3971 - Main Policy Loss: -0.0613, Entropy: 0.0562\n",
      "Episode 3981 - Main Policy Loss: -0.1143, Entropy: 0.2527\n",
      "Episode 3991 - Main Policy Loss: -0.7839, Entropy: 0.4021\n",
      "Saved checkpoint at episode 4000/10000\n",
      "Episode 4001 - Main Policy Loss: -0.5905, Entropy: 0.5299\n",
      "Episode 4011 - Main Policy Loss: -0.7816, Entropy: 0.3449\n",
      "Episode 4021 - Main Policy Loss: -0.8373, Entropy: 1.1045\n",
      "Episode 4031 - Main Policy Loss: -0.3518, Entropy: 0.6800\n",
      "Episode 4041 - Main Policy Loss: -2.9238, Entropy: 0.6107\n",
      "Episode 4051 - Main Policy Loss: -0.0481, Entropy: 0.0476\n",
      "Episode 4061 - Main Policy Loss: -0.5236, Entropy: 0.3049\n",
      "Episode 4071 - Main Policy Loss: -5.7899, Entropy: 0.0545\n",
      "Episode 4081 - Main Policy Loss: -3.3967, Entropy: 1.8717\n",
      "Episode 4091 - Main Policy Loss: -0.4479, Entropy: 0.2810\n",
      "Episode 4101 - Main Policy Loss: -6.7605, Entropy: 0.2408\n",
      "Episode 4111 - Main Policy Loss: 0.0268, Entropy: 0.1388\n",
      "Episode 4121 - Main Policy Loss: -2.9718, Entropy: 0.4574\n",
      "Episode 4131 - Main Policy Loss: -4.8932, Entropy: 0.2641\n",
      "Episode 4141 - Main Policy Loss: -1.6066, Entropy: 0.8045\n",
      "Episode 4151 - Main Policy Loss: 0.2260, Entropy: 0.4417\n",
      "Episode 4161 - Main Policy Loss: -0.5641, Entropy: 0.4594\n",
      "Episode 4171 - Main Policy Loss: -1.0396, Entropy: 0.6452\n",
      "Episode 4181 - Main Policy Loss: -0.0601, Entropy: 0.0936\n",
      "Episode 4191 - Main Policy Loss: -1.2908, Entropy: 0.6743\n",
      "Episode 4201 - Main Policy Loss: 0.0288, Entropy: 0.2514\n",
      "Episode 4211 - Main Policy Loss: -1.5326, Entropy: 0.4017\n",
      "Episode 4221 - Main Policy Loss: -1.0405, Entropy: 0.9587\n",
      "Episode 4231 - Main Policy Loss: -0.1363, Entropy: 0.1801\n",
      "Episode 4241 - Main Policy Loss: -8.3451, Entropy: 0.5329\n",
      "Episode 4251 - Main Policy Loss: -1.2294, Entropy: 0.3708\n",
      "Episode 4261 - Main Policy Loss: -0.7137, Entropy: 0.4500\n",
      "Episode 4271 - Main Policy Loss: -0.0341, Entropy: 0.1997\n",
      "Episode 4281 - Main Policy Loss: -2.8757, Entropy: 0.7441\n",
      "Episode 4291 - Main Policy Loss: -4.7447, Entropy: 2.0594\n",
      "Episode 4301 - Main Policy Loss: -1.0035, Entropy: 0.8276\n",
      "Episode 4311 - Main Policy Loss: -2.5659, Entropy: 1.6430\n",
      "Episode 4321 - Main Policy Loss: 0.2947, Entropy: 0.8343\n",
      "Episode 4331 - Main Policy Loss: -3.1777, Entropy: 1.4455\n",
      "Episode 4341 - Main Policy Loss: -1.6744, Entropy: 1.2470\n",
      "Episode 4351 - Main Policy Loss: -0.1213, Entropy: 1.5796\n",
      "Episode 4361 - Main Policy Loss: -4.1640, Entropy: 1.2293\n",
      "Episode 4371 - Main Policy Loss: -1.0008, Entropy: 1.3189\n",
      "Episode 4381 - Main Policy Loss: -2.7408, Entropy: 0.5653\n",
      "Episode 4391 - Main Policy Loss: -1.6019, Entropy: 0.9525\n",
      "Episode 4401 - Main Policy Loss: -0.5923, Entropy: 0.6226\n",
      "Episode 4411 - Main Policy Loss: -1.4437, Entropy: 0.9501\n",
      "Episode 4421 - Main Policy Loss: -0.0065, Entropy: 1.5311\n",
      "Episode 4431 - Main Policy Loss: -0.3598, Entropy: 0.6024\n",
      "Episode 4441 - Main Policy Loss: 1.0887, Entropy: 0.9431\n",
      "Episode 4451 - Main Policy Loss: -0.6995, Entropy: 0.4846\n",
      "Episode 4461 - Main Policy Loss: -0.8048, Entropy: 0.4890\n",
      "Episode 4471 - Main Policy Loss: -1.4882, Entropy: 0.7593\n",
      "Episode 4481 - Main Policy Loss: -1.0891, Entropy: 0.5171\n",
      "Episode 4491 - Main Policy Loss: -0.3306, Entropy: 1.1728\n",
      "Episode 4501 - Main Policy Loss: -0.5990, Entropy: 0.3810\n",
      "Episode 4511 - Main Policy Loss: -1.6365, Entropy: 0.4249\n",
      "Episode 4521 - Main Policy Loss: -2.3829, Entropy: 0.7775\n",
      "Episode 4531 - Main Policy Loss: -0.9584, Entropy: 0.4215\n",
      "Episode 4541 - Main Policy Loss: -0.0708, Entropy: 0.0672\n",
      "Episode 4551 - Main Policy Loss: -2.3226, Entropy: 0.7661\n",
      "Episode 4561 - Main Policy Loss: -1.1584, Entropy: 0.5669\n",
      "Episode 4571 - Main Policy Loss: -3.0863, Entropy: 0.6232\n",
      "Episode 4581 - Main Policy Loss: -1.4884, Entropy: 0.4632\n",
      "Episode 4591 - Main Policy Loss: -1.3155, Entropy: 0.3636\n",
      "Episode 4601 - Main Policy Loss: -0.0294, Entropy: 0.0274\n",
      "Episode 4611 - Main Policy Loss: -1.3941, Entropy: 0.4681\n",
      "Episode 4621 - Main Policy Loss: -0.1447, Entropy: 0.3735\n",
      "Episode 4631 - Main Policy Loss: -5.8103, Entropy: 0.5261\n",
      "Episode 4641 - Main Policy Loss: -0.6024, Entropy: 0.6941\n",
      "Episode 4651 - Main Policy Loss: -0.4339, Entropy: 0.7629\n",
      "Episode 4661 - Main Policy Loss: -0.0549, Entropy: 0.1597\n",
      "Episode 4671 - Main Policy Loss: -1.5570, Entropy: 0.4444\n",
      "Episode 4681 - Main Policy Loss: -0.2692, Entropy: 0.2047\n",
      "Episode 4691 - Main Policy Loss: -0.5666, Entropy: 0.6378\n",
      "Episode 4701 - Main Policy Loss: -0.3515, Entropy: 0.4665\n",
      "Episode 4711 - Main Policy Loss: -1.9219, Entropy: 0.5497\n",
      "Episode 4721 - Main Policy Loss: -0.1054, Entropy: 0.0842\n",
      "Episode 4731 - Main Policy Loss: -0.0191, Entropy: 0.0210\n",
      "Episode 4741 - Main Policy Loss: -0.0002, Entropy: 0.0014\n",
      "Episode 4751 - Main Policy Loss: -0.2328, Entropy: 0.2207\n",
      "Episode 4761 - Main Policy Loss: -0.0086, Entropy: 0.0311\n",
      "Episode 4771 - Main Policy Loss: -0.6338, Entropy: 0.3909\n",
      "Episode 4781 - Main Policy Loss: -0.2464, Entropy: 0.2493\n",
      "Episode 4791 - Main Policy Loss: -0.0574, Entropy: 0.0567\n",
      "Episode 4801 - Main Policy Loss: -2.3905, Entropy: 0.7090\n",
      "Episode 4811 - Main Policy Loss: -1.1680, Entropy: 0.7214\n",
      "Episode 4821 - Main Policy Loss: -0.8636, Entropy: 1.3130\n",
      "Episode 4831 - Main Policy Loss: -3.2128, Entropy: 0.8678\n",
      "Episode 4841 - Main Policy Loss: -0.6294, Entropy: 0.4159\n",
      "Episode 4851 - Main Policy Loss: -0.8598, Entropy: 0.5234\n",
      "Episode 4861 - Main Policy Loss: 2.8044, Entropy: 0.6310\n",
      "Episode 4871 - Main Policy Loss: -0.5599, Entropy: 0.3722\n",
      "Episode 4881 - Main Policy Loss: -0.5138, Entropy: 0.4240\n",
      "Episode 4891 - Main Policy Loss: -0.8404, Entropy: 0.6105\n",
      "Episode 4901 - Main Policy Loss: -2.7617, Entropy: 0.7812\n",
      "Episode 4911 - Main Policy Loss: -1.8349, Entropy: 1.5076\n",
      "Episode 4921 - Main Policy Loss: -2.2226, Entropy: 1.6492\n",
      "Episode 4931 - Main Policy Loss: -0.2969, Entropy: 0.6095\n",
      "Episode 4941 - Main Policy Loss: -1.0364, Entropy: 1.1362\n",
      "Episode 4951 - Main Policy Loss: -3.5525, Entropy: 0.7085\n",
      "Episode 4961 - Main Policy Loss: -0.1462, Entropy: 0.3732\n",
      "Episode 4971 - Main Policy Loss: 0.0690, Entropy: 0.8091\n",
      "Episode 4981 - Main Policy Loss: -2.5548, Entropy: 1.1006\n",
      "Episode 4991 - Main Policy Loss: -0.5954, Entropy: 0.4836\n",
      "\n",
      "Episode 5000/10000\n",
      "Loss - Main: -0.2396, Adv: -0.9627\n",
      "Learning rate - Main: 0.000349\n",
      "Connected to Java server at localhost:3\n",
      "Connected to ID Alpha-Beta server at localhost:9\n",
      "ID AlphaBeta reset\n",
      "ID Alpha-Beta reset response: {'current_role': 'RED', 'ai_role': 'BLUE', 'legal_moves': ['A0-A1', 'A0-B0', 'A0-B1', 'A3-B4', 'A4-A5', 'A4-B4', 'A4-B5', 'B2-C3', 'B3-B4', 'B3-C3', 'B3-C4', 'C1-D2', 'C2-C3', 'C2-D2', 'C2-D3', 'D0-E1', 'D1-D2', 'D1-E1', 'D1-E2', 'E0-E1', 'E0-F0', 'E0-F1'], 'board': [['RED_KING', 'RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'EMPTY'], ['RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN'], ['RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN'], ['RED_COURTESAN', 'RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN'], ['RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN'], ['EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_KING']]}\n",
      "Set parameters response: {'agent_type': 'ID Alpha-Beta', 'max_depth': 8, 'status': 'parameters updated'}\n",
      "\n",
      "Episode 1/1\n",
      "Policy Network plays second (BLUE)\n",
      "Alpha-Beta agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A0-B0 (computed in 30000ms)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B KRRR-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-B-\n",
      "B KRRRBB\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 3\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A3-B4 (computed in 30001ms)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-B-\n",
      "B KRRRRB\n",
      "A RRR-R-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-B-\n",
      "B KRRRR-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 5\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A4-A5 (computed in 30000ms)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-B-\n",
      "B KRRRR-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRB-BB\n",
      "C RRR-B-\n",
      "B KRRRR-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 7\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C1-D2 (computed in 30001ms)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRR-BB\n",
      "C R-R-B-\n",
      "B KRRRR-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-B-BB\n",
      "D RRRBBB\n",
      "C R-R-B-\n",
      "B KRRRR-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 9\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B3-C4 (computed in 30000ms)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-B-BB\n",
      "D RRRBBB\n",
      "C R-R-R-\n",
      "B KRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-B-BB\n",
      "D RRRB-B\n",
      "C R-R-B-\n",
      "B KRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 11\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: D1-E2 (computed in 30000ms)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-R-BB\n",
      "D R-RB-B\n",
      "C R-R-B-\n",
      "B KRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F2-E2\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B-BB\n",
      "D R-RB-B\n",
      "C R-R-B-\n",
      "B KRR-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 13\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B1-C1 (computed in 30001ms)\n",
      "Selected move: B1-C1\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B-BB\n",
      "D R-RB-B\n",
      "C RRR-B-\n",
      "B K-R-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-BB-B\n",
      "D R-RB-B\n",
      "C RRR-B-\n",
      "B K-R-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 15\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: D2-D3 (computed in 30000ms)\n",
      "Selected move: D2-D3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-BB-B\n",
      "D R--R-B\n",
      "C RRR-B-\n",
      "B K-R-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R--B-B\n",
      "C RRR-B-\n",
      "B K-R-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 17\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C2-D3 (computed in 30001ms)\n",
      "Selected move: C2-D3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R--R-B\n",
      "C RR--B-\n",
      "B K-R-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-D3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R--B-B\n",
      "C RR----\n",
      "B K-R-R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 19\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B2-C3 (computed in 30001ms)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R--B-B\n",
      "C RR-R--\n",
      "B K---R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R--B--\n",
      "C RR-RB-\n",
      "B K---R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 21\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C3-C4 (computed in 30000ms)\n",
      "Selected move: C3-C4\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R--B--\n",
      "C RR--R-\n",
      "B K---R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-C4\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R-----\n",
      "C RR--B-\n",
      "B K---R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 23\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B4-C4 (computed in 10206ms)\n",
      "Selected move: B4-C4\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E R-B--B\n",
      "D R-----\n",
      "C RR--R-\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-E1\n",
      "  012345\n",
      "F ---BBQ\n",
      "E RBB--B\n",
      "D R-----\n",
      "C RR--R-\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 25\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: D0-E1 (computed in 6228ms)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F ---BBQ\n",
      "E RRB--B\n",
      "D ------\n",
      "C RR--R-\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 26\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E5-D5\n",
      "  012345\n",
      "F ---BBQ\n",
      "E RRB---\n",
      "D -----B\n",
      "C RR--R-\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 27\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C4-D5 (computed in 10637ms)\n",
      "Selected move: C4-D5\n",
      "  012345\n",
      "F ---BBQ\n",
      "E RRB---\n",
      "D -----R\n",
      "C RR----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 28\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F ---B-Q\n",
      "E RRB-B-\n",
      "D -----R\n",
      "C RR----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 29\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: E1-E2 (computed in 30001ms)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R-R-B-\n",
      "D -----R\n",
      "C RR----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 30\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-D3\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R-R---\n",
      "D ---B-R\n",
      "C RR----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 31\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: E2-F3 (computed in 3058ms)\n",
      "Selected move: E2-F3\n",
      "  012345\n",
      "F ---R-Q\n",
      "E R-----\n",
      "D ---B-R\n",
      "C RR----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 32\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F ---R-Q\n",
      "E R-----\n",
      "D --B--R\n",
      "C RR----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 33\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C1-D2 (computed in 175ms)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F ---R-Q\n",
      "E R-----\n",
      "D --R--R\n",
      "C R-----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 34\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F5-E5\n",
      "  012345\n",
      "F ---R--\n",
      "E R----Q\n",
      "D --R--R\n",
      "C R-----\n",
      "B K-----\n",
      "A RRR--R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 35\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: D5-E5 (computed in 1ms)\n",
      "Selected move: D5-E5\n",
      "  012345\n",
      "F ---R--\n",
      "E R----R\n",
      "D --R---\n",
      "C R-----\n",
      "B K-----\n",
      "A RRR--R\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Game Over! Winner: alpha_beta\n",
      "\n",
      "Test Results Summary:\n",
      "Episodes: 1\n",
      "Policy Network wins: 0 (0.0%)\n",
      "Alpha-Beta wins: 1 (100.0%)\n",
      "Ties: 0 (0.0%)\n",
      "Average steps per episode: 35.0\n",
      "Connection to Java server closed\n",
      "Closed connection to ID Alpha-Beta server\n",
      "\n",
      "Episode 5000/10000\n",
      "Win rate: 0.0000\n",
      "Learning Rate: 0.000349\n",
      "Saved best model with win rate: 0.00 at episode 5000/10000\n",
      "Saved checkpoint at episode 5000/10000\n",
      "Communication error: Received empty response from server\n",
      "Attempting to reconnect...\n",
      "Connected to Java server at localhost:3\n",
      "Episode 5001 - Main Policy Loss: -1.0479, Entropy: 0.7081\n",
      "Episode 5011 - Main Policy Loss: -0.2606, Entropy: 0.7325\n",
      "Episode 5021 - Main Policy Loss: -0.2069, Entropy: 0.2938\n",
      "Episode 5031 - Main Policy Loss: -2.1863, Entropy: 1.2114\n",
      "Episode 5041 - Main Policy Loss: -2.3649, Entropy: 0.7393\n",
      "Episode 5051 - Main Policy Loss: 0.0609, Entropy: 1.1233\n",
      "Episode 5061 - Main Policy Loss: -4.1400, Entropy: 0.8956\n",
      "Episode 5071 - Main Policy Loss: -1.5626, Entropy: 1.9104\n",
      "Episode 5081 - Main Policy Loss: -1.6909, Entropy: 1.1738\n",
      "Episode 5091 - Main Policy Loss: -2.8837, Entropy: 0.9043\n",
      "Episode 5101 - Main Policy Loss: -2.3982, Entropy: 1.2465\n",
      "Episode 5111 - Main Policy Loss: -3.5681, Entropy: 2.0833\n",
      "Episode 5121 - Main Policy Loss: -0.0111, Entropy: 1.3945\n",
      "Episode 5131 - Main Policy Loss: 5.8636, Entropy: 1.7974\n",
      "Episode 5141 - Main Policy Loss: -4.9700, Entropy: 1.3643\n",
      "Episode 5151 - Main Policy Loss: -2.5190, Entropy: 3.4326\n",
      "Episode 5161 - Main Policy Loss: -2.7490, Entropy: 2.3296\n",
      "Episode 5171 - Main Policy Loss: 0.0775, Entropy: 1.3410\n",
      "Episode 5181 - Main Policy Loss: -4.8282, Entropy: 1.8909\n",
      "Episode 5191 - Main Policy Loss: -2.5572, Entropy: 2.0932\n",
      "Episode 5201 - Main Policy Loss: -8.0583, Entropy: 1.7407\n",
      "Episode 5211 - Main Policy Loss: -3.8719, Entropy: 1.2528\n",
      "Episode 5221 - Main Policy Loss: -3.6675, Entropy: 1.1418\n",
      "Episode 5231 - Main Policy Loss: -2.2982, Entropy: 2.2918\n",
      "Episode 5241 - Main Policy Loss: -1.8301, Entropy: 1.5809\n",
      "Episode 5251 - Main Policy Loss: -3.3468, Entropy: 1.4888\n",
      "Episode 5261 - Main Policy Loss: -3.4032, Entropy: 0.7666\n",
      "Episode 5271 - Main Policy Loss: -1.4061, Entropy: 0.7925\n",
      "Episode 5281 - Main Policy Loss: -4.6923, Entropy: 0.9566\n",
      "Episode 5291 - Main Policy Loss: -4.2462, Entropy: 0.9853\n",
      "Episode 5301 - Main Policy Loss: -4.6536, Entropy: 0.7127\n",
      "Episode 5311 - Main Policy Loss: -1.3279, Entropy: 0.6720\n",
      "Episode 5321 - Main Policy Loss: -3.2224, Entropy: 1.3677\n",
      "Episode 5331 - Main Policy Loss: 0.1895, Entropy: 0.7930\n",
      "Episode 5341 - Main Policy Loss: -8.3821, Entropy: 1.0747\n",
      "Episode 5351 - Main Policy Loss: 0.0463, Entropy: 1.7108\n",
      "Episode 5361 - Main Policy Loss: -5.6111, Entropy: 1.4998\n",
      "Episode 5371 - Main Policy Loss: 0.5466, Entropy: 2.4923\n",
      "Episode 5381 - Main Policy Loss: -3.0244, Entropy: 2.8786\n",
      "Episode 5391 - Main Policy Loss: -6.0681, Entropy: 1.1195\n",
      "Episode 5401 - Main Policy Loss: -0.6540, Entropy: 1.5140\n",
      "Episode 5411 - Main Policy Loss: -1.3729, Entropy: 1.9858\n",
      "Episode 5421 - Main Policy Loss: -2.6738, Entropy: 1.1974\n",
      "Episode 5431 - Main Policy Loss: -4.7912, Entropy: 2.0758\n",
      "Episode 5441 - Main Policy Loss: -2.3858, Entropy: 1.6354\n",
      "Episode 5451 - Main Policy Loss: -2.9447, Entropy: 1.7368\n",
      "Episode 5461 - Main Policy Loss: -1.3626, Entropy: 1.6021\n",
      "Episode 5471 - Main Policy Loss: -1.6207, Entropy: 1.5785\n",
      "Episode 5481 - Main Policy Loss: 0.2610, Entropy: 1.1560\n",
      "Episode 5491 - Main Policy Loss: -1.2838, Entropy: 1.3983\n",
      "Episode 5501 - Main Policy Loss: -0.6980, Entropy: 0.7873\n",
      "Episode 5511 - Main Policy Loss: -1.8857, Entropy: 1.9475\n",
      "Episode 5521 - Main Policy Loss: -2.7994, Entropy: 0.5523\n",
      "Episode 5531 - Main Policy Loss: -3.1166, Entropy: 1.1572\n",
      "Episode 5541 - Main Policy Loss: -3.8659, Entropy: 0.6696\n",
      "Episode 5551 - Main Policy Loss: -6.0726, Entropy: 1.9263\n",
      "Episode 5561 - Main Policy Loss: -0.8772, Entropy: 0.8019\n",
      "Episode 5571 - Main Policy Loss: -6.8553, Entropy: 1.1817\n",
      "Episode 5581 - Main Policy Loss: -1.8684, Entropy: 1.0186\n",
      "Episode 5591 - Main Policy Loss: -3.6825, Entropy: 1.8484\n",
      "Episode 5601 - Main Policy Loss: -5.2572, Entropy: 1.9834\n",
      "Episode 5611 - Main Policy Loss: 3.2291, Entropy: 1.3455\n",
      "Episode 5621 - Main Policy Loss: -8.7615, Entropy: 1.9479\n",
      "Episode 5631 - Main Policy Loss: -2.5840, Entropy: 1.8563\n",
      "Episode 5641 - Main Policy Loss: -3.9906, Entropy: 2.6788\n",
      "Episode 5651 - Main Policy Loss: -0.0958, Entropy: 2.3178\n",
      "Episode 5661 - Main Policy Loss: -17.3915, Entropy: 2.9783\n",
      "Episode 5671 - Main Policy Loss: -5.3939, Entropy: 2.2342\n",
      "Episode 5681 - Main Policy Loss: -5.4266, Entropy: 1.7574\n",
      "Episode 5691 - Main Policy Loss: -1.7241, Entropy: 0.9579\n",
      "Episode 5701 - Main Policy Loss: -0.4923, Entropy: 1.3249\n",
      "Episode 5711 - Main Policy Loss: -3.9128, Entropy: 1.4468\n",
      "Episode 5721 - Main Policy Loss: -0.3719, Entropy: 0.7441\n",
      "Episode 5731 - Main Policy Loss: -1.4219, Entropy: 1.0730\n",
      "Episode 5741 - Main Policy Loss: -0.6598, Entropy: 0.6343\n",
      "Episode 5751 - Main Policy Loss: -0.6969, Entropy: 1.5746\n",
      "Episode 5761 - Main Policy Loss: -2.6357, Entropy: 1.4351\n",
      "Episode 5771 - Main Policy Loss: -2.0089, Entropy: 1.2991\n",
      "Episode 5781 - Main Policy Loss: -3.1235, Entropy: 2.5706\n",
      "Episode 5791 - Main Policy Loss: 0.6854, Entropy: 1.2419\n",
      "Episode 5801 - Main Policy Loss: -2.4509, Entropy: 1.5032\n",
      "Episode 5811 - Main Policy Loss: -3.4768, Entropy: 1.2641\n",
      "Episode 5821 - Main Policy Loss: -3.8412, Entropy: 1.2001\n",
      "Episode 5831 - Main Policy Loss: -6.7810, Entropy: 0.8791\n",
      "Episode 5841 - Main Policy Loss: -2.5753, Entropy: 0.8575\n",
      "Episode 5851 - Main Policy Loss: -3.3376, Entropy: 1.4032\n",
      "Episode 5861 - Main Policy Loss: -12.2735, Entropy: 1.2358\n",
      "Episode 5871 - Main Policy Loss: -7.5601, Entropy: 2.1408\n",
      "Episode 5881 - Main Policy Loss: -4.4550, Entropy: 1.4145\n",
      "Episode 5891 - Main Policy Loss: -2.8005, Entropy: 2.3863\n",
      "Episode 5901 - Main Policy Loss: -6.8433, Entropy: 2.1340\n",
      "Episode 5911 - Main Policy Loss: -3.9658, Entropy: 1.8493\n",
      "Episode 5921 - Main Policy Loss: -1.4844, Entropy: 0.8963\n",
      "Episode 5931 - Main Policy Loss: -6.0941, Entropy: 1.3102\n",
      "Episode 5941 - Main Policy Loss: -0.7672, Entropy: 1.6231\n",
      "Episode 5951 - Main Policy Loss: -5.5783, Entropy: 2.0815\n",
      "Episode 5961 - Main Policy Loss: -6.2885, Entropy: 1.7721\n",
      "Episode 5971 - Main Policy Loss: -5.9254, Entropy: 1.2107\n",
      "Episode 5981 - Main Policy Loss: -8.6444, Entropy: 1.5226\n",
      "Episode 5991 - Main Policy Loss: -2.3213, Entropy: 0.8694\n",
      "Saved checkpoint at episode 6000/10000\n",
      "Episode 6001 - Main Policy Loss: -4.6005, Entropy: 1.5180\n",
      "Episode 6011 - Main Policy Loss: -5.7218, Entropy: 2.4626\n",
      "Episode 6021 - Main Policy Loss: -6.3701, Entropy: 1.4955\n",
      "Episode 6031 - Main Policy Loss: -0.9528, Entropy: 1.4423\n",
      "Episode 6041 - Main Policy Loss: -6.9647, Entropy: 2.5764\n",
      "Episode 6051 - Main Policy Loss: -7.2838, Entropy: 3.3891\n",
      "Episode 6061 - Main Policy Loss: -0.8511, Entropy: 2.1586\n",
      "Episode 6071 - Main Policy Loss: -6.5235, Entropy: 2.1154\n",
      "Episode 6081 - Main Policy Loss: -3.7213, Entropy: 1.4647\n",
      "Episode 6091 - Main Policy Loss: -0.8908, Entropy: 0.5310\n",
      "Episode 6101 - Main Policy Loss: -12.1515, Entropy: 0.9415\n",
      "Episode 6111 - Main Policy Loss: -5.2255, Entropy: 1.1961\n",
      "Episode 6121 - Main Policy Loss: -5.1869, Entropy: 1.7000\n",
      "Episode 6131 - Main Policy Loss: -0.6199, Entropy: 2.1963\n",
      "Episode 6141 - Main Policy Loss: -16.5248, Entropy: 1.9749\n",
      "Episode 6151 - Main Policy Loss: -2.9951, Entropy: 1.0393\n",
      "Episode 6161 - Main Policy Loss: -1.7907, Entropy: 1.1346\n",
      "Episode 6171 - Main Policy Loss: -1.7443, Entropy: 1.2472\n",
      "Episode 6181 - Main Policy Loss: -2.7877, Entropy: 1.9664\n",
      "Episode 6191 - Main Policy Loss: -10.1141, Entropy: 1.0364\n",
      "Episode 6201 - Main Policy Loss: -3.2008, Entropy: 0.9809\n",
      "Episode 6211 - Main Policy Loss: -13.9549, Entropy: 1.8439\n",
      "Episode 6221 - Main Policy Loss: -4.0124, Entropy: 1.4968\n",
      "Episode 6231 - Main Policy Loss: -7.1150, Entropy: 1.9125\n",
      "Episode 6241 - Main Policy Loss: -7.3690, Entropy: 2.5061\n",
      "Episode 6251 - Main Policy Loss: -11.2438, Entropy: 2.0910\n",
      "Episode 6261 - Main Policy Loss: -1.7876, Entropy: 0.9712\n",
      "Episode 6271 - Main Policy Loss: -5.0716, Entropy: 1.4529\n",
      "Episode 6281 - Main Policy Loss: -5.6222, Entropy: 2.3880\n",
      "Episode 6291 - Main Policy Loss: -7.3595, Entropy: 2.6872\n",
      "Episode 6301 - Main Policy Loss: -3.2616, Entropy: 1.1825\n",
      "Episode 6311 - Main Policy Loss: -10.3251, Entropy: 2.5046\n",
      "Episode 6321 - Main Policy Loss: -5.7099, Entropy: 1.4177\n",
      "Episode 6331 - Main Policy Loss: -6.4248, Entropy: 2.0243\n",
      "Episode 6341 - Main Policy Loss: -3.1562, Entropy: 0.8326\n",
      "Episode 6351 - Main Policy Loss: -4.8651, Entropy: 2.3805\n",
      "Episode 6361 - Main Policy Loss: -12.7279, Entropy: 3.2303\n",
      "Episode 6371 - Main Policy Loss: -10.0964, Entropy: 1.6071\n",
      "Episode 6381 - Main Policy Loss: -6.6622, Entropy: 1.3859\n",
      "Episode 6391 - Main Policy Loss: -5.5655, Entropy: 2.0268\n",
      "Episode 6401 - Main Policy Loss: -9.1252, Entropy: 1.6749\n",
      "Episode 6411 - Main Policy Loss: -17.8921, Entropy: 2.4393\n",
      "Episode 6421 - Main Policy Loss: -10.0506, Entropy: 2.1966\n",
      "Episode 6431 - Main Policy Loss: -6.8313, Entropy: 2.6001\n",
      "Episode 6441 - Main Policy Loss: -10.9319, Entropy: 3.9280\n",
      "Episode 6451 - Main Policy Loss: -16.0324, Entropy: 2.6825\n",
      "Episode 6461 - Main Policy Loss: -9.3115, Entropy: 1.5037\n",
      "Episode 6471 - Main Policy Loss: -6.4131, Entropy: 1.5189\n",
      "Episode 6481 - Main Policy Loss: -3.0858, Entropy: 1.6259\n",
      "Episode 6491 - Main Policy Loss: -3.7069, Entropy: 2.5582\n",
      "Episode 6501 - Main Policy Loss: -15.8669, Entropy: 2.6022\n",
      "Episode 6511 - Main Policy Loss: -3.6986, Entropy: 3.4783\n",
      "Episode 6521 - Main Policy Loss: -10.1487, Entropy: 2.3868\n",
      "Episode 6531 - Main Policy Loss: -11.5617, Entropy: 1.9020\n",
      "Episode 6541 - Main Policy Loss: -2.9244, Entropy: 0.8170\n",
      "Episode 6551 - Main Policy Loss: -5.3359, Entropy: 2.0446\n",
      "Episode 6561 - Main Policy Loss: -7.6662, Entropy: 0.5584\n",
      "Episode 6571 - Main Policy Loss: -7.7309, Entropy: 2.6484\n",
      "Episode 6581 - Main Policy Loss: -12.9266, Entropy: 2.6051\n",
      "Episode 6591 - Main Policy Loss: -22.0902, Entropy: 2.0157\n",
      "Episode 6601 - Main Policy Loss: -3.8497, Entropy: 2.3380\n",
      "Episode 6611 - Main Policy Loss: -18.5334, Entropy: 2.2305\n",
      "Episode 6621 - Main Policy Loss: -6.1077, Entropy: 3.0722\n",
      "Episode 6631 - Main Policy Loss: -9.3032, Entropy: 2.9279\n",
      "Episode 6641 - Main Policy Loss: -2.0859, Entropy: 0.9063\n",
      "Episode 6651 - Main Policy Loss: -4.6149, Entropy: 2.0535\n",
      "Episode 6661 - Main Policy Loss: -11.3136, Entropy: 2.8191\n",
      "Episode 6671 - Main Policy Loss: -5.5027, Entropy: 3.0578\n",
      "Episode 6681 - Main Policy Loss: -9.6747, Entropy: 2.3223\n",
      "Episode 6691 - Main Policy Loss: -14.0442, Entropy: 1.9956\n",
      "Episode 6701 - Main Policy Loss: -7.8187, Entropy: 2.2999\n",
      "Episode 6711 - Main Policy Loss: -16.0645, Entropy: 2.3090\n",
      "Episode 6721 - Main Policy Loss: -9.5007, Entropy: 1.9395\n",
      "Episode 6731 - Main Policy Loss: -14.9612, Entropy: 3.6399\n",
      "Episode 6741 - Main Policy Loss: -8.2104, Entropy: 3.2489\n",
      "Episode 6751 - Main Policy Loss: -6.1186, Entropy: 2.0118\n",
      "Episode 6761 - Main Policy Loss: -14.6483, Entropy: 3.0583\n",
      "Episode 6771 - Main Policy Loss: -12.1669, Entropy: 1.9461\n",
      "Episode 6781 - Main Policy Loss: -6.2801, Entropy: 3.4743\n",
      "Episode 6791 - Main Policy Loss: -5.7883, Entropy: 2.7451\n",
      "Episode 6801 - Main Policy Loss: -6.0350, Entropy: 2.2120\n",
      "Episode 6811 - Main Policy Loss: -3.4116, Entropy: 2.2527\n",
      "Episode 6821 - Main Policy Loss: -14.8441, Entropy: 2.7937\n",
      "Episode 6831 - Main Policy Loss: -12.1046, Entropy: 3.2657\n",
      "Episode 6841 - Main Policy Loss: -13.0503, Entropy: 2.7070\n",
      "Episode 6851 - Main Policy Loss: -3.0694, Entropy: 3.3585\n",
      "Episode 6861 - Main Policy Loss: -11.4733, Entropy: 3.2102\n",
      "Episode 6871 - Main Policy Loss: -26.5531, Entropy: 2.7652\n",
      "Episode 6881 - Main Policy Loss: -9.0255, Entropy: 3.3230\n",
      "Episode 6891 - Main Policy Loss: -6.0978, Entropy: 2.8914\n",
      "Episode 6901 - Main Policy Loss: -6.0392, Entropy: 2.1582\n",
      "Episode 6911 - Main Policy Loss: -5.7107, Entropy: 2.4231\n",
      "Episode 6921 - Main Policy Loss: -8.4727, Entropy: 3.9059\n",
      "Episode 6931 - Main Policy Loss: -8.0097, Entropy: 2.5969\n",
      "Episode 6941 - Main Policy Loss: -11.5822, Entropy: 3.6674\n",
      "Episode 6951 - Main Policy Loss: -3.0374, Entropy: 1.6377\n",
      "Episode 6961 - Main Policy Loss: -19.2542, Entropy: 3.2479\n",
      "Episode 6971 - Main Policy Loss: -11.0563, Entropy: 2.2390\n",
      "Episode 6981 - Main Policy Loss: -11.6926, Entropy: 2.9430\n",
      "Episode 6991 - Main Policy Loss: -12.2189, Entropy: 3.5102\n",
      "Saved checkpoint at episode 7000/10000\n",
      "Episode 7001 - Main Policy Loss: -15.0666, Entropy: 3.0430\n",
      "Episode 7011 - Main Policy Loss: -11.6062, Entropy: 4.5719\n",
      "Episode 7021 - Main Policy Loss: -4.6945, Entropy: 3.0772\n",
      "Episode 7031 - Main Policy Loss: -6.4493, Entropy: 3.2550\n",
      "Episode 7041 - Main Policy Loss: -9.5283, Entropy: 2.7380\n",
      "Episode 7051 - Main Policy Loss: -4.2405, Entropy: 2.1560\n",
      "Episode 7061 - Main Policy Loss: -9.1658, Entropy: 4.0493\n",
      "Episode 7071 - Main Policy Loss: -22.1867, Entropy: 2.8550\n",
      "Episode 7081 - Main Policy Loss: -9.8175, Entropy: 1.5205\n",
      "Episode 7091 - Main Policy Loss: -12.0426, Entropy: 0.9143\n",
      "Episode 7101 - Main Policy Loss: -3.1261, Entropy: 1.9516\n",
      "Episode 7111 - Main Policy Loss: -7.4024, Entropy: 3.9594\n",
      "Episode 7121 - Main Policy Loss: -10.9938, Entropy: 3.3342\n",
      "Episode 7131 - Main Policy Loss: -8.5486, Entropy: 3.5382\n",
      "Episode 7141 - Main Policy Loss: -9.7664, Entropy: 3.5177\n",
      "Episode 7151 - Main Policy Loss: -8.9805, Entropy: 2.8116\n",
      "Episode 7161 - Main Policy Loss: -12.7869, Entropy: 3.5002\n",
      "Episode 7171 - Main Policy Loss: -20.6519, Entropy: 3.3288\n",
      "Episode 7181 - Main Policy Loss: -9.7740, Entropy: 3.3686\n",
      "Episode 7191 - Main Policy Loss: -7.4979, Entropy: 3.1067\n",
      "Episode 7201 - Main Policy Loss: -7.5207, Entropy: 2.1293\n",
      "Episode 7211 - Main Policy Loss: -11.6634, Entropy: 3.7668\n",
      "Episode 7221 - Main Policy Loss: -11.0303, Entropy: 4.2847\n",
      "Episode 7231 - Main Policy Loss: -10.9809, Entropy: 1.9252\n",
      "Episode 7241 - Main Policy Loss: -12.6062, Entropy: 4.9099\n",
      "Episode 7251 - Main Policy Loss: -7.9648, Entropy: 2.5458\n",
      "Episode 7261 - Main Policy Loss: -9.8668, Entropy: 3.3174\n",
      "Episode 7271 - Main Policy Loss: -11.0556, Entropy: 2.6450\n",
      "Episode 7281 - Main Policy Loss: -10.1044, Entropy: 3.0839\n",
      "Episode 7291 - Main Policy Loss: -10.5440, Entropy: 1.0548\n",
      "Episode 7301 - Main Policy Loss: -12.2716, Entropy: 3.6890\n",
      "Episode 7311 - Main Policy Loss: -15.8641, Entropy: 2.9339\n",
      "Episode 7321 - Main Policy Loss: -9.7099, Entropy: 4.9173\n",
      "Episode 7331 - Main Policy Loss: -7.1648, Entropy: 3.7442\n",
      "Episode 7341 - Main Policy Loss: -11.6952, Entropy: 3.3444\n",
      "Episode 7351 - Main Policy Loss: -10.5138, Entropy: 2.8827\n",
      "Episode 7361 - Main Policy Loss: -2.9093, Entropy: 3.7945\n",
      "Episode 7371 - Main Policy Loss: -24.8208, Entropy: 2.9486\n",
      "Episode 7381 - Main Policy Loss: -12.2552, Entropy: 4.7035\n",
      "Episode 7391 - Main Policy Loss: -6.8852, Entropy: 3.7309\n",
      "Episode 7401 - Main Policy Loss: -13.2917, Entropy: 3.0288\n",
      "Episode 7411 - Main Policy Loss: -12.1783, Entropy: 4.0072\n",
      "Episode 7421 - Main Policy Loss: -12.0958, Entropy: 3.7655\n",
      "Episode 7431 - Main Policy Loss: -15.1166, Entropy: 3.0462\n",
      "Episode 7441 - Main Policy Loss: -13.8603, Entropy: 3.5696\n",
      "Episode 7451 - Main Policy Loss: -7.0748, Entropy: 3.5502\n",
      "Episode 7461 - Main Policy Loss: -20.4391, Entropy: 3.7336\n",
      "Episode 7471 - Main Policy Loss: -15.1311, Entropy: 3.5890\n",
      "Episode 7481 - Main Policy Loss: -13.6892, Entropy: 3.1038\n",
      "Episode 7491 - Main Policy Loss: -12.1451, Entropy: 3.9849\n",
      "Episode 7501 - Main Policy Loss: -15.9623, Entropy: 3.7528\n",
      "Episode 7511 - Main Policy Loss: -6.0467, Entropy: 3.2154\n",
      "Episode 7521 - Main Policy Loss: -4.8187, Entropy: 1.8407\n",
      "Episode 7531 - Main Policy Loss: -5.4379, Entropy: 3.2322\n",
      "Episode 7541 - Main Policy Loss: -8.0551, Entropy: 5.2598\n",
      "Episode 7551 - Main Policy Loss: -12.4868, Entropy: 3.8866\n",
      "Episode 7561 - Main Policy Loss: -2.2542, Entropy: 2.8212\n",
      "Episode 7571 - Main Policy Loss: -8.1204, Entropy: 3.2279\n",
      "Episode 7581 - Main Policy Loss: -5.7899, Entropy: 3.3281\n",
      "Episode 7591 - Main Policy Loss: -19.3258, Entropy: 2.8721\n",
      "Episode 7601 - Main Policy Loss: 0.0681, Entropy: 2.7094\n",
      "Episode 7611 - Main Policy Loss: -10.4671, Entropy: 1.7323\n",
      "Episode 7621 - Main Policy Loss: -3.8209, Entropy: 3.4738\n",
      "Episode 7631 - Main Policy Loss: -0.4436, Entropy: 2.9525\n",
      "Episode 7641 - Main Policy Loss: -6.9110, Entropy: 2.3842\n",
      "Episode 7651 - Main Policy Loss: -0.6939, Entropy: 0.9021\n",
      "Episode 7661 - Main Policy Loss: -1.9561, Entropy: 1.7013\n",
      "Episode 7671 - Main Policy Loss: 4.1933, Entropy: 3.1158\n",
      "Episode 7681 - Main Policy Loss: -15.0689, Entropy: 3.8361\n",
      "Episode 7691 - Main Policy Loss: 2.2236, Entropy: 1.6467\n",
      "Episode 7701 - Main Policy Loss: -0.3494, Entropy: 0.5644\n",
      "Episode 7711 - Main Policy Loss: 2.7836, Entropy: 1.8933\n",
      "Episode 7721 - Main Policy Loss: -4.3984, Entropy: 0.7863\n",
      "Episode 7731 - Main Policy Loss: -5.5726, Entropy: 0.9754\n",
      "Episode 7741 - Main Policy Loss: 0.0284, Entropy: 0.5174\n",
      "Episode 7751 - Main Policy Loss: -1.7308, Entropy: 1.4883\n",
      "Episode 7761 - Main Policy Loss: -21.7162, Entropy: 2.0527\n",
      "Episode 7771 - Main Policy Loss: -3.5624, Entropy: 2.8705\n",
      "Episode 7781 - Main Policy Loss: -5.8963, Entropy: 3.0599\n",
      "Episode 7791 - Main Policy Loss: -11.5689, Entropy: 3.4229\n",
      "Episode 7801 - Main Policy Loss: -6.5928, Entropy: 4.2737\n",
      "Episode 7811 - Main Policy Loss: -11.9708, Entropy: 4.8543\n",
      "Episode 7821 - Main Policy Loss: -0.4914, Entropy: 3.3108\n",
      "Episode 7831 - Main Policy Loss: -2.4474, Entropy: 2.6232\n",
      "Episode 7841 - Main Policy Loss: -12.4595, Entropy: 3.8957\n",
      "Episode 7851 - Main Policy Loss: -12.0872, Entropy: 3.8902\n",
      "Episode 7861 - Main Policy Loss: -14.1137, Entropy: 4.0705\n",
      "Episode 7871 - Main Policy Loss: -0.4558, Entropy: 1.8883\n",
      "Episode 7881 - Main Policy Loss: -0.8348, Entropy: 4.2322\n",
      "Episode 7891 - Main Policy Loss: -2.5096, Entropy: 4.3673\n",
      "Episode 7901 - Main Policy Loss: -23.0531, Entropy: 4.2782\n",
      "Episode 7911 - Main Policy Loss: -7.2831, Entropy: 2.8618\n",
      "Episode 7921 - Main Policy Loss: -3.7307, Entropy: 1.8247\n",
      "Episode 7931 - Main Policy Loss: 0.0171, Entropy: 1.0656\n",
      "Episode 7941 - Main Policy Loss: -3.1508, Entropy: 1.5097\n",
      "Episode 7951 - Main Policy Loss: -0.6943, Entropy: 2.1347\n",
      "Episode 7961 - Main Policy Loss: -3.1218, Entropy: 1.5745\n",
      "Episode 7971 - Main Policy Loss: -3.6527, Entropy: 1.5139\n",
      "Episode 7981 - Main Policy Loss: -0.7080, Entropy: 1.6382\n",
      "Episode 7991 - Main Policy Loss: -3.9846, Entropy: 1.9109\n",
      "Saved checkpoint at episode 8000/10000\n",
      "Episode 8001 - Main Policy Loss: 3.8565, Entropy: 0.3254\n",
      "Episode 8011 - Main Policy Loss: -3.8178, Entropy: 1.8859\n",
      "Episode 8021 - Main Policy Loss: -2.4416, Entropy: 2.3302\n",
      "Episode 8031 - Main Policy Loss: -14.9120, Entropy: 1.0443\n",
      "Episode 8041 - Main Policy Loss: -0.9799, Entropy: 0.7131\n",
      "Episode 8051 - Main Policy Loss: -2.1202, Entropy: 0.9638\n",
      "Episode 8061 - Main Policy Loss: -3.4585, Entropy: 2.1137\n",
      "Episode 8071 - Main Policy Loss: -3.6011, Entropy: 1.5846\n",
      "Episode 8081 - Main Policy Loss: -5.8539, Entropy: 2.7778\n",
      "Episode 8091 - Main Policy Loss: -4.1252, Entropy: 1.4386\n",
      "Episode 8101 - Main Policy Loss: -2.5823, Entropy: 2.7605\n",
      "Episode 8111 - Main Policy Loss: 0.4798, Entropy: 2.7920\n",
      "Episode 8121 - Main Policy Loss: -2.9795, Entropy: 3.0325\n",
      "Episode 8131 - Main Policy Loss: -5.8343, Entropy: 2.1856\n",
      "Episode 8141 - Main Policy Loss: -0.5921, Entropy: 2.0473\n",
      "Episode 8151 - Main Policy Loss: -1.8624, Entropy: 1.8869\n",
      "Episode 8161 - Main Policy Loss: -7.7115, Entropy: 1.6407\n",
      "Episode 8171 - Main Policy Loss: -6.1121, Entropy: 1.3548\n",
      "Episode 8181 - Main Policy Loss: -0.5088, Entropy: 0.7378\n",
      "Episode 8191 - Main Policy Loss: -1.8434, Entropy: 1.0143\n",
      "Episode 8201 - Main Policy Loss: 0.8573, Entropy: 1.2942\n",
      "Episode 8211 - Main Policy Loss: -0.9679, Entropy: 1.3526\n",
      "Episode 8221 - Main Policy Loss: -1.0151, Entropy: 2.1640\n",
      "Episode 8231 - Main Policy Loss: -7.0928, Entropy: 2.8635\n",
      "Episode 8241 - Main Policy Loss: -1.8795, Entropy: 2.2458\n",
      "Episode 8251 - Main Policy Loss: -3.2678, Entropy: 1.5408\n",
      "Episode 8261 - Main Policy Loss: -4.2339, Entropy: 1.6906\n",
      "Episode 8271 - Main Policy Loss: -1.2699, Entropy: 0.9829\n",
      "Episode 8281 - Main Policy Loss: -0.5213, Entropy: 1.3530\n",
      "Episode 8291 - Main Policy Loss: -3.3445, Entropy: 2.6675\n",
      "Episode 8301 - Main Policy Loss: 0.0170, Entropy: 1.0948\n",
      "Episode 8311 - Main Policy Loss: -0.8779, Entropy: 2.2752\n",
      "Episode 8321 - Main Policy Loss: 0.0480, Entropy: 1.3553\n",
      "Episode 8331 - Main Policy Loss: -1.4155, Entropy: 1.0758\n",
      "Episode 8341 - Main Policy Loss: -6.1327, Entropy: 2.2850\n",
      "Episode 8351 - Main Policy Loss: -4.0483, Entropy: 1.3835\n",
      "Episode 8361 - Main Policy Loss: -6.5398, Entropy: 1.8882\n",
      "Episode 8371 - Main Policy Loss: -0.4607, Entropy: 0.7487\n",
      "Episode 8381 - Main Policy Loss: -1.4248, Entropy: 1.1519\n",
      "Episode 8391 - Main Policy Loss: -4.8542, Entropy: 2.0623\n",
      "Episode 8401 - Main Policy Loss: -3.4556, Entropy: 1.5571\n",
      "Episode 8411 - Main Policy Loss: 0.4258, Entropy: 1.5483\n",
      "Episode 8421 - Main Policy Loss: -2.0426, Entropy: 0.8383\n",
      "Episode 8431 - Main Policy Loss: -3.6194, Entropy: 1.0328\n",
      "Episode 8441 - Main Policy Loss: -2.9617, Entropy: 1.0595\n",
      "Episode 8451 - Main Policy Loss: -2.7688, Entropy: 2.0300\n",
      "Episode 8461 - Main Policy Loss: -4.0107, Entropy: 2.1069\n",
      "Episode 8471 - Main Policy Loss: 0.0942, Entropy: 2.1167\n",
      "Episode 8481 - Main Policy Loss: -2.6787, Entropy: 1.0152\n",
      "Episode 8491 - Main Policy Loss: -5.1123, Entropy: 1.1366\n",
      "Episode 8501 - Main Policy Loss: -0.6630, Entropy: 0.4194\n",
      "Episode 8511 - Main Policy Loss: -0.9750, Entropy: 0.7441\n",
      "Episode 8521 - Main Policy Loss: 3.0147, Entropy: 1.2303\n",
      "Episode 8531 - Main Policy Loss: -3.6855, Entropy: 0.9792\n",
      "Episode 8541 - Main Policy Loss: 1.0769, Entropy: 1.6886\n",
      "Episode 8551 - Main Policy Loss: -1.9295, Entropy: 1.2241\n",
      "Episode 8561 - Main Policy Loss: -0.8083, Entropy: 0.8260\n",
      "Episode 8571 - Main Policy Loss: -1.2005, Entropy: 1.5160\n",
      "Episode 8581 - Main Policy Loss: -2.1284, Entropy: 0.9135\n",
      "Episode 8591 - Main Policy Loss: -2.5673, Entropy: 0.9127\n",
      "Episode 8601 - Main Policy Loss: -1.2293, Entropy: 0.9878\n",
      "Episode 8611 - Main Policy Loss: 0.3170, Entropy: 1.0767\n",
      "Episode 8621 - Main Policy Loss: -0.1723, Entropy: 1.2092\n",
      "Episode 8631 - Main Policy Loss: -4.5996, Entropy: 2.8288\n",
      "Episode 8641 - Main Policy Loss: -0.6092, Entropy: 1.2517\n",
      "Episode 8651 - Main Policy Loss: -0.4315, Entropy: 0.7928\n",
      "Episode 8661 - Main Policy Loss: -3.9699, Entropy: 2.1011\n",
      "Episode 8671 - Main Policy Loss: -5.6558, Entropy: 2.8067\n",
      "Episode 8681 - Main Policy Loss: -1.8138, Entropy: 1.0045\n",
      "Episode 8691 - Main Policy Loss: -0.2373, Entropy: 0.2690\n",
      "Episode 8701 - Main Policy Loss: -0.0814, Entropy: 0.0520\n",
      "Episode 8711 - Main Policy Loss: -2.0468, Entropy: 1.5552\n",
      "Episode 8721 - Main Policy Loss: -15.9937, Entropy: 1.7493\n",
      "Episode 8731 - Main Policy Loss: -11.8253, Entropy: 1.9996\n",
      "Episode 8741 - Main Policy Loss: -8.6933, Entropy: 2.1756\n",
      "Episode 8751 - Main Policy Loss: -2.8045, Entropy: 3.1535\n",
      "Episode 8761 - Main Policy Loss: -0.9894, Entropy: 2.2351\n",
      "Episode 8771 - Main Policy Loss: -0.1515, Entropy: 2.3557\n",
      "Episode 8781 - Main Policy Loss: -2.1369, Entropy: 3.5392\n",
      "Episode 8791 - Main Policy Loss: -10.0390, Entropy: 2.6601\n",
      "Episode 8801 - Main Policy Loss: 2.7540, Entropy: 4.1377\n",
      "Episode 8811 - Main Policy Loss: 2.6279, Entropy: 4.4412\n",
      "Episode 8821 - Main Policy Loss: -3.9861, Entropy: 4.3800\n",
      "Episode 8831 - Main Policy Loss: -4.6516, Entropy: 4.3489\n",
      "Episode 8841 - Main Policy Loss: 1.7711, Entropy: 3.4574\n",
      "Episode 8851 - Main Policy Loss: -4.6561, Entropy: 2.7586\n",
      "Episode 8861 - Main Policy Loss: -3.1271, Entropy: 5.4761\n",
      "Episode 8871 - Main Policy Loss: -5.0885, Entropy: 5.7970\n",
      "Episode 8881 - Main Policy Loss: 2.6630, Entropy: 4.0028\n",
      "Episode 8891 - Main Policy Loss: -9.5855, Entropy: 3.9500\n",
      "Episode 8901 - Main Policy Loss: -1.4540, Entropy: 2.4691\n",
      "Episode 8911 - Main Policy Loss: 0.1698, Entropy: 3.0080\n",
      "Episode 8921 - Main Policy Loss: -12.8677, Entropy: 1.7924\n",
      "Episode 8931 - Main Policy Loss: -9.8536, Entropy: 3.0016\n",
      "Episode 8941 - Main Policy Loss: -2.5075, Entropy: 2.7121\n",
      "Episode 8951 - Main Policy Loss: -0.0753, Entropy: 3.3965\n",
      "Episode 8961 - Main Policy Loss: -5.6224, Entropy: 3.6603\n",
      "Episode 8971 - Main Policy Loss: -1.8523, Entropy: 3.7040\n",
      "Episode 8981 - Main Policy Loss: -0.1187, Entropy: 2.1761\n",
      "Episode 8991 - Main Policy Loss: -8.3080, Entropy: 2.0403\n",
      "Saved checkpoint at episode 9000/10000\n",
      "Episode 9001 - Main Policy Loss: -1.6806, Entropy: 2.6634\n",
      "Episode 9011 - Main Policy Loss: -3.7663, Entropy: 2.4296\n",
      "Episode 9021 - Main Policy Loss: 1.9872, Entropy: 2.6384\n",
      "Episode 9031 - Main Policy Loss: 3.0152, Entropy: 1.6216\n",
      "Episode 9041 - Main Policy Loss: -9.1810, Entropy: 2.2300\n",
      "Episode 9051 - Main Policy Loss: -2.7348, Entropy: 2.5453\n",
      "Episode 9061 - Main Policy Loss: -4.4061, Entropy: 1.8558\n",
      "Episode 9071 - Main Policy Loss: -0.4951, Entropy: 1.4104\n",
      "Episode 9081 - Main Policy Loss: -2.8128, Entropy: 2.4417\n",
      "Episode 9091 - Main Policy Loss: -1.4044, Entropy: 1.1438\n",
      "Episode 9101 - Main Policy Loss: -3.8936, Entropy: 2.1819\n",
      "Episode 9111 - Main Policy Loss: -2.9759, Entropy: 1.5174\n",
      "Episode 9121 - Main Policy Loss: -6.3903, Entropy: 2.1533\n",
      "Episode 9131 - Main Policy Loss: -4.6717, Entropy: 2.6062\n",
      "Episode 9141 - Main Policy Loss: 1.6629, Entropy: 2.6911\n",
      "Episode 9151 - Main Policy Loss: 0.2996, Entropy: 1.4915\n",
      "Episode 9161 - Main Policy Loss: 0.1663, Entropy: 2.3176\n",
      "Episode 9171 - Main Policy Loss: -3.6955, Entropy: 1.4459\n",
      "Episode 9181 - Main Policy Loss: 4.5537, Entropy: 4.2836\n",
      "Episode 9191 - Main Policy Loss: -4.9965, Entropy: 2.8258\n",
      "Episode 9201 - Main Policy Loss: -7.8388, Entropy: 5.0809\n",
      "Episode 9211 - Main Policy Loss: -6.6093, Entropy: 2.5542\n",
      "Episode 9221 - Main Policy Loss: -3.6158, Entropy: 4.4333\n",
      "Episode 9231 - Main Policy Loss: -4.6574, Entropy: 1.5745\n",
      "Episode 9241 - Main Policy Loss: -4.3982, Entropy: 3.0337\n",
      "Episode 9251 - Main Policy Loss: -2.1295, Entropy: 2.4245\n",
      "Episode 9261 - Main Policy Loss: -2.0244, Entropy: 1.6843\n",
      "Episode 9271 - Main Policy Loss: -3.9484, Entropy: 2.6674\n",
      "Episode 9281 - Main Policy Loss: -0.4174, Entropy: 1.5908\n",
      "Episode 9291 - Main Policy Loss: -7.2543, Entropy: 3.0106\n",
      "Episode 9301 - Main Policy Loss: -3.1433, Entropy: 1.7060\n",
      "Episode 9311 - Main Policy Loss: -2.8956, Entropy: 1.3579\n",
      "Episode 9321 - Main Policy Loss: 4.7111, Entropy: 1.3709\n",
      "Episode 9331 - Main Policy Loss: -3.4386, Entropy: 1.4263\n",
      "Episode 9341 - Main Policy Loss: -5.0128, Entropy: 1.8331\n",
      "Episode 9351 - Main Policy Loss: -3.2722, Entropy: 1.6794\n",
      "Episode 9361 - Main Policy Loss: -3.1536, Entropy: 0.8423\n",
      "Episode 9371 - Main Policy Loss: 2.6611, Entropy: 2.3945\n",
      "Episode 9381 - Main Policy Loss: -1.6994, Entropy: 1.0944\n",
      "Episode 9391 - Main Policy Loss: 3.3041, Entropy: 2.0156\n",
      "Episode 9401 - Main Policy Loss: -2.9379, Entropy: 2.8642\n",
      "Episode 9411 - Main Policy Loss: -1.3957, Entropy: 2.7491\n",
      "Episode 9421 - Main Policy Loss: -0.7611, Entropy: 2.2539\n",
      "Episode 9431 - Main Policy Loss: -4.7519, Entropy: 2.6478\n",
      "Episode 9441 - Main Policy Loss: -1.8423, Entropy: 2.9782\n",
      "Episode 9451 - Main Policy Loss: -1.3399, Entropy: 1.3152\n",
      "Episode 9461 - Main Policy Loss: -1.7510, Entropy: 1.0823\n",
      "Episode 9471 - Main Policy Loss: -0.7387, Entropy: 0.9851\n",
      "Episode 9481 - Main Policy Loss: -1.2024, Entropy: 2.6975\n",
      "Episode 9491 - Main Policy Loss: -1.2203, Entropy: 1.6000\n",
      "Episode 9501 - Main Policy Loss: -0.8367, Entropy: 1.0038\n",
      "Episode 9511 - Main Policy Loss: -1.0521, Entropy: 1.4709\n",
      "Episode 9521 - Main Policy Loss: 0.1295, Entropy: 1.1716\n",
      "Episode 9531 - Main Policy Loss: -2.0537, Entropy: 1.1929\n",
      "Episode 9541 - Main Policy Loss: -2.4327, Entropy: 0.7072\n",
      "Episode 9551 - Main Policy Loss: -1.2308, Entropy: 0.7828\n",
      "Episode 9561 - Main Policy Loss: 0.0988, Entropy: 1.2060\n",
      "Episode 9571 - Main Policy Loss: -0.3856, Entropy: 0.4199\n",
      "Episode 9581 - Main Policy Loss: -2.4464, Entropy: 1.4142\n",
      "Episode 9591 - Main Policy Loss: -1.0197, Entropy: 1.2742\n",
      "Episode 9601 - Main Policy Loss: -3.3077, Entropy: 1.6083\n",
      "Episode 9611 - Main Policy Loss: -2.2283, Entropy: 1.8152\n",
      "Episode 9621 - Main Policy Loss: -9.3923, Entropy: 3.4110\n",
      "Episode 9631 - Main Policy Loss: -4.1971, Entropy: 2.6560\n",
      "Episode 9641 - Main Policy Loss: -2.8185, Entropy: 1.5606\n",
      "Episode 9651 - Main Policy Loss: -5.0788, Entropy: 1.9976\n",
      "Episode 9661 - Main Policy Loss: -13.5803, Entropy: 3.8679\n",
      "Episode 9671 - Main Policy Loss: -3.9603, Entropy: 2.6200\n",
      "Episode 9681 - Main Policy Loss: -5.6570, Entropy: 2.9954\n",
      "Episode 9691 - Main Policy Loss: -8.1937, Entropy: 4.1500\n",
      "Episode 9701 - Main Policy Loss: -2.5342, Entropy: 2.6130\n",
      "Episode 9711 - Main Policy Loss: -3.0647, Entropy: 2.1247\n",
      "Episode 9721 - Main Policy Loss: -3.6583, Entropy: 1.6322\n",
      "Episode 9731 - Main Policy Loss: -10.7255, Entropy: 3.3365\n",
      "Episode 9741 - Main Policy Loss: 0.2085, Entropy: 2.0748\n",
      "Episode 9751 - Main Policy Loss: -3.7984, Entropy: 1.9963\n",
      "Episode 9761 - Main Policy Loss: -3.4940, Entropy: 2.6811\n",
      "Episode 9771 - Main Policy Loss: -7.6959, Entropy: 2.2344\n",
      "Episode 9781 - Main Policy Loss: -0.5033, Entropy: 1.6838\n",
      "Episode 9791 - Main Policy Loss: 2.9236, Entropy: 2.5085\n",
      "Episode 9801 - Main Policy Loss: -11.4702, Entropy: 1.6584\n",
      "Episode 9811 - Main Policy Loss: -4.3771, Entropy: 1.5046\n",
      "Episode 9821 - Main Policy Loss: -3.2248, Entropy: 2.0609\n",
      "Episode 9831 - Main Policy Loss: -6.8737, Entropy: 1.9838\n",
      "Episode 9841 - Main Policy Loss: -1.7833, Entropy: 2.0131\n",
      "Episode 9851 - Main Policy Loss: -7.2079, Entropy: 1.1504\n",
      "Episode 9861 - Main Policy Loss: -0.5383, Entropy: 3.0061\n",
      "Episode 9871 - Main Policy Loss: -1.0739, Entropy: 2.6415\n",
      "Episode 9881 - Main Policy Loss: 4.5022, Entropy: 3.0301\n",
      "Episode 9891 - Main Policy Loss: -6.4890, Entropy: 2.5021\n",
      "Episode 9901 - Main Policy Loss: -3.4223, Entropy: 2.8708\n",
      "Episode 9911 - Main Policy Loss: -8.8451, Entropy: 0.7360\n",
      "Episode 9921 - Main Policy Loss: 2.4009, Entropy: 1.7579\n",
      "Episode 9931 - Main Policy Loss: -8.1954, Entropy: 1.9427\n",
      "Episode 9941 - Main Policy Loss: -2.5345, Entropy: 1.5793\n",
      "Episode 9951 - Main Policy Loss: -12.9227, Entropy: 2.2019\n",
      "Episode 9961 - Main Policy Loss: -1.3928, Entropy: 1.8406\n",
      "Episode 9971 - Main Policy Loss: -0.7211, Entropy: 1.7441\n",
      "Episode 9981 - Main Policy Loss: -2.2232, Entropy: 1.0095\n",
      "Episode 9991 - Main Policy Loss: -5.0997, Entropy: 1.2396\n",
      "\n",
      "Episode 10000/10000\n",
      "Loss - Main: -6.4245, Adv: -7.6299\n",
      "Learning rate - Main: 0.000391\n",
      "Connected to Java server at localhost:3\n",
      "Connected to ID Alpha-Beta server at localhost:9\n",
      "ID AlphaBeta reset\n",
      "ID Alpha-Beta reset response: {'current_role': 'RED', 'ai_role': 'BLUE', 'legal_moves': ['A0-A1', 'A0-B0', 'A0-B1', 'A3-B4', 'A4-A5', 'A4-B4', 'A4-B5', 'B2-C3', 'B3-B4', 'B3-C3', 'B3-C4', 'C1-D2', 'C2-C3', 'C2-D2', 'C2-D3', 'D0-E1', 'D1-D2', 'D1-E1', 'D1-E2', 'E0-E1', 'E0-F0', 'E0-F1'], 'board': [['RED_KING', 'RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'EMPTY'], ['RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN'], ['RED_COURTESAN', 'RED_COURTESAN', 'RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN'], ['RED_COURTESAN', 'RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN'], ['RED_COURTESAN', 'EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN'], ['EMPTY', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_COURTESAN', 'BLUE_KING']]}\n",
      "Set parameters response: {'agent_type': 'ID Alpha-Beta', 'max_depth': 8, 'status': 'parameters updated'}\n",
      "\n",
      "Episode 1/1\n",
      "Policy Network plays second (BLUE)\n",
      "Alpha-Beta agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A0-B0 (computed in 30000ms)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B KRRR-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B KRRB-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 3\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B2-B3 (computed in 30001ms)\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B KR-R-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B KR-R--\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 5\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A4-A5 (computed in 30000ms)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B KR-R--\n",
      "A RRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR---\n",
      "B KR-RB-\n",
      "A RRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 7\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A5-B4 (computed in 28655ms)\n",
      "Selected move: A5-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR---\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RB-BBB\n",
      "D RR-BBB\n",
      "C RRR---\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 9\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: D0-E1 (computed in 30000ms)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RR-BBB\n",
      "D -R-BBB\n",
      "C RRR---\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RR-BBB\n",
      "D -R-B-B\n",
      "C RRR-B-\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 11\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: E1-F1 (computed in 26629ms)\n",
      "Selected move: E1-F1\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C RRR-B-\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C RRR---\n",
      "B KR-BR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 13\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C2-B3 (computed in 27534ms)\n",
      "Selected move: C2-B3\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C RR----\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E R--BBB\n",
      "D -R-B--\n",
      "C RR--B-\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 15\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: F1-F2 (computed in 20300ms)\n",
      "Selected move: F1-F2\n",
      "  012345\n",
      "F --RBBQ\n",
      "E R--BBB\n",
      "D -R-B--\n",
      "C RR--B-\n",
      "B KR-RR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F --RBBQ\n",
      "E R--BBB\n",
      "D -R-B--\n",
      "C RR----\n",
      "B KR-BR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 17\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: F2-E3 (computed in 20866ms)\n",
      "Selected move: F2-E3\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--RBB\n",
      "D -R-B--\n",
      "C RR----\n",
      "B KR-BR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-E3\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--BBB\n",
      "D -R----\n",
      "C RR----\n",
      "B KR-BR-\n",
      "A RRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 19\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A2-B3 (computed in 7525ms)\n",
      "Selected move: A2-B3\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--BBB\n",
      "D -R----\n",
      "C RR----\n",
      "B KR-RR-\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D -R--B-\n",
      "C RR----\n",
      "B KR-RR-\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 21\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B1-C2 (computed in 22162ms)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D -R--B-\n",
      "C RRR---\n",
      "B K--RR-\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D -R----\n",
      "C RRR-B-\n",
      "B K--RR-\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 23\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B4-C4 (computed in 9083ms)\n",
      "Selected move: B4-C4\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D -R----\n",
      "C RRR-R-\n",
      "B K--R--\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R--BBB\n",
      "D -R----\n",
      "C RRR-R-\n",
      "B K--R--\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 25\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: B3-C3 (computed in 20161ms)\n",
      "Selected move: B3-C3\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R--BBB\n",
      "D -R----\n",
      "C RRRRR-\n",
      "B K-----\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 26\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R--B-B\n",
      "D -R--B-\n",
      "C RRRRR-\n",
      "B K-----\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 27\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C1-D2 (computed in 18230ms)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R--B-B\n",
      "D -RR-B-\n",
      "C R-RRR-\n",
      "B K-----\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 28\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R--B-B\n",
      "D -RR---\n",
      "C R-RRB-\n",
      "B K-----\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 29\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C3-C4 (computed in 22961ms)\n",
      "Selected move: C3-C4\n",
      "  012345\n",
      "F ---B-Q\n",
      "E R--B-B\n",
      "D -RR---\n",
      "C R-R-R-\n",
      "B K-----\n",
      "A RR-R--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 30\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F5-E5\n",
      "  012345\n",
      "F ---B-B\n",
      "E R--B-Q\n",
      "D -RR---\n",
      "C R-R-R-\n",
      "B K-----\n",
      "A RR-R--\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 31\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: A3-B4 (computed in 30000ms)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F ---B-B\n",
      "E R--B-Q\n",
      "D -RR---\n",
      "C R-R-R-\n",
      "B K---R-\n",
      "A RR----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 32\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F3-E2\n",
      "  012345\n",
      "F -----B\n",
      "E R-BB-Q\n",
      "D -RR---\n",
      "C R-R-R-\n",
      "B K---R-\n",
      "A RR----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 33\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: C4-D5 (computed in 9342ms)\n",
      "Selected move: C4-D5\n",
      "  012345\n",
      "F -----B\n",
      "E R-BB-Q\n",
      "D -RR--R\n",
      "C R-R---\n",
      "B K---R-\n",
      "A RR----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 34\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E2-D2\n",
      "  012345\n",
      "F -----B\n",
      "E R--B-Q\n",
      "D -RB--R\n",
      "C R-R---\n",
      "B K---R-\n",
      "A RR----\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 35\n",
      "Player: Alpha-Beta (RED)\n",
      "ID Alpha-Beta move: D5-E5 (computed in 1ms)\n",
      "Selected move: D5-E5\n",
      "  012345\n",
      "F -----B\n",
      "E R--B-R\n",
      "D -RB---\n",
      "C R-R---\n",
      "B K---R-\n",
      "A RR----\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Game Over! Winner: alpha_beta\n",
      "\n",
      "Test Results Summary:\n",
      "Episodes: 1\n",
      "Policy Network wins: 0 (0.0%)\n",
      "Alpha-Beta wins: 1 (100.0%)\n",
      "Ties: 0 (0.0%)\n",
      "Average steps per episode: 35.0\n",
      "Connection to Java server closed\n",
      "Closed connection to ID Alpha-Beta server\n",
      "\n",
      "Episode 10000/10000\n",
      "Win rate: 0.0000\n",
      "Learning Rate: 0.000391\n",
      "Saved checkpoint at episode 10000/10000\n"
     ]
    }
   ],
   "source": [
    "env = kac.KingAndCourtesanEnv(\n",
    "    port=3,\n",
    ")\n",
    "\n",
    "#for train_index in range(NUMBER_OF_TRAININGS):\n",
    "reinforce_policy_nn, episodes_win_rates, main_network_episodes_losses, adversary_network_episodes_losses = train_reinforce_discrete(\n",
    "    env=env,\n",
    "    num_episodes=10000,\n",
    "    max_episode_duration=float('inf'),\n",
    "    learning_rate=0.0005,\n",
    "    gamma=0.99,\n",
    "    entropy_coef=0.05,  # Entropy regularization\n",
    "    grad_clip=1.0,  # Gradient clipping\n",
    "    eval_frequency=5000,  # Evaluate every 50 episodes\n",
    "    verbose=True,\n",
    "    heuristic_scale=0.2,\n",
    "    opponent_reward_weight=0.3,\n",
    "    checkpoint_frequency=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMd8icPmV5kV"
   },
   "outputs": [],
   "source": [
    "torch.save(reinforce_policy_nn, MODELS_DIR / \"reinforce_policy_network.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742267905643,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "9st68oTbV5kV",
    "outputId": "e41d836b-ee15-4ae2-f4c0-6c859c27d591"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reinforce_train_stats']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump({'episodes_win_rates': episodes_win_rates, 'main_network_episodes_losses': main_network_episodes_losses,\n",
    "             'adversary_network_episodes_losses': adversary_network_episodes_losses}, 'reinforce_train_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742267928541,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "QHpnR9D0YSv0",
    "outputId": "512076ec-ff80-4840-a8b5-668c494bf351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication error: Received empty response from server\n",
      "Attempting to reconnect...\n",
      "Connected to Java server at localhost:3\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "reinforce_trains_result_list: List[List[Union[int, float]]] = [[], []]\n",
    "reinforce_trains_result_list[0] = list(range(len(episodes_win_rates)))\n",
    "reinforce_trains_result_list[1] = episodes_win_rates\n",
    "\n",
    "reinforce_trains_result_df = pd.DataFrame(\n",
    "    np.array(reinforce_trains_result_list).T,\n",
    "    columns=[\"num_episodes\", \"win_rate\"],\n",
    ")\n",
    "reinforce_trains_result_df[\"agent\"] = \"REINFORCE\"\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcGkOZ-xYSv0"
   },
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1742267940594,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "NRq_U97oYSv0",
    "outputId": "374d63d9-9f5b-4544-d732-7fb16f12a565"
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    x=\"num_episodes\",\n",
    "    y=\"win_rate\",\n",
    "    kind=\"line\",\n",
    "    hue=\"agent\",\n",
    "    estimator=None,\n",
    "    data=reinforce_trains_result_df,\n",
    "    height=7,\n",
    "    aspect=2,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.savefig(PLOTS_DIR / \"reinforce_trains_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1742268055748,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "NisEQa49YSv0",
    "outputId": "e571a339-07ce-4eaf-ad31-96099bd0f5f7"
   },
   "outputs": [],
   "source": [
    "all_trains_result_df = pd.concat(\n",
    "    [\n",
    "        reinforce_trains_result_df,\n",
    "        reinforce_trains_result_df,\n",
    "    ]\n",
    ")\n",
    "g = sns.relplot(\n",
    "    x=\"num_episodes\",\n",
    "    y=\"win_rate\",\n",
    "    kind=\"line\",\n",
    "    hue=\"agent\",\n",
    "    data=all_trains_result_df,\n",
    "    height=7,\n",
    "    aspect=2,\n",
    ")\n",
    "plt.savefig(PLOTS_DIR / \"trains_results_agg.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMV3HH_3YSv0"
   },
   "source": [
    "### Testing the agent against a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210662,
     "status": "ok",
     "timestamp": 1742268506188,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "ibMaJf_lYSv0",
    "outputId": "85c866f1-abbb-4e4b-a6b0-cc1b77e0f3fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n",
      "\n",
      "Episode 1/5\n",
      "Policy Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-RB\n",
      "B RRR--B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-C4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRR---\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RR-R--\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B RR-B--\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B RR-B--\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRB--B\n",
      "B RR----\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: B1-B2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRB--B\n",
      "B R-R---\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRB---\n",
      "B R-R-B-\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C R-R---\n",
      "B R-R-B-\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RB-BBB\n",
      "D RR-BBB\n",
      "C R-R---\n",
      "B R-R-B-\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RR-BBB\n",
      "D -R-BBB\n",
      "C R-R---\n",
      "B R-R-B-\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RR-BBB\n",
      "D -R-B-B\n",
      "C R-R-B-\n",
      "B R-R-B-\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: E1-F2\n",
      "  012345\n",
      "F -BRBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C R-R-B-\n",
      "B R-R-B-\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -BRBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C R-R---\n",
      "B R-RBB-\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F -BRBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C R-R---\n",
      "B RKRBB-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F -BRBBQ\n",
      "E R--BBB\n",
      "D -R-B-B\n",
      "C R-B---\n",
      "B RKR-B-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: D1-C2\n",
      "  012345\n",
      "F -BRBBQ\n",
      "E R--BBB\n",
      "D ---B-B\n",
      "C R-R---\n",
      "B RKR-B-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-F2\n",
      "  012345\n",
      "F --BBBQ\n",
      "E R--BBB\n",
      "D ---B-B\n",
      "C R-R---\n",
      "B RKR-B-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: C2-D2\n",
      "  012345\n",
      "F --BBBQ\n",
      "E R--BBB\n",
      "D --RB-B\n",
      "C R-----\n",
      "B RKR-B-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F --BBBQ\n",
      "E R--BBB\n",
      "D --RB--\n",
      "C R---B-\n",
      "B RKR-B-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: E0-E1\n",
      "  012345\n",
      "F --BBBQ\n",
      "E -R-BBB\n",
      "D --RB--\n",
      "C R---B-\n",
      "B RKR-B-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E -R-BBB\n",
      "D --RB--\n",
      "C R-----\n",
      "B RKRBB-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E -R-BBB\n",
      "D --RB--\n",
      "C R-----\n",
      "B RK-RB-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F2-F1\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E -R-BBB\n",
      "D --RB--\n",
      "C R-----\n",
      "B RK-RB-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C1\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E -R-BBB\n",
      "D --RB--\n",
      "C RK----\n",
      "B R--RB-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 26\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-E0\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BR-BBB\n",
      "D --RB--\n",
      "C RK----\n",
      "B R--RB-\n",
      "A -RRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: A5-B5\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BR-BBB\n",
      "D --RB--\n",
      "C RK----\n",
      "B R--RBR\n",
      "A -RRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 28\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B4-B5\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BR-BBB\n",
      "D --RB--\n",
      "C RK----\n",
      "B R--R-B\n",
      "A -RRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: C0-D0\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BR-BBB\n",
      "D R-RB--\n",
      "C -K----\n",
      "B R--R-B\n",
      "A -RRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 30\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BR-BBB\n",
      "D R-RB--\n",
      "C -K----\n",
      "B R--R--\n",
      "A -RRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: B0-C0\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BR-BBB\n",
      "D R-RB--\n",
      "C RK----\n",
      "B ---R--\n",
      "A -RRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 32\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BR-B-B\n",
      "D R-RBB-\n",
      "C RK----\n",
      "B ---R--\n",
      "A -RRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: E1-E0\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D R-RBB-\n",
      "C RK----\n",
      "B ---R--\n",
      "A -RRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 34\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D R-RB--\n",
      "C RK--B-\n",
      "B ---R--\n",
      "A -RRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D RKRB--\n",
      "C R---B-\n",
      "B ---R--\n",
      "A -RRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 36\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D RKRB--\n",
      "C R-----\n",
      "B ---B--\n",
      "A -RRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F ---BBQ\n",
      "E R--B-B\n",
      "D RKRB--\n",
      "C R-----\n",
      "B --RB--\n",
      "A -R-R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 38\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F5-E5\n",
      "  012345\n",
      "F ---BBB\n",
      "E R--B-Q\n",
      "D RKRB--\n",
      "C R-----\n",
      "B --RB--\n",
      "A -R-R-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F ---BBB\n",
      "E R--B-Q\n",
      "D RKRB--\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 40\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F ---B-B\n",
      "E R--BBQ\n",
      "D RKRB--\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E3\n",
      "  012345\n",
      "F ---B-B\n",
      "E R--RBQ\n",
      "D RK-B--\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 42\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-E3\n",
      "  012345\n",
      "F ---B-B\n",
      "E R--BBQ\n",
      "D RK----\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F1\n",
      "  012345\n",
      "F -R-B-B\n",
      "E ---BBQ\n",
      "D RK----\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 44\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E3-E2\n",
      "  012345\n",
      "F -R-B-B\n",
      "E --B-BQ\n",
      "D RK----\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: F1-F2\n",
      "  012345\n",
      "F --RB-B\n",
      "E --B-BQ\n",
      "D RK----\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 46\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F --RB-B\n",
      "E -B--BQ\n",
      "D RK----\n",
      "C R-----\n",
      "B --RB--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 47\n",
      "Player: Random (RED)\n",
      "Selected move: B2-B3\n",
      "  012345\n",
      "F --RB-B\n",
      "E -B--BQ\n",
      "D RK----\n",
      "C R-----\n",
      "B ---R--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 48\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F --RB-B\n",
      "E -B---Q\n",
      "D RK--B-\n",
      "C R-----\n",
      "B ---R--\n",
      "A --RR-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 49\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F --RB-B\n",
      "E -B---Q\n",
      "D RK--B-\n",
      "C R-----\n",
      "B --RR--\n",
      "A ---R-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Move 50\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F --RB-B\n",
      "E -B---Q\n",
      "D RK----\n",
      "C R---B-\n",
      "B --RR--\n",
      "A ---R-B\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (3,1)\n",
      "\n",
      "Episode 2/5\n",
      "Policy Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: A4-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRRRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B RRRBRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R--BBB\n",
      "C RRR--B\n",
      "B RRRBRB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D R--BBB\n",
      "C RRB--B\n",
      "B RRR-RB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: D0-D1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D -R-BBB\n",
      "C RRB--B\n",
      "B RRR-RB\n",
      "A KRRR--\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-RBBB\n",
      "D -R-BBB\n",
      "C RRB--B\n",
      "B RRR-R-\n",
      "A KRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RRRBBB\n",
      "D ---BBB\n",
      "C RRB--B\n",
      "B RRR-R-\n",
      "A KRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RRRBBB\n",
      "D ---BBB\n",
      "C RRB---\n",
      "B RRR-B-\n",
      "A KRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RRRBBB\n",
      "D ---BBB\n",
      "C RRR---\n",
      "B R-R-B-\n",
      "A KRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-E2\n",
      "  012345\n",
      "F --BBBQ\n",
      "E RRBBBB\n",
      "D ---BBB\n",
      "C RRR---\n",
      "B R-R-B-\n",
      "A KRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E RRBBBB\n",
      "D ---BBB\n",
      "C RR-R--\n",
      "B R-R-B-\n",
      "A KRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F --BBBQ\n",
      "E RRBBBB\n",
      "D ---B-B\n",
      "C RR-RB-\n",
      "B R-R-B-\n",
      "A KRRR-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E RRBBBB\n",
      "D ---B-B\n",
      "C RR-RB-\n",
      "B R-RRB-\n",
      "A KR-R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F --BBBQ\n",
      "E RRBBBB\n",
      "D ---B-B\n",
      "C RR-R--\n",
      "B R-RBB-\n",
      "A KR-R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: C3-D4\n",
      "  012345\n",
      "F --BBBQ\n",
      "E RRBBBB\n",
      "D ---BRB\n",
      "C RR----\n",
      "B R-RBB-\n",
      "A KR-R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E3-D4\n",
      "  012345\n",
      "F --BBBQ\n",
      "E RRB-BB\n",
      "D ---BBB\n",
      "C RR----\n",
      "B R-RBB-\n",
      "A KR-R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F1\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E -RB-BB\n",
      "D ---BBB\n",
      "C RR----\n",
      "B R-RBB-\n",
      "A KR-R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E -RB-BB\n",
      "D ---B-B\n",
      "C RR--B-\n",
      "B R-RBB-\n",
      "A KR-R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E -RB-BB\n",
      "D ---B-B\n",
      "C RR--B-\n",
      "B R-RBR-\n",
      "A KR---B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E -B--BB\n",
      "D ---B-B\n",
      "C RR--B-\n",
      "B R-RBR-\n",
      "A KR---B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: C0-D0\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E -B--BB\n",
      "D R--B-B\n",
      "C -R--B-\n",
      "B R-RBR-\n",
      "A KR---B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F2-F1\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E -B--BB\n",
      "D R--B-B\n",
      "C -R--B-\n",
      "B R-RBR-\n",
      "A KR---B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: D0-D1\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E -B--BB\n",
      "D -R-B-B\n",
      "C -R--B-\n",
      "B R-RBR-\n",
      "A KR---B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-E0\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BB--BB\n",
      "D -R-B-B\n",
      "C -R--B-\n",
      "B R-RBR-\n",
      "A KR---B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: B4-A5\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BB--BB\n",
      "D -R-B-B\n",
      "C -R--B-\n",
      "B R-RB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 26\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F3-E3\n",
      "  012345\n",
      "F ----BQ\n",
      "E BB-BBB\n",
      "D -R-B-B\n",
      "C -R--B-\n",
      "B R-RB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: B0-B1\n",
      "  012345\n",
      "F ----BQ\n",
      "E BB-BBB\n",
      "D -R-B-B\n",
      "C -R--B-\n",
      "B -RRB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 28\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E0-D0\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-BBB\n",
      "D BR-B-B\n",
      "C -R--B-\n",
      "B -RRB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-BBB\n",
      "D BRRB-B\n",
      "C ----B-\n",
      "B -RRB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 30\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D0-C0\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-BBB\n",
      "D -RRB-B\n",
      "C B---B-\n",
      "B -RRB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E3\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-RBB\n",
      "D -R-B-B\n",
      "C B---B-\n",
      "B -RRB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 32\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-E3\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-BBB\n",
      "D -R---B\n",
      "C B---B-\n",
      "B -RRB--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-BBB\n",
      "D -R---B\n",
      "C B--RB-\n",
      "B -R-B--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 34\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-B-B\n",
      "D -R--BB\n",
      "C B--RB-\n",
      "B -R-B--\n",
      "A KR---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: A0-A1\n",
      "  012345\n",
      "F ----BQ\n",
      "E -B-B-B\n",
      "D -R--BB\n",
      "C B--RB-\n",
      "B -R-B--\n",
      "A RK---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 36\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F -----Q\n",
      "E -B-BBB\n",
      "D -R--BB\n",
      "C B--RB-\n",
      "B -R-B--\n",
      "A RK---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 37\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C0\n",
      "  012345\n",
      "F -----Q\n",
      "E -B-BBB\n",
      "D -R--BB\n",
      "C R--RB-\n",
      "B ---B--\n",
      "A RK---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 38\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F -----Q\n",
      "E -B--BB\n",
      "D -R-BBB\n",
      "C R--RB-\n",
      "B ---B--\n",
      "A RK---R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,1)\n",
      "\n",
      "Move 39\n",
      "Player: Random (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F -----Q\n",
      "E -B--BB\n",
      "D -R-BBB\n",
      "C R--RB-\n",
      "B ---B--\n",
      "A R-K--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 40\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F -----Q\n",
      "E -B-B-B\n",
      "D -R-BBB\n",
      "C R--RB-\n",
      "B ---B--\n",
      "A R-K--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,2)\n",
      "\n",
      "Move 41\n",
      "Player: Random (RED)\n",
      "Selected move: A2-A3\n",
      "  012345\n",
      "F -----Q\n",
      "E -B-B-B\n",
      "D -R-BBB\n",
      "C R--RB-\n",
      "B ---B--\n",
      "A R--K-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 42\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F5-E5\n",
      "  012345\n",
      "F -----B\n",
      "E -B-B-Q\n",
      "D -R-BBB\n",
      "C R--RB-\n",
      "B ---B--\n",
      "A R--K-R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 43\n",
      "Player: Random (RED)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F -----B\n",
      "E -B-B-Q\n",
      "D -R-BBB\n",
      "C R---B-\n",
      "B ---R--\n",
      "A R--K-R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 44\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -----B\n",
      "E -B-B-Q\n",
      "D -R-BBB\n",
      "C R-----\n",
      "B ---B--\n",
      "A R--K-R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 45\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E2\n",
      "  012345\n",
      "F -----B\n",
      "E -BRB-Q\n",
      "D ---BBB\n",
      "C R-----\n",
      "B ---B--\n",
      "A R--K-R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 46\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F -----B\n",
      "E -BRB-Q\n",
      "D ---B-B\n",
      "C R---B-\n",
      "B ---B--\n",
      "A R--K-R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 47\n",
      "Player: Random (RED)\n",
      "Selected move: E2-F3\n",
      "  012345\n",
      "F ---R-B\n",
      "E -B-B-Q\n",
      "D ---B-B\n",
      "C R---B-\n",
      "B ---B--\n",
      "A R--K-R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 48\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D3-C2\n",
      "  012345\n",
      "F ---R-B\n",
      "E -B-B-Q\n",
      "D -----B\n",
      "C R-B-B-\n",
      "B ---B--\n",
      "A R--K-R\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 49\n",
      "Player: Random (RED)\n",
      "Selected move: A5-B5\n",
      "  012345\n",
      "F ---R-B\n",
      "E -B-B-Q\n",
      "D -----B\n",
      "C R-B-B-\n",
      "B ---B-R\n",
      "A R--K--\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Move 50\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C2-C1\n",
      "  012345\n",
      "F ---R-B\n",
      "E -B-B-Q\n",
      "D -----B\n",
      "C RB--B-\n",
      "B ---B-R\n",
      "A R--K--\n",
      "BLUE KING Position: (4,5)\n",
      "RED KING Position: (0,3)\n",
      "\n",
      "Episode 3/5\n",
      "Policy Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRRR-B\n",
      "B RR-B-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: C3-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B RR-R-B\n",
      "A KRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B RR-R--\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: D0-E1\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RRBBBB\n",
      "D -R-BBB\n",
      "C RRR--B\n",
      "B RR-R--\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E RRBBBB\n",
      "D -R-BBB\n",
      "C RRR---\n",
      "B RR-RB-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: E0-F0\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -RBBBB\n",
      "D -R-BBB\n",
      "C RRR---\n",
      "B RR-RB-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: E2-E1\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D -R-BBB\n",
      "C RRR---\n",
      "B RR-RB-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: B3-C3\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D -R-BBB\n",
      "C RRRR--\n",
      "B RR--B-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D -R-B-B\n",
      "C RRRRB-\n",
      "B RR--B-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D -RRB-B\n",
      "C R-RRB-\n",
      "B RR--B-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D -RRB-B\n",
      "C R-RR--\n",
      "B RR-BB-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: C0-D0\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C --RR--\n",
      "B RR-BB-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C --BR--\n",
      "B RR--B-\n",
      "A KRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C --BR--\n",
      "B RRR-B-\n",
      "A KR-RRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C ---B--\n",
      "B RRR-B-\n",
      "A KR-RRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C ---B--\n",
      "B RRR-B-\n",
      "A K-RRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C3-C2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C --B---\n",
      "B RRR-B-\n",
      "A K-RRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: A2-B3\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C --B---\n",
      "B RRRRB-\n",
      "A K--RRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C2-C1\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C -B----\n",
      "B RRRRB-\n",
      "A K--RRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C -B----\n",
      "B RRRRB-\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C1-B2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C ------\n",
      "B RRBRB-\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: B1-B2\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB-B\n",
      "C ------\n",
      "B R-RRB-\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D5-C4\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB--\n",
      "C ----B-\n",
      "B R-RRB-\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 25\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B1\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB--\n",
      "C ----B-\n",
      "B RKRRB-\n",
      "A ---R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 26\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -B-BBB\n",
      "D RRRB--\n",
      "C ------\n",
      "B RKRBB-\n",
      "A ---R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 27\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E1\n",
      "  012345\n",
      "F RBBBBQ\n",
      "E -R-BBB\n",
      "D RR-B--\n",
      "C ------\n",
      "B RKRBB-\n",
      "A ---R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 28\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-E0\n",
      "  012345\n",
      "F R-BBBQ\n",
      "E BR-BBB\n",
      "D RR-B--\n",
      "C ------\n",
      "B RKRBB-\n",
      "A ---R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 29\n",
      "Player: Random (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F R-BBBQ\n",
      "E BR-BBB\n",
      "D RR-B--\n",
      "C ---R--\n",
      "B RK-BB-\n",
      "A ---R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 30\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B4-A5\n",
      "  012345\n",
      "F R-BBBQ\n",
      "E BR-BBB\n",
      "D RR-B--\n",
      "C ---R--\n",
      "B RK-B--\n",
      "A ---R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 31\n",
      "Player: Random (RED)\n",
      "Selected move: F0-F1\n",
      "  012345\n",
      "F -RBBBQ\n",
      "E BR-BBB\n",
      "D RR-B--\n",
      "C ---R--\n",
      "B RK-B--\n",
      "A ---R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 32\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F2-F1\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E BR-BBB\n",
      "D RR-B--\n",
      "C ---R--\n",
      "B RK-B--\n",
      "A ---R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 33\n",
      "Player: Random (RED)\n",
      "Selected move: D1-D2\n",
      "  012345\n",
      "F -B-BBQ\n",
      "E BR-BBB\n",
      "D R-RB--\n",
      "C ---R--\n",
      "B RK-B--\n",
      "A ---R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 34\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-E1\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BB-BBB\n",
      "D R-RB--\n",
      "C ---R--\n",
      "B RK-B--\n",
      "A ---R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,1)\n",
      "\n",
      "Move 35\n",
      "Player: Random (RED)\n",
      "Selected move: B1-C2\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BB-BBB\n",
      "D R-RB--\n",
      "C --KR--\n",
      "B R--B--\n",
      "A ---R-B\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 36\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F ---BBQ\n",
      "E BB-BBB\n",
      "D R-RB--\n",
      "C --BR--\n",
      "B R-----\n",
      "A ---R-B\n",
      "BLUE KING Position: (5,5)\n",
      "\n",
      "\n",
      "Game Over! Winner: policy_network\n",
      "\n",
      "Episode 4/5\n",
      "Policy Network plays second (BLUE)\n",
      "Random agent plays first (RED)\n",
      "\n",
      "Move 1\n",
      "Player: Random (RED)\n",
      "Selected move: A0-B0\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B KRRR-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 2\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR--B\n",
      "B KRRB-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 3\n",
      "Player: Random (RED)\n",
      "Selected move: C1-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C R-R--B\n",
      "B KRRB-B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 4\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRRBBB\n",
      "C R-B--B\n",
      "B KRR--B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 5\n",
      "Player: Random (RED)\n",
      "Selected move: D2-E3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BRBB\n",
      "D RR-BBB\n",
      "C R-B--B\n",
      "B KRR--B\n",
      "A RRRRR-\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 6\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B5-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BRBB\n",
      "D RR-BBB\n",
      "C R-B--B\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 7\n",
      "Player: Random (RED)\n",
      "Selected move: E3-F4\n",
      "  012345\n",
      "F -BBBRQ\n",
      "E R-B-BB\n",
      "D RR-BBB\n",
      "C R-B--B\n",
      "B KRR---\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 8\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F -BBBRQ\n",
      "E R-B-BB\n",
      "D RR-BBB\n",
      "C R-B---\n",
      "B KRR-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 9\n",
      "Player: Random (RED)\n",
      "Selected move: D1-E1\n",
      "  012345\n",
      "F -BBBRQ\n",
      "E RRB-BB\n",
      "D R--BBB\n",
      "C R-B---\n",
      "B KRR-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 10\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F3-F4\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E RRB-BB\n",
      "D R--BBB\n",
      "C R-B---\n",
      "B KRR-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 11\n",
      "Player: Random (RED)\n",
      "Selected move: D0-D1\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E RRB-BB\n",
      "D -R-BBB\n",
      "C R-B---\n",
      "B KRR-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 12\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C2-C1\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E RRB-BB\n",
      "D -R-BBB\n",
      "C RB----\n",
      "B KRR-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 13\n",
      "Player: Random (RED)\n",
      "Selected move: E1-E2\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E R-R-BB\n",
      "D -R-BBB\n",
      "C RB----\n",
      "B KRR-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 14\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C1-B2\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E R-R-BB\n",
      "D -R-BBB\n",
      "C R-----\n",
      "B KRB-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (1,0)\n",
      "\n",
      "Move 15\n",
      "Player: Random (RED)\n",
      "Selected move: B0-C1\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E R-R-BB\n",
      "D -R-BBB\n",
      "C RK----\n",
      "B -RB-B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 16\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B2-B1\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E R-R-BB\n",
      "D -R-BBB\n",
      "C RK----\n",
      "B -B--B-\n",
      "A RRRRRB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 17\n",
      "Player: Random (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F -BB-BQ\n",
      "E R-R-BB\n",
      "D -R-BBB\n",
      "C RK----\n",
      "B -B--R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 18\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: F1-E2\n",
      "  012345\n",
      "F --B-BQ\n",
      "E R-B-BB\n",
      "D -R-BBB\n",
      "C RK----\n",
      "B -B--R-\n",
      "A RRR-RB\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 19\n",
      "Player: Random (RED)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F --B-BQ\n",
      "E R-B-BB\n",
      "D -R-BBB\n",
      "C RK----\n",
      "B -B--R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 20\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: D4-C4\n",
      "  012345\n",
      "F --B-BQ\n",
      "E R-B-BB\n",
      "D -R-B-B\n",
      "C RK--B-\n",
      "B -B--R-\n",
      "A RRR--R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 21\n",
      "Player: Random (RED)\n",
      "Selected move: A2-A3\n",
      "  012345\n",
      "F --B-BQ\n",
      "E R-B-BB\n",
      "D -R-B-B\n",
      "C RK--B-\n",
      "B -B--R-\n",
      "A RR-R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 22\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F --B-BQ\n",
      "E R-B-BB\n",
      "D -R-B-B\n",
      "C RK----\n",
      "B -B-BR-\n",
      "A RR-R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,1)\n",
      "\n",
      "Move 23\n",
      "Player: Random (RED)\n",
      "Selected move: C1-C2\n",
      "  012345\n",
      "F --B-BQ\n",
      "E R-B-BB\n",
      "D -R-B-B\n",
      "C R-K---\n",
      "B -B-BR-\n",
      "A RR-R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (2,2)\n",
      "\n",
      "Move 24\n",
      "Player: Policy Network (BLUE)\n",
      "Selected move: B3-C2\n",
      "  012345\n",
      "F --B-BQ\n",
      "E R-B-BB\n",
      "D -R-B-B\n",
      "C R-B---\n",
      "B -B--R-\n",
      "A RR-R-R\n",
      "BLUE KING Position: (5,5)\n",
      "\n",
      "\n",
      "Game Over! Winner: policy_network\n",
      "\n",
      "Episode 5/5\n",
      "Policy Network plays first (RED)\n",
      "Random agent plays second (BLUE)\n",
      "\n",
      "Move 1\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A4-A5\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RR-BBB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 2\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-D2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRB-BB\n",
      "C RRR-BB\n",
      "B RRRR-B\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 3\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B2-C3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-BBBB\n",
      "D RRB-BB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 4\n",
      "Player: Random (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-B-BB\n",
      "D RRBBBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A KRRR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 5\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-B-BB\n",
      "D RRBBBB\n",
      "C RRRRBB\n",
      "B RRRR-B\n",
      "A KR-R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 6\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-B-BB\n",
      "D RRBB-B\n",
      "C RRRBBB\n",
      "B RRRR-B\n",
      "A KR-R-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 7\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A1-A2\n",
      "  012345\n",
      "F -BBBBQ\n",
      "E R-B-BB\n",
      "D RRBB-B\n",
      "C RRRBBB\n",
      "B RRRR-B\n",
      "A K-RR-R\n",
      "BLUE KING Position: (5,5)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 8\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-F4\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-B-BB\n",
      "D RRBB-B\n",
      "C RRRBBB\n",
      "B RRRR-B\n",
      "A K-RR-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 9\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-B-BB\n",
      "D RRBB-B\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A K-RR-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 10\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-E3\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-BB-B\n",
      "D RRBB-B\n",
      "C RR-RBB\n",
      "B RRRR-B\n",
      "A K-RR-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 11\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B2-C2\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-BB-B\n",
      "D RRBB-B\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A K-RR-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 12\n",
      "Player: Random (BLUE)\n",
      "Selected move: E5-D4\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-BB--\n",
      "D RRBBBB\n",
      "C RRRRBB\n",
      "B RR-R-B\n",
      "A K-RR-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 13\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A2-B2\n",
      "  012345\n",
      "F -BBBQB\n",
      "E R-BB--\n",
      "D RRBBBB\n",
      "C RRRRBB\n",
      "B RRRR-B\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 14\n",
      "Player: Random (BLUE)\n",
      "Selected move: F1-E0\n",
      "  012345\n",
      "F --BBQB\n",
      "E B-BB--\n",
      "D RRBBBB\n",
      "C RRRRBB\n",
      "B RRRR-B\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 15\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D1-E0\n",
      "  012345\n",
      "F --BBQB\n",
      "E R-BB--\n",
      "D R-BBBB\n",
      "C RRRRBB\n",
      "B RRRR-B\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 16\n",
      "Player: Random (BLUE)\n",
      "Selected move: D4-C3\n",
      "  012345\n",
      "F --BBQB\n",
      "E R-BB--\n",
      "D R-BB-B\n",
      "C RRRBBB\n",
      "B RRRR-B\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 17\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F --BBQB\n",
      "E R-BB--\n",
      "D RRBB-B\n",
      "C R-RBBB\n",
      "B RRRR-B\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 18\n",
      "Player: Random (BLUE)\n",
      "Selected move: B5-A4\n",
      "  012345\n",
      "F --BBQB\n",
      "E R-BB--\n",
      "D RRBB-B\n",
      "C R-RBBB\n",
      "B RRRR--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 19\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C0-C1\n",
      "  012345\n",
      "F --BBQB\n",
      "E R-BB--\n",
      "D RRBB-B\n",
      "C -RRBBB\n",
      "B RRRR--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 20\n",
      "Player: Random (BLUE)\n",
      "Selected move: E2-D1\n",
      "  012345\n",
      "F --BBQB\n",
      "E R--B--\n",
      "D RBBB-B\n",
      "C -RRBBB\n",
      "B RRRR--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 21\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C2-C3\n",
      "  012345\n",
      "F --BBQB\n",
      "E R--B--\n",
      "D RBBB-B\n",
      "C -R-RBB\n",
      "B RRRR--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,4)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 22\n",
      "Player: Random (BLUE)\n",
      "Selected move: F4-F3\n",
      "  012345\n",
      "F --BQBB\n",
      "E R--B--\n",
      "D RBBB-B\n",
      "C -R-RBB\n",
      "B RRRR--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 23\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B2-C2\n",
      "  012345\n",
      "F --BQBB\n",
      "E R--B--\n",
      "D RBBB-B\n",
      "C -RRRBB\n",
      "B RR-R--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 24\n",
      "Player: Random (BLUE)\n",
      "Selected move: C4-B3\n",
      "  012345\n",
      "F --BQBB\n",
      "E R--B--\n",
      "D RBBB-B\n",
      "C -RRR-B\n",
      "B RR-B--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 25\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C1-D1\n",
      "  012345\n",
      "F --BQBB\n",
      "E R--B--\n",
      "D RRBB-B\n",
      "C --RR-B\n",
      "B RR-B--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 26\n",
      "Player: Random (BLUE)\n",
      "Selected move: F4-E4\n",
      "  012345\n",
      "F --BQ-B\n",
      "E R--BB-\n",
      "D RRBB-B\n",
      "C --RR-B\n",
      "B RR-B--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 27\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C2-B3\n",
      "  012345\n",
      "F --BQ-B\n",
      "E R--BB-\n",
      "D RRBB-B\n",
      "C ---R-B\n",
      "B RR-R--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 28\n",
      "Player: Random (BLUE)\n",
      "Selected move: F2-E1\n",
      "  012345\n",
      "F ---Q-B\n",
      "E RB-BB-\n",
      "D RRBB-B\n",
      "C ---R-B\n",
      "B RR-R--\n",
      "A K--RBR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 29\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B3-A4\n",
      "  012345\n",
      "F ---Q-B\n",
      "E RB-BB-\n",
      "D RRBB-B\n",
      "C ---R-B\n",
      "B RR----\n",
      "A K--RRR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 30\n",
      "Player: Random (BLUE)\n",
      "Selected move: E4-D4\n",
      "  012345\n",
      "F ---Q-B\n",
      "E RB-B--\n",
      "D RRBBBB\n",
      "C ---R-B\n",
      "B RR----\n",
      "A K--RRR\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 31\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A4-B5\n",
      "  012345\n",
      "F ---Q-B\n",
      "E RB-B--\n",
      "D RRBBBB\n",
      "C ---R-B\n",
      "B RR---R\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 32\n",
      "Player: Random (BLUE)\n",
      "Selected move: E1-D0\n",
      "  012345\n",
      "F ---Q-B\n",
      "E R--B--\n",
      "D BRBBBB\n",
      "C ---R-B\n",
      "B RR---R\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 33\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D1-D0\n",
      "  012345\n",
      "F ---Q-B\n",
      "E R--B--\n",
      "D R-BBBB\n",
      "C ---R-B\n",
      "B RR---R\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 34\n",
      "Player: Random (BLUE)\n",
      "Selected move: D2-D1\n",
      "  012345\n",
      "F ---Q-B\n",
      "E R--B--\n",
      "D RB-BBB\n",
      "C ---R-B\n",
      "B RR---R\n",
      "A K--R-R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 35\n",
      "Player: Policy Network (RED)\n",
      "Selected move: A3-B4\n",
      "  012345\n",
      "F ---Q-B\n",
      "E R--B--\n",
      "D RB-BBB\n",
      "C ---R-B\n",
      "B RR--RR\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 36\n",
      "Player: Random (BLUE)\n",
      "Selected move: F5-E5\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--B-B\n",
      "D RB-BBB\n",
      "C ---R-B\n",
      "B RR--RR\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 37\n",
      "Player: Policy Network (RED)\n",
      "Selected move: C3-D4\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--B-B\n",
      "D RB-BRB\n",
      "C -----B\n",
      "B RR--RR\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 38\n",
      "Player: Random (BLUE)\n",
      "Selected move: E5-E4\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--BB-\n",
      "D RB-BRB\n",
      "C -----B\n",
      "B RR--RR\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 39\n",
      "Player: Policy Network (RED)\n",
      "Selected move: D4-E4\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--BR-\n",
      "D RB-B-B\n",
      "C -----B\n",
      "B RR--RR\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 40\n",
      "Player: Random (BLUE)\n",
      "Selected move: C5-B4\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--BR-\n",
      "D RB-B-B\n",
      "C ------\n",
      "B RR--BR\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 41\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B5-B4\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--BR-\n",
      "D RB-B-B\n",
      "C ------\n",
      "B RR--R-\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 42\n",
      "Player: Random (BLUE)\n",
      "Selected move: D3-C2\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--BR-\n",
      "D RB---B\n",
      "C --B---\n",
      "B RR--R-\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 43\n",
      "Player: Policy Network (RED)\n",
      "Selected move: B4-B5\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--BR-\n",
      "D RB---B\n",
      "C --B---\n",
      "B RR---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 44\n",
      "Player: Random (BLUE)\n",
      "Selected move: D1-D0\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--BR-\n",
      "D B----B\n",
      "C --B---\n",
      "B RR---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 45\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E4-E5\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--B-R\n",
      "D B----B\n",
      "C --B---\n",
      "B RR---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 46\n",
      "Player: Random (BLUE)\n",
      "Selected move: C2-C1\n",
      "  012345\n",
      "F ---Q--\n",
      "E R--B-R\n",
      "D B----B\n",
      "C -B----\n",
      "B RR---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 47\n",
      "Player: Policy Network (RED)\n",
      "Selected move: E0-F0\n",
      "  012345\n",
      "F R--Q--\n",
      "E ---B-R\n",
      "D B----B\n",
      "C -B----\n",
      "B RR---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 48\n",
      "Player: Random (BLUE)\n",
      "Selected move: C1-B1\n",
      "  012345\n",
      "F R--Q--\n",
      "E ---B-R\n",
      "D B----B\n",
      "C ------\n",
      "B RB---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 49\n",
      "Player: Policy Network (RED)\n",
      "Selected move: F0-F1\n",
      "  012345\n",
      "F -R-Q--\n",
      "E ---B-R\n",
      "D B----B\n",
      "C ------\n",
      "B RB---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Move 50\n",
      "Player: Random (BLUE)\n",
      "Selected move: E3-D3\n",
      "  012345\n",
      "F -R-Q--\n",
      "E -----R\n",
      "D B--B-B\n",
      "C ------\n",
      "B RB---R\n",
      "A K----R\n",
      "BLUE KING Position: (5,3)\n",
      "RED KING Position: (0,0)\n",
      "\n",
      "Test Results Summary:\n",
      "Episodes: 5\n",
      "Policy Network wins: 2 (40.0%)\n",
      "Random agent wins: 0 (0.0%)\n",
      "Ties: 0 (0.0%)\n",
      "Average steps per episode: 42.0\n",
      "Connection to Java server closed\n"
     ]
    }
   ],
   "source": [
    "results = test_functions.test_policy_network_vs_random(env_port=3, num_episodes=5, policy_network=reinforce_policy_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0uSrREaYSv1"
   },
   "source": [
    "### Testing the agent against our Java ID Alpha Beta agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEva11BxYSv1"
   },
   "outputs": [],
   "source": [
    "reinforce_policy_nn = torch.load(\n",
    "    MODELS_DIR / \"reinforce_policy_network.pth\",\n",
    "    map_location=device,\n",
    "    weights_only=False  # Only do this if you trust the source of this file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_functions.test_policy_network_vs_alpha_beta(env_port=3, num_episodes=1,\n",
    "                                                           policy_network=reinforce_policy_nn, agent_port=3,\n",
    "                                                           max_steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = test_functions.test_policy_network_vs_alpha_beta(env_port=3, num_episodes=1,\n",
    "#                                                           policy_network=reinforce_policy_nn, agent_port=3, max_steps=300, first_player_policy_network=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqtx_9wYYSv1"
   },
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3foCmBwYSv1"
   },
   "outputs": [],
   "source": [
    "train_score_reinforce = reinforce_trains_result_df[[\"num_episodes\", \"mean_final_episode_reward\"]].groupby(\n",
    "    \"num_episodes\").mean().max()\n",
    "train_score_reinforce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZ7ZNbatYSv1"
   },
   "source": [
    "## 4. Gradient-Free Optimization - CEM / ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUG_9t8vYSv1"
   },
   "source": [
    "### 4.1 Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rO0HlLMYSv1"
   },
   "source": [
    "In Reinforcement Learning, by convention the score is a reward to maximize whereas in mathematical optimization the score is a cost to minimize; the objective function will therefore return the opposite of the reward as the score of evaluated policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectiveFunction:\n",
    "    \"\"\"\n",
    "    Objective function for evaluating a policy in a given environment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : gym.Env\n",
    "        The environment in which to evaluate the policy.\n",
    "    policy : torch.nn.Module\n",
    "        The policy to evaluate.\n",
    "    adversary_policy : torch.nn.Module\n",
    "        The adversary policy.\n",
    "    num_episodes : int, optional\n",
    "        The number of episodes to run for each evaluation, by default 1.\n",
    "    max_time_steps : float, optional\n",
    "        The maximum number of time steps per episode, by default float(\"inf\").\n",
    "    minimization_solver : bool, optional\n",
    "        Whether the solver is a minimization solver, by default True.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    env : gym.Env\n",
    "        The environment in which to evaluate the policy.\n",
    "    policy : torch.nn.Module\n",
    "        The policy to evaluate.\n",
    "    num_episodes : int\n",
    "        The number of episodes to run for each evaluation.\n",
    "    max_time_steps : float\n",
    "        The maximum number of time steps per episode.\n",
    "    minimization_solver : bool\n",
    "        Whether the solver is a minimization solver.\n",
    "    num_evals : int\n",
    "        The number of evaluations performed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            env: gym.Env,\n",
    "            policy: torch.nn.Module,\n",
    "            adversary_policy: torch.nn.Module,\n",
    "            num_episodes: int = 1,\n",
    "            max_time_steps: float = float(\"inf\"),\n",
    "            minimization_solver: bool = True,\n",
    "            heuristic_scale: float = 0.2\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.policy = policy\n",
    "        self.adversary_policy = adversary_policy\n",
    "        self.num_episodes = num_episodes\n",
    "        self.max_time_steps = max_time_steps\n",
    "        self.minimization_solver = minimization_solver\n",
    "        self.heuristic_scale = heuristic_scale\n",
    "\n",
    "        self.num_evals = 0\n",
    "\n",
    "    def eval(self, env, policy_params: np.ndarray, num_episodes: Optional[int] = None,\n",
    "             max_time_steps: Optional[float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate a policy.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        policy_params : np.ndarray\n",
    "            The parameters of the policy to evaluate.\n",
    "        num_episodes : int, optional\n",
    "            The number of episodes to run for each evaluation, by default None.\n",
    "        max_time_steps : float, optional\n",
    "            The maximum number of time steps per episode, by default None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The average total rewards over the evaluation episodes.\n",
    "        \"\"\"\n",
    "        self.policy.set_params(policy_params)\n",
    "\n",
    "        self.num_evals += 1\n",
    "\n",
    "        if num_episodes is None:\n",
    "            num_episodes = self.num_episodes\n",
    "\n",
    "        if max_time_steps is None:\n",
    "            max_time_steps = self.max_time_steps\n",
    "\n",
    "        average_return = avg_return_on_multiple_episodes(env=env, policy_nn=self.policy,\n",
    "                                                         policy_nn_adversary=self.policy, num_test_episode=num_episodes,\n",
    "                                                         verbose=False, max_episode_duration=max_time_steps,\n",
    "                                                         heuristic_scale=self.heuristic_scale)\n",
    "\n",
    "        # print(average_return)\n",
    "\n",
    "        if self.minimization_solver:\n",
    "            average_return *= -1.0\n",
    "\n",
    "        return average_return  # Optimizers do minimization by default...\n",
    "\n",
    "    def __call__(self, env, policy_params: np.ndarray, num_episodes: Optional[int] = None,\n",
    "                 max_time_steps: Optional[float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate a policy.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        env: KingAndCourtesanEnv\n",
    "            The environment in which to evaluate the policy.\n",
    "        policy_params : np.ndarray\n",
    "            The parameters of the policy to evaluate.\n",
    "        num_episodes : int, optional\n",
    "            The number of episodes to run for each evaluation, by default None.\n",
    "        max_time_steps : float, optional\n",
    "            The maximum number of time steps per episode, by default None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The average total rewards over the evaluation episodes.\n",
    "        \"\"\"\n",
    "        return self.eval(env, policy_params, num_episodes=self.num_episodes, max_time_steps=self.max_time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQMH1gw8YSv1"
   },
   "source": [
    "## 4.2 CEM optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4IUsgXEYSv1"
   },
   "source": [
    "`cem_uncorrelated` function searches the best $\\theta$ parameters with a Cross Entropy Method, using the objective function defined above.\n",
    "$\\mathbb{P}$ can be defined as an multivariate normal distribution $\\mathcal{N}\\left( \\boldsymbol{\\mu}, \\boldsymbol{\\sigma^2} \\boldsymbol{\\Sigma} \\right)$ where $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\sigma^2} \\boldsymbol{\\Sigma}$ are vectors i.e. we use one mean and one variance parameters per dimension of $\\boldsymbol{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sRKJYodYSv1"
   },
   "source": [
    "**Cross Entropy**\n",
    "\n",
    "**Input**:<br>\n",
    "$\\quad\\quad$ $f$: the objective function<br>\n",
    "$\\quad\\quad$ $\\mathbb{P}$: family of distribution<br>\n",
    "$\\quad\\quad$ $\\boldsymbol{\\theta}$: initial parameters for the proposal distribution $\\mathbb{P}$<br>\n",
    "\n",
    "**Algorithm parameter**:<br>\n",
    "$\\quad\\quad$ $m$: sample size<br>\n",
    "$\\quad\\quad$ $m_{\\text{elite}}$: number of samples to use to fit $\\boldsymbol{\\theta}$<br>\n",
    "\n",
    "**FOR EACH** iteration<br>\n",
    "$\\quad\\quad$ samples $\\leftarrow \\{ \\boldsymbol{x}_1, \\dots, \\boldsymbol{x}_m \\}$ with $\\boldsymbol{x}_i \\sim \\mathbb{P}(\\boldsymbol{\\theta}) ~~ \\forall i \\in 1\\dots m$<br>\n",
    "$\\quad\\quad$ elite $\\leftarrow $ { $m_{\\text{elite}}$ best samples } $\\quad$ (i.e. select best samples according to $f$)<br>\n",
    "$\\quad\\quad$ $\\boldsymbol{\\theta} \\leftarrow $ fit $\\mathbb{P}(\\boldsymbol{\\theta})$ to the elite samples<br>\n",
    "\n",
    "**RETURN** $\\boldsymbol{\\theta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742285508784,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "O-D3naLi8U7_"
   },
   "outputs": [],
   "source": [
    "def cem_uncorrelated(\n",
    "        env,\n",
    "        objective_function: Callable[[np.ndarray], float],\n",
    "        mean_array: np.ndarray,\n",
    "        var_array: np.ndarray,\n",
    "        max_iterations: int = 500,\n",
    "        sample_size: int = 50,\n",
    "        elite_frac: float = 0.2,\n",
    "        print_every: int = 10,\n",
    "        success_score: float = float(\"inf\"),\n",
    "        num_evals_for_stop: Optional[int] = None,\n",
    "        hist_dict: Optional[dict] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cross-entropy method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    objective_function : Callable[[np.ndarray], float]\n",
    "        The function to maximize.\n",
    "    mean_array : np.ndarray\n",
    "        The initial proposal distribution (mean vector).\n",
    "    var_array : np.ndarray\n",
    "        The initial proposal distribution (variance vector).\n",
    "    max_iterations : int, optional\n",
    "        Number of training iterations, by default 500.\n",
    "    sample_size : int, optional\n",
    "        Size of population at each iteration, by default 50.\n",
    "    elite_frac : float, optional\n",
    "        Rate of top performers to use in update with elite_frac ∈ ]0;1], by default 0.2.\n",
    "    print_every : int, optional\n",
    "        How often to print average score, by default 10.\n",
    "    success_score : float, optional\n",
    "        The score at which to stop the optimization, by default float(\"inf\").\n",
    "    num_evals_for_stop : Optional[int], optional\n",
    "        Number of evaluations for stopping criteria, by default None.\n",
    "    hist_dict : Optional[dict], optional\n",
    "        Dictionary to log the history, by default None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The optimized mean vector.\n",
    "    \"\"\"\n",
    "    assert 0.0 < elite_frac <= 1.0\n",
    "\n",
    "    n_elite = math.ceil(sample_size * elite_frac)\n",
    "\n",
    "    for iteration_index in range(0, max_iterations):\n",
    "\n",
    "        # SAMPLE A NEW POPULATION OF SOLUTIONS (X VECTORS) ####################\n",
    "\n",
    "        x_array = np.random.normal(mean_array, np.sqrt(var_array), size=(sample_size, len(mean_array)))\n",
    "\n",
    "        # EVALUATE SAMPLES AND EXTRACT THE BEST ONES (\"ELITE\") ################\n",
    "\n",
    "        score_array = np.array([objective_function(env, x) for x in x_array])\n",
    "\n",
    "        sorted_indices_array = np.argsort(\n",
    "            score_array)\n",
    "        elite_indices_array = sorted_indices_array[\n",
    "                              :n_elite]\n",
    "\n",
    "        elite_x_array = x_array[elite_indices_array]\n",
    "\n",
    "        # FIT THE NORMAL DISTRIBUTION ON THE ELITE POPULATION #################\n",
    "\n",
    "        mean_array = np.mean(elite_x_array, axis=0)\n",
    "        var_array = np.var(elite_x_array, axis=0)\n",
    "        score = np.min(score_array)\n",
    "\n",
    "        # PRINT STATUS ########################################################\n",
    "\n",
    "        if iteration_index % print_every == 0:\n",
    "            print(\"Iteration {}\\tScore {}\".format(iteration_index, score))\n",
    "\n",
    "        if hist_dict is not None:\n",
    "            hist_dict[iteration_index] = [score] + mean_array.tolist() + var_array.tolist()\n",
    "\n",
    "        # STOPPING CRITERIA ####################################################\n",
    "\n",
    "        if num_evals_for_stop is not None:\n",
    "            score = objective_function(mean_array)\n",
    "\n",
    "        # `num_evals_for_stop = None` may be used to fasten computations but it introduces bias...\n",
    "        if score <= success_score:\n",
    "            break\n",
    "\n",
    "    return mean_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1eT9sWAYSv2"
   },
   "source": [
    "### Training the agents (DQN v2 and REINFORCE) with CEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc-pUlvsYSv2"
   },
   "source": [
    "### DQN v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742281179085,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "sWBWVw0QB1OW",
    "outputId": "ac5f3a67-5a71-4f75-8b07-0c6b89de938a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Java server at localhost:3\n"
     ]
    }
   ],
   "source": [
    "port = 3\n",
    "render_mode = 'human'\n",
    "env = kac.KingAndCourtesanEnv(port=port, render_mode=render_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMBokQtO8U7_"
   },
   "outputs": [],
   "source": [
    "dqnv2_cem = QNetwork(env.observation_space.shape[0])\n",
    "#dqnv2_cem_adversary = QNetwork(env.observation_space.shape[0])\n",
    "\n",
    "objective_function = ObjectiveFunction(\n",
    "    env=env, policy=dqnv2_cem, adversaty_policy=dqnv2_cem, num_episodes=10, max_time_steps=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = len(dqnv2_cem.get_params())\n",
    "init_mean_array = np.zeros(num_params)\n",
    "init_var_array = np.ones(num_params) * 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist_dict = {}\n",
    "\n",
    "print(f\"Optimizing {num_params} parameters\")\n",
    "\n",
    "#init_mean_array = np.random.random(num_params)\n",
    "#init_var_array = np.ones(num_params) * 100.0\n",
    "\n",
    "optimized_policy_params_dqnv2_cem = cem_uncorrelated(\n",
    "    env,\n",
    "    objective_function=objective_function,\n",
    "    mean_array=init_mean_array,\n",
    "    var_array=init_var_array,\n",
    "    max_iterations=30,\n",
    "    sample_size=50,\n",
    "    elite_frac=0.1,\n",
    "    print_every=1,\n",
    "    success_score=-500,\n",
    "    num_evals_for_stop=None,\n",
    "    hist_dict=hist_dict,\n",
    ")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqnv2_cem.set_params(optimized_policy_params_dqnv2_cem)\n",
    "torch.save(dqnv2_cem.state_dict(), MODELS_DIR / \"dqnv2_cem.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7uSDqqO8U8A"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    hist_dict,\n",
    "    orient=\"index\",\n",
    "    columns=[\"score\", \"mu1\", \"mu2\", \"mu3\", \"mu4\", \"var1\", \"var2\", \"var3\", \"var4\"],\n",
    ")\n",
    "ax = df.score.plot(title=\"Average reward\", figsize=(20, 5))\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.savefig(PLOTS_DIR / \"dqnv2_cem_avg_reward_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQMAsnNS8U8A"
   },
   "outputs": [],
   "source": [
    "ax = df[[\"mu1\", \"mu2\", \"mu3\", \"mu4\"]].plot(\n",
    "    title=\"Theta w.r.t training steps\", figsize=(20, 5)\n",
    ");\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"dqnv2_cem_params_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bpiUKEhYSv2"
   },
   "outputs": [],
   "source": [
    "ax = df[[\"var1\", \"var2\", \"var3\", \"var4\"]].plot(\n",
    "    logy=True, title=\"Variance w.r.t training steps\", figsize=(20, 5)\n",
    ")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"dqnv2_cem_var_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGFHJzgUYSv2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Optimized weights: \", optimized_policy_params_dqnv2_cem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1BUZQpyYSv2"
   },
   "source": [
    "### REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce_policy_nn_cem = PolicyNetwork(env.observation_space.shape[0])\n",
    "reinforce_policy_nn_cem = reinforce_policy_nn_cem.to(device)\n",
    "#reinforce_policy_nn_cem_adversary = PolicyNetwork(env.observation_space.shape[0])\n",
    "objective_function = ObjectiveFunction(\n",
    "    env=env, policy=reinforce_policy_nn_cem, adversary_policy=reinforce_policy_nn_cem, num_episodes=10,\n",
    "    max_time_steps=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist_dict = {}\n",
    "\n",
    "num_params = len(reinforce_policy_nn_cem.get_params())\n",
    "print(f\"Optimizing {num_params} parameters\")\n",
    "\n",
    "optimized_policy_params_reinforce_policy_nn_cem = cem_uncorrelated(\n",
    "    env,\n",
    "    objective_function=objective_function,\n",
    "    mean_array=init_mean_array,\n",
    "    var_array=init_var_array,\n",
    "    max_iterations=15,\n",
    "    sample_size=50,\n",
    "    elite_frac=0.1,\n",
    "    print_every=1,\n",
    "    success_score=-500,\n",
    "    num_evals_for_stop=None,\n",
    "    hist_dict=hist_dict,\n",
    ")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce_policy_nn_cem.set_params(optimized_policy_params_reinforce_policy_nn_cem)\n",
    "torch.save(reinforce_policy_nn_cem.state_dict(), MODELS_DIR / \"reinforce_policy_nn_cem.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing against a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_functions.test_policy_network_vs_random(env_port=3, num_episodes=1,\n",
    "                                             policy_network=reinforce_policy_nn_cem, max_steps=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing against our Java ID Alpha Beta agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cem_reinforce = test_functions.test_policy_network_vs_alpha_beta(env_port=3, num_episodes=1,\n",
    "                                                                         policy_network=reinforce_policy_nn_cem,\n",
    "                                                                         agent_port=3, max_steps=300,\n",
    "                                                                         first_player_policy_network=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    hist_dict,\n",
    "    orient=\"index\",\n",
    "    columns=[\"score\", \"mu1\", \"mu2\", \"mu3\", \"mu4\", \"var1\", \"var2\", \"var3\", \"var4\"],\n",
    ")\n",
    "ax = df.score.plot(title=\"Average reward\", figsize=(20, 5))\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.savefig(PLOTS_DIR / \"reinforce_policy_nn_cem_avg_reward_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[[\"mu1\", \"mu2\", \"mu3\", \"mu4\"]].plot(\n",
    "    title=\"Theta w.r.t training steps\", figsize=(20, 5)\n",
    ");\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"reinforce_policy_nn_cem_params_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[[\"var1\", \"var2\", \"var3\", \"var4\"]].plot(\n",
    "    logy=True, title=\"Variance w.r.t training steps\", figsize=(20, 5)\n",
    ")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"reinforce_policy_nn_cem_var_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized weights: \", optimized_policy_params_reinforce_policy_nn_cem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFzybmTJYSv2"
   },
   "source": [
    "## 4.3 (1+1)-SA-ES optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7zIeXUQYSv3"
   },
   "source": [
    "`saes_1_1` function searchs the best $\\theta$ parameters with a (1+1)-SA-ES algorithm, using the objective function defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWwKxdkfYSv3"
   },
   "source": [
    "**(1+1)-SA-ES**\n",
    "\n",
    "**Input**:<br>\n",
    "$\\quad\\quad$ $f$: the objective function<br>\n",
    "$\\quad\\quad$ $\\boldsymbol{x}$: initial solution<br>\n",
    "\n",
    "**Algorithm parameter**:<br>\n",
    "$\\quad\\quad$ $\\tau$: self-adaptation learning rate<br>\n",
    "\n",
    "**FOR EACH** generation<br>\n",
    "$\\quad\\quad$ 1. mutation of $\\sigma$ (current individual strategy) : $\\sigma' \\leftarrow \\sigma ~ e^{\\tau \\mathcal{N}(0,1)}$<br>\n",
    "$\\quad\\quad$ 2. mutation of $\\boldsymbol{x}$ (current solution) : $\\boldsymbol{x}' \\leftarrow \\boldsymbol{x} + \\sigma' ~ \\mathcal{N}(0,1)$<br>\n",
    "$\\quad\\quad$ 3. eval $f(\\boldsymbol{x}')$<br>\n",
    "$\\quad\\quad$ 4. survivor selection $\\boldsymbol{x} \\leftarrow \\boldsymbol{x}'$ and $\\sigma \\leftarrow \\sigma'$ if $f(\\boldsymbol{x}') \\leq f(\\boldsymbol{x})$<br>\n",
    "\n",
    "**RETURN** $\\boldsymbol{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742286894027,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "SV16-qO9YSv3"
   },
   "outputs": [],
   "source": [
    "def saes_1_1(\n",
    "        env,\n",
    "        objective_function: Callable[[np.ndarray], float],\n",
    "        x_array: np.ndarray,\n",
    "        sigma_array: np.ndarray,\n",
    "        max_iterations: int = 500,\n",
    "        tau: Optional[float] = None,\n",
    "        print_every: int = 10,\n",
    "        success_score: float = float(\"inf\"),\n",
    "        num_evals_for_stop: Optional[int] = None,\n",
    "        hist_dict: Optional[dict] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    (1+1)-Self-Adaptive Evolution Strategy (SA-ES) optimization algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env: KingAndCourtesanEnv\n",
    "        The environment in which to evaluate the policy.\n",
    "    objective_function : Callable[[np.ndarray], float]\n",
    "        The function to minimize.\n",
    "    x_array : np.ndarray\n",
    "        The initial solution vector.\n",
    "    sigma_array : np.ndarray\n",
    "        The initial strategy parameter vector (step sizes).\n",
    "    max_iterations : int, optional\n",
    "        The maximum number of iterations, by default 500.\n",
    "    tau : Optional[float], optional\n",
    "        The self-adaptation learning rate, by default None.\n",
    "    print_every : int, optional\n",
    "        How often to print the current score, by default 10.\n",
    "    success_score : float, optional\n",
    "        The score at which to stop the optimization, by default float(\"inf\").\n",
    "    num_evals_for_stop : Optional[int], optional\n",
    "        Number of evaluations for stopping criteria, by default None.\n",
    "    hist_dict : Optional[dict], optional\n",
    "        Dictionary to log the history, by default None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The optimized solution vector.\n",
    "    \"\"\"\n",
    "    # Number of dimension of the solution space\n",
    "    d = x_array.shape[0]\n",
    "\n",
    "    if tau is None:\n",
    "        # Self-adaptation learning rate\n",
    "        tau = 1.0 / (2.0 * d)\n",
    "\n",
    "    score = objective_function(env, x_array)\n",
    "\n",
    "    for iteration_index in range(0, max_iterations):\n",
    "        # 1. Mutation of sigma (current \"individual strategy\")\n",
    "        new_sigma_array = sigma_array * np.exp(tau * np.random.normal(0, 1, size=d))\n",
    "\n",
    "        # 2. Mutation of x (current solution)\n",
    "        new_x_array = x_array + new_sigma_array * np.random.normal(0, 1, size=d)\n",
    "\n",
    "        # 3. Eval f(x')\n",
    "        new_score = objective_function(env, new_x_array)\n",
    "\n",
    "        # 4. survivor selection (we follow the ES convention and do minimization)\n",
    "        if new_score <= score:  # You may try `new_score < score` for less exploration\n",
    "            score = new_score\n",
    "            x_array = new_x_array.copy()\n",
    "            sigma_array = new_sigma_array.copy()\n",
    "\n",
    "        # PRINT STATUS ########################################################\n",
    "\n",
    "        if iteration_index % print_every == 0:\n",
    "            print(\"Iteration {}\\tScore {}\".format(iteration_index, score))\n",
    "\n",
    "        if hist_dict is not None:\n",
    "            hist_dict[iteration_index] = [score] + x_array.tolist() + sigma_array.tolist()\n",
    "\n",
    "        # STOPPING CRITERIA ####################################################\n",
    "\n",
    "        if num_evals_for_stop is not None:\n",
    "            score = objective_function(env, x_array)\n",
    "\n",
    "        # `num_evals_for_stop = None` may be used to fasten computations but it introduces bias...\n",
    "        if score <= success_score:\n",
    "            break\n",
    "\n",
    "    return x_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWtuvGs3YSv3"
   },
   "source": [
    "### Training the agents (DQN v2 and REINFORCE) with (1+1)-SA-ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ksl14kmrYSv3"
   },
   "source": [
    "### DQN v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gty7lF8KYSv3"
   },
   "outputs": [],
   "source": [
    "dqnv2_saes_1_1 = QNetwork(env.observation_space.shape[0])\n",
    "dqnv2_saes_1_1_adversary = QNetwork(env.observation_space.shape[0])\n",
    "\n",
    "objective_function = ObjectiveFunction(\n",
    "    env=env, policy=dqnv2_saes_1_1, adversary_policy=dqnv2_saes_1_1, num_episodes=10, max_time_steps=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1742286904724,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "4ktyQDZMFWc7"
   },
   "outputs": [],
   "source": [
    "initial_solution_array = np.random.randn(num_params) * np.sqrt(1.0 / num_params)\n",
    "initial_sigma_array = np.ones(num_params) * 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkDZR3GZYSv3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist_dict = {}\n",
    "\n",
    "num_params = len(dqnv2_saes_1_1.get_params())\n",
    "\n",
    "optimized_policy_params_dqnv2_saes_1_1 = saes_1_1(\n",
    "    objective_function=objective_function,\n",
    "    x_array=initial_solution_array,\n",
    "    sigma_array=initial_sigma_array,\n",
    "    tau=0.001,\n",
    "    max_iterations=30,\n",
    "    print_every=1,\n",
    "    success_score=-500,\n",
    "    num_evals_for_stop=None,\n",
    "    hist_dict=hist_dict,\n",
    ")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCYQIlS7B1OY"
   },
   "outputs": [],
   "source": [
    "dqnv2_saes_1_1.set_params(optimized_policy_params_dqnv2_cem)\n",
    "torch.save(dqnv2_saes_1_1.state_dict(), MODELS_DIR / \"dqnv2_saes_1_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH1jvtlZYSv3"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    hist_dict,\n",
    "    orient=\"index\",\n",
    "    columns=[\n",
    "        \"score\",\n",
    "        \"mu1\",\n",
    "        \"mu2\",\n",
    "        \"mu3\",\n",
    "        \"mu4\",\n",
    "        \"sigma1\",\n",
    "        \"sigma2\",\n",
    "        \"sigma3\",\n",
    "        \"sigma4\",\n",
    "    ],\n",
    ")\n",
    "ax = df.score.plot(title=\"Average reward\", figsize=(30, 5))\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.savefig(PLOTS_DIR / \"dqnv2_saes_1_1_avg_reward_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmN1Lee9YSv3"
   },
   "outputs": [],
   "source": [
    "ax = df[[\"mu1\", \"mu2\", \"mu3\", \"mu4\"]].plot(\n",
    "    title=\"Theta w.r.t training steps\", figsize=(30, 5)\n",
    ")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"dqnv2_saes_1_1_params_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCIehZMRYSv3"
   },
   "outputs": [],
   "source": [
    "ax = df[[\"sigma1\", \"sigma2\", \"sigma3\", \"sigma4\"]].plot(\n",
    "    logy=True, title=\"Sigma w.r.t training steps\", figsize=(30, 5)\n",
    ")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"dqnv2_saes_1_1_var_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgKchDVFYSv3"
   },
   "outputs": [],
   "source": [
    "print(\"Optimized weights: \", optimized_policy_params_dqnv2_saes_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxgqbbQ5YSv3"
   },
   "source": [
    "### REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1742286920473,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "M_3YXonSYSv3"
   },
   "outputs": [],
   "source": [
    "reinforce_policy_nn_saes_1_1 = PolicyNetwork(env.observation_space.shape[0])\n",
    "reinforce_policy_nn_saes_1_1 = reinforce_policy_nn_saes_1_1.to(device)\n",
    "reinforce_policy_nn_saes_1_1_adversary = PolicyNetwork(env.observation_space.shape[0])\n",
    "objective_function = ObjectiveFunction(\n",
    "    env=env, policy=reinforce_policy_nn_saes_1_1, adversary_policy=reinforce_policy_nn_saes_1_1,\n",
    "    num_episodes=10, max_time_steps=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73933,
     "status": "ok",
     "timestamp": 1742287035997,
     "user": {
      "displayName": "Arnauld LINVANI",
      "userId": "15767780697894810406"
     },
     "user_tz": -60
    },
    "id": "F2tTOxCFYSv3",
    "outputId": "2a079fa1-da8a-4f8d-8f91-5ebb7fdebb60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\tScore -0.09976843530428652\n",
      "Iteration 1\tScore -0.09976843530428652\n",
      "Iteration 2\tScore -0.09976843530428652\n",
      "Iteration 3\tScore -1.6944612737802625\n",
      "Iteration 4\tScore -3.462636829149102\n",
      "Iteration 5\tScore -3.462636829149102\n",
      "Iteration 6\tScore -3.462636829149102\n",
      "Iteration 7\tScore -3.462636829149102\n",
      "Iteration 8\tScore -3.462636829149102\n",
      "Iteration 9\tScore -3.462636829149102\n",
      "Iteration 10\tScore -3.705783408188279\n",
      "Iteration 11\tScore -3.705783408188279\n",
      "Iteration 12\tScore -3.705783408188279\n",
      "Iteration 13\tScore -3.705783408188279\n",
      "Iteration 14\tScore -4.6162798529026725\n",
      "Iteration 15\tScore -4.6162798529026725\n",
      "Iteration 16\tScore -4.6162798529026725\n",
      "Iteration 17\tScore -4.6162798529026725\n",
      "Iteration 18\tScore -4.6162798529026725\n",
      "Iteration 19\tScore -4.6162798529026725\n",
      "Iteration 20\tScore -4.6162798529026725\n",
      "Iteration 21\tScore -4.6162798529026725\n",
      "Iteration 22\tScore -4.6162798529026725\n",
      "Iteration 23\tScore -4.6162798529026725\n",
      "Iteration 24\tScore -5.411534701251733\n",
      "Iteration 25\tScore -5.411534701251733\n",
      "Iteration 26\tScore -5.411534701251733\n",
      "Iteration 27\tScore -5.411534701251733\n",
      "Iteration 28\tScore -5.411534701251733\n",
      "Iteration 29\tScore -5.411534701251733\n",
      "Iteration 30\tScore -5.411534701251733\n",
      "Iteration 31\tScore -5.411534701251733\n",
      "Iteration 32\tScore -5.411534701251733\n",
      "Iteration 33\tScore -5.411534701251733\n",
      "Iteration 34\tScore -5.411534701251733\n",
      "Iteration 35\tScore -5.411534701251733\n",
      "Iteration 36\tScore -5.411534701251733\n",
      "Iteration 37\tScore -5.411534701251733\n",
      "Iteration 38\tScore -5.411534701251733\n",
      "Iteration 39\tScore -5.411534701251733\n",
      "Iteration 40\tScore -5.411534701251733\n",
      "Iteration 41\tScore -5.411534701251733\n",
      "Iteration 42\tScore -5.411534701251733\n",
      "Iteration 43\tScore -5.411534701251733\n",
      "Iteration 44\tScore -5.411534701251733\n",
      "Iteration 45\tScore -5.411534701251733\n",
      "Iteration 46\tScore -5.411534701251733\n",
      "Iteration 47\tScore -5.411534701251733\n",
      "Iteration 48\tScore -5.411534701251733\n",
      "Iteration 49\tScore -5.411534701251733\n",
      "Connection to Java server closed\n",
      "CPU times: user 1min 1s, sys: 6.51 s, total: 1min 8s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist_dict = {}\n",
    "\n",
    "num_params = len(reinforce_policy_nn_saes_1_1.get_params())\n",
    "\n",
    "#initial_solution_array = np.random.random(num_params)\n",
    "#initial_sigma_array = np.ones(num_params) * 1.0\n",
    "\n",
    "optimized_policy_params_reinforce_policy_nn_saes_1_1 = saes_1_1(\n",
    "    env,\n",
    "    objective_function=objective_function,\n",
    "    x_array=initial_solution_array,\n",
    "    sigma_array=initial_sigma_array,\n",
    "    tau=0.001,\n",
    "    max_iterations=50,\n",
    "    print_every=1,\n",
    "    success_score=-500,\n",
    "    num_evals_for_stop=None,\n",
    "    hist_dict=hist_dict,\n",
    ")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce_policy_nn_saes_1_1.set_params(optimized_policy_params_reinforce_policy_nn_saes_1_1)\n",
    "torch.save(reinforce_policy_nn_saes_1_1.state_dict(), MODELS_DIR / \"reinforce_policy_nn_saes_1_1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing against a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_functions.test_policy_network_vs_random(env_port=3, num_episodes=1,\n",
    "                                             policy_network=reinforce_policy_nn_saes_1_1, max_steps=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing against our Java ID Alpha Beta agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_saes_1_1_reinforce = test_functions.test_policy_network_vs_alpha_beta(env_port=3, num_episodes=1,\n",
    "                                                                              policy_network=reinforce_policy_nn_saes_1_1,\n",
    "                                                                              agent_port=3, max_steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    hist_dict,\n",
    "    orient=\"index\",\n",
    "    columns=[\n",
    "        \"score\",\n",
    "        \"mu1\",\n",
    "        \"mu2\",\n",
    "        \"mu3\",\n",
    "        \"mu4\",\n",
    "        \"sigma1\",\n",
    "        \"sigma2\",\n",
    "        \"sigma3\",\n",
    "        \"sigma4\",\n",
    "    ],\n",
    ")\n",
    "ax = df.score.plot(title=\"Average reward\", figsize=(30, 5))\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.savefig(PLOTS_DIR / \"reinforce_policy_nn_saes_1_1_avg_reward_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T4f1_-DYSv3"
   },
   "outputs": [],
   "source": [
    "ax = df[[\"mu1\", \"mu2\", \"mu3\", \"mu4\"]].plot(\n",
    "    title=\"Theta w.r.t training steps\", figsize=(30, 5)\n",
    ")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"reinforce_policy_nn_saes_1_1_params_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZ9YUsRwYSv3"
   },
   "outputs": [],
   "source": [
    "ax = df[[\"sigma1\", \"sigma2\", \"sigma3\", \"sigma4\"]].plot(\n",
    "    logy=True, title=\"Sigma w.r.t training steps\", figsize=(30, 5)\n",
    ")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.savefig(PLOTS_DIR / \"reinforce_policy_nn_saes_1_1_var_wrt_iterations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized weights: \", optimized_policy_params_reinforce_policy_nn_saes_1_1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
